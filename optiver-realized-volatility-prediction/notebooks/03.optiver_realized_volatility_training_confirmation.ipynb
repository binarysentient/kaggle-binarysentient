{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2f18e2-9894-4f0c-bd57-8b37afc02309",
   "metadata": {},
   "source": [
    "### Can our model predict current volatility?  (forget future; first it should be capable of predicting current one with given features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40c4e895-fd66-490d-a8b8-d28b324d3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from optiver_features_handler import get_features_map_for_stock, get_row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad9958-4061-4195-b9d8-77f142bc7fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "750eb0e3-2860-490b-bc3c-2a512485a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join(\"..\",\"input\",\"optiver-realized-volatility-prediction\")\n",
    "OUTPUT_DIRECTORY = os.path.join(\"..\",\"output\")\n",
    "MODEL_OUTPUT_DIRECTORY = os.path.join(OUTPUT_DIRECTORY,\"models\")\n",
    "os.makedirs(OUTPUT_DIRECTORY,exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_DIRECTORY,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02947ab-aa1d-4af0-9d6e-7a51cff159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptiverRealizedVolatilityDataset(Dataset):\n",
    "    def __init__(self, data_directory, mode=\"train\", lazy_load=True):\n",
    "        \"\"\"initializes Optiver Competition dataset\n",
    "        `mode`: train|test\n",
    "        `data_directory`: the datadirectory of the input data, where there are test.csv, train.csv, and parquet folders for trade_train.parquet and other relevant folders\n",
    "        \"\"\"\n",
    "        print(\"INIT: OptiverRealizedVolatilityDataset\")\n",
    "        if mode.lower() not in ['train','test']:\n",
    "            raise Exception(\"Invalid mode passed for Optiver dataset. Valid values:train|test\")\n",
    "        self.data_directory = data_directory\n",
    "        self.mode = mode.lower()\n",
    "        self.main_df = pd.read_csv(os.path.join(self.data_directory,f'{self.mode}.csv'))\n",
    "#         if self.mode == 'train':\n",
    "#             self.main_df['row_id'] = self.main_df.apply(lambda x: f\"{x['stock_id']:.0f}-{x['time_id']:.0f}\", axis=1)\n",
    "        if self.mode == 'test':\n",
    "            self.main_df['target'] = 0\n",
    "        \n",
    "        self.cache_stocks_done_set = set()\n",
    "        # this is our final features lookup where we park all our features which can be addressed by row_id\n",
    "        # which is individual train/test.csv row id using 'stock_id`-`time_id`\n",
    "        self.cache_rowid_feature_map = {}\n",
    "        row_id_series = self.main_df['stock_id'].astype(str) + \"-\" +self.main_df['time_id'].astype(str)\n",
    "        targets = self.main_df['target'].tolist()\n",
    "        self.stock_possible_timeids_list = {}\n",
    "        for idx, row_id in enumerate(row_id_series.tolist()):\n",
    "            stock_id = int(row_id.split('-')[0])\n",
    "            time_id = int(row_id.split('-')[1])\n",
    "            self.cache_rowid_feature_map[row_id] = {'target':targets[idx], 'stock_id':stock_id,'time_id':time_id,'row_id':row_id}\n",
    "            \n",
    "            # below code is to make sure what timeids we expect from stock data extractor\n",
    "            # in case of missing parquet files we'll have to know the keys to fill default values into\n",
    "            if stock_id not in self.stock_possible_timeids_list:\n",
    "                self.stock_possible_timeids_list[stock_id] = []\n",
    "            self.stock_possible_timeids_list[stock_id].append(time_id)\n",
    "            \n",
    "        \n",
    "        if lazy_load == False:\n",
    "            worker_data = []\n",
    "            for gkey, gdf in self.main_df.groupby(['stock_id']):\n",
    "                worker_data.append((self.data_directory, self.mode, gkey))\n",
    "#             print(\"---------- CPU COUNG:\", multiprocessing.cpu_count())\n",
    "            # NOTE: this was hell of a hunt; this windows and pytorch and jupyter combination is too tedious\n",
    "            #       make sure the function that we distribute don't call pytorch\n",
    "            chunksize = multiprocessing.cpu_count() * 2\n",
    "            processed = 0\n",
    "            for worker_data_chunk in [worker_data[i * chunksize:(i + 1) * chunksize] for i in range((len(worker_data) + chunksize - 1) // chunksize )]:\n",
    "                with Pool(multiprocessing.cpu_count()) as p:\n",
    "                    \n",
    "                    feature_set_list = p.starmap(get_features_map_for_stock, worker_data_chunk)\n",
    "                    \n",
    "                    for feature_map in feature_set_list:\n",
    "                        for rowid, features_dict in feature_map.items():\n",
    "                            for fkey,fval in features_dict.items():\n",
    "                                self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                            self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                        # udpate the indications that we've already fetched this stock and the lazy loader code won't fetch this again\n",
    "                        self.cache_stocks_done_set.add(int(rowid.split('-')[0]))\n",
    "                    \n",
    "                    processed += chunksize\n",
    "                    print(f\"Processed and loaded {processed} stocks features.\")\n",
    "    \n",
    "    def __cache_generate_features(self, main_stock_id, main_time_id):\n",
    "            \n",
    "            \n",
    "            main_row_id = get_row_id(main_stock_id, main_time_id)\n",
    "            if main_stock_id not in self.cache_stocks_done_set:\n",
    "#                 trade_df = pd.read_parquet(os.path.join(self.data_directory, f\"trade_{self.mode}.parquet\", f\"stock_id={stock_id}\"))   \n",
    "                # we'll combine the featureset with the bigger feature set of all stocks\n",
    "                feature_map = get_features_map_for_stock(self.data_directory, self.mode, main_stock_id)\n",
    "                # NOTE: sometime we might now have parquet files in that case we'll have 3 entried in .csv while only 1 gets returned in feature map\n",
    "                # we need to cover for that disparity\n",
    "                for time_id in self.stock_possible_timeids_list[main_stock_id]:\n",
    "                    expected_row_id = get_row_id(main_stock_id, time_id)\n",
    "                    if expected_row_id not in feature_map:\n",
    "                        feature_map[expected_row_id] = {}\n",
    "                for rowid, features_dict in feature_map.items():\n",
    "                    for fkey,fval in features_dict.items():\n",
    "                        self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                    self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                self.cache_stocks_done_set.add(main_stock_id)\n",
    "#             print(self.cache_rowid_feature_map[main_row_id])\n",
    "#             print(torch.tensor([self.cache_rowid_feature_map[main_row_id].get('book_realized_volatility',0)]))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map[main_row_id].get('log_return1_2s', [0]*(int(600/2)))))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map.get('book_directional_volume1_2s', [0]*(int(600/2)))))\n",
    "            return self.cache_rowid_feature_map[main_row_id]\n",
    "        \n",
    "    @staticmethod\n",
    "    def transform_to_01_realized_volatility_linear_data(features_dict):\n",
    "        return (\n",
    "                {\n",
    "                    'row_id':features_dict['row_id'],\n",
    "#                     'book_realized_volatility':torch.tensor([features_dict.get('book_realized_volatility',0)]),\n",
    "                    'log_return1_1s':torch.tensor(features_dict.get('log_return1_1s', [0]*(int(600/1)))),\n",
    "                    'log_return2_1s':torch.tensor(features_dict.get('log_return2_1s', [0]*(int(600/1)))),\n",
    "#                     'book_directional_volume1_1s':torch.tensor(features_dict.get('book_directional_volume1_1s', [0]*(int(600/1)))) \n",
    "                },\n",
    "                torch.tensor([features_dict['target']])\n",
    "#                 [features_dict['target']]\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.main_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: handle for num_workers more than 0\n",
    "        #      using https://pytorch.org/docs/stable/data.html\n",
    "        #      using torch.util.data.get_worker_info()\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        stock_id = self.main_df.at[idx, 'stock_id']\n",
    "        time_id = self.main_df.at[idx, 'time_id']\n",
    "        x,y = self.__cache_generate_features(stock_id,time_id)\n",
    "#         x, y = self.__transform_to_01_realized_volatility_linear_data(features_dict)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efcee691-c9ce-481f-a4e8-dbf97b66b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT: OptiverRealizedVolatilityDataset\n",
      "Processed and loaded 32 stocks features.\n",
      "Processed and loaded 64 stocks features.\n",
      "Processed and loaded 96 stocks features.\n",
      "Processed and loaded 128 stocks features.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    dataset = OptiverRealizedVolatilityDataset(DATA_DIRECTORY, mode=\"train\", lazy_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d58ff-26aa-4b02-b2ac-991ccb366c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in range(0,9):\n",
    "#     print(dataset[x])\n",
    "dataset[10000] #[0]['book_wap1_1s'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01a7450-a6f4-49ac-861b-81912176aed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'book_realized_volatility'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29064/1947945716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtradevola\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'book_realized_volatility'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#     print('book',X['book_realized_volatility'].item(),'trade', X['trade_realized_volatility'].item(),'traget', y.item())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print('bookdiff', abs(X['book_realized_volatility'].item()-y.item()), 'tradediff', abs(X['trade_realized_volatility'].item()-y.item()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'book_realized_volatility'"
     ]
    }
   ],
   "source": [
    "# for key, val in dataset.cache_rowid_feature_map.items():\n",
    "#     dataset.main_df.at[0,'time_id']\n",
    "#     dataset.main_df.at[0,'stock_id']\n",
    "tradevola = []\n",
    "for idx in range(0, len(dataset)):\n",
    "    X, y = dataset[idx]\n",
    "    tradevola.append(X['book_realized_volatility'].item())\n",
    "#     print('book',X['book_realized_volatility'].item(),'trade', X['trade_realized_volatility'].item(),'traget', y.item())\n",
    "#     print('bookdiff', abs(X['book_realized_volatility'].item()-y.item()), 'tradediff', abs(X['trade_realized_volatility'].item()-y.item()))\n",
    "#     break\n",
    "#     input()\n",
    "#     except:\n",
    "#         print(\"ERRR\")\n",
    "#         print(idx)\n",
    "#         print(dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a690b3b2-6d81-4ce0-b7eb-a82d78183697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    428932.000000\n",
       "mean          0.004233\n",
       "std           0.003586\n",
       "min           0.000081\n",
       "25%           0.002065\n",
       "50%           0.003159\n",
       "75%           0.005108\n",
       "max           0.086421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(tradevola).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a72c9b-fab8-4536-b125-abc46cc800b6",
   "metadata": {},
   "source": [
    "### Learnings about model CNN input\n",
    "- it's better to use multiple channel for logreturn1 and logreturn2 than stacking it and using as one channel\n",
    "- 2 channels input for CNN is better than stacking it(dim 2, which is logret1_t1, logret2_t1, logret1_t2, logret2_t2...) and using it as one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15e35973-37f1-408a-b47f-3a8fa6c9879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.cnn_stack = nn.Sequential(\n",
    "            nn.Conv1d(2, 8, kernel_size=10, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1d(8, 8, kernel_size=8, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "#             nn.Conv1d(8, 8, kernel_size=4, stride=2, padding=0), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.1),\n",
    "        )\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(256, 64),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "#         self.basic_stack = nn.Sequential(\n",
    "#             nn.Linear(int(600/2)*1,512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.4),\n",
    "#             nn.Linear(512,1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.4),\n",
    "# #             nn.Linear(2048,1024),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.Dropout(),\n",
    "#             nn.Linear(1024,512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(512,128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(128,128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128,1),\n",
    "#         )\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         logits = self.basic_stack(x)\n",
    "#         x = self.flatten(x)\n",
    "        logits = self.cnn_stack(x)\n",
    "        logits = self.flatten(logits)\n",
    "        logits = self.linear_stack(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn_mse(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)))\n",
    "\n",
    "def loss_fn_mspe(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)/y))\n",
    "\n",
    "def loss_fn_orig(y, pred):\n",
    "    return torch.sqrt(torch.mean(torch.square((y-pred)/y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4954eef-824e-4676-b639-f443156a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7dc67ca2-9cf8-4035-a214-112214b37cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (cnn_stack): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(10,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Conv1d(8, 8, kernel_size=(8,), stride=(2,))\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (linear_stack): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1f24f-c586-4e1b-aad6-fb4671c87232",
   "metadata": {},
   "source": [
    "#### analyze the initial weights (or change them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "931890cf-e329-4a15-b0d0-352dc27f985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @torch.no_grad()\n",
    "# def init_weights(m):\n",
    "# #     print(m)\n",
    "#     if type(m) == nn.Linear:\n",
    "# #         m.weight.fill_(1.0)\n",
    "#         torch.nn.init.xavier_uniform_(m.weight,gain=10)\n",
    "#         m.bias.data.uniform_(-1,1)\n",
    "# #     elif type(m) == nn.ReLU:\n",
    "# #         print(m.data)\n",
    "#     else:\n",
    "#         print(type(m))\n",
    "# #         print(m.weight)\n",
    "# model.apply(init_weights)\n",
    "# # for param in model.parameters():\n",
    "# # #     print(param)\n",
    "# #       print(param.data.size(), param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c79a7d-9e08-4433-9c77-1af049f349d6",
   "metadata": {},
   "source": [
    "### LEarning rate: our base line is 0.34 loss as that's what the optiver guys have when they use current 10 min realize vol and use it as target (copy to prediction). We create simplest neural network and work with learning rates to figure out what's best and when we see something in range of 0.35 then we've found good Learning rate\n",
    "- #### SGD: 1e-7 works best\n",
    "- #### ADAM: 1e-5, (NOTE: 1e-3 makes it behave dumb where some deep local minima gets stuck and produces constant output!)\n",
    "- TODO: analyze that constant output phenomenon more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cb3871f-5215-4afb-92fc-47ae2d385fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-4\n",
    "# batch_size = 4096\n",
    "# epochs = 100\n",
    "\n",
    "# input_scaling = 1\n",
    "# output_scaling = 1\n",
    "\n",
    "# # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "# strategyname = \"ret1_n_ret2\"\n",
    "# summary_writer = SummaryWriter(f'../output/training_tensorboard/{strategyname}_scaleIn{input_scaling}Out{output_scaling}_{learning_rate}_{batch_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a7ed1-80f8-4a57-90b4-223345dde76b",
   "metadata": {},
   "source": [
    "### Learnings about training\n",
    "- (non scaling)logreturns input and volatility output; non scaled makes the model predict constant output with no variety(close to 0 std dev)\n",
    "- scaling input rids of variety issue, \n",
    "- scaling output makes the model start with low rmse initially so there's less ground to cover and we can iterate over ideas rapidly due to less epochs needed to achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cef34a31-7317-47c0-a94f-9bebe2fd2e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.9983476549386978 [61440/343145]\n",
      "train: 0.9847098477184772 [126976/343145]\n",
      "train: 0.9504085704684258 [192512/343145]\n",
      "train: 0.87978770211339 [258048/343145]\n",
      "train: 0.7531887255609035 [323584/343145]\n",
      "train: 0.6435347646474838 test: 0.6146032129015241 [339968/343145]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.5646568992558647 [49152/343145]\n",
      "train: 0.43775734677910805 [114688/343145]\n",
      "train: 0.42078856378793716 [180224/343145]\n",
      "train: 0.39037532918155193 [245760/343145]\n",
      "train: 0.3658187445253134 [311296/343145]\n",
      "train: 0.34527418443134855 test: 0.34698096059617545 [339968/343145]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.3403148107668933 [36864/343145]\n",
      "train: 0.32175048254430294 [102400/343145]\n",
      "train: 0.32228028029203415 [167936/343145]\n",
      "train: 0.3091813959181309 [233472/343145]\n",
      "train: 0.30388619750738144 [299008/343145]\n",
      "train: 0.30980747640132905 test: 0.30217160213561284 [339968/343145]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.3057509818497826 [24576/343145]\n",
      "train: 0.2924225628376007 [90112/343145]\n",
      "train: 0.28788970597088337 [155648/343145]\n",
      "train: 0.2894842363893986 [221184/343145]\n",
      "train: 0.286340544000268 [286720/343145]\n",
      "train: 0.2875113854041466 test: 0.2794106077580225 [339968/343145]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2852759080774644 [12288/343145]\n",
      "train: 0.2734860796481371 [77824/343145]\n",
      "train: 0.276662714779377 [143360/343145]\n",
      "train: 0.2679412476718426 [208896/343145]\n",
      "train: 0.2643454847857356 [274432/343145]\n",
      "train: 0.26674519293010235 [339968/343145]\n",
      "train: nan test: 0.2626016629593713 [339968/343145]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24961727857589722 [    0/343145]\n",
      "train: 0.2620629146695137 [65536/343145]\n",
      "train: 0.2577206986024976 [131072/343145]\n",
      "train: 0.26521509513258934 [196608/343145]\n",
      "train: 0.2604890465736389 [262144/343145]\n",
      "train: 0.25554895028471947 [327680/343145]\n",
      "train: 0.2523148755232493 test: 0.2555596913610186 [339968/343145]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2522852394510718 [53248/343145]\n",
      "train: 0.26143011823296547 [118784/343145]\n",
      "train: 0.2552560241892934 [184320/343145]\n",
      "train: 0.2605438092723489 [249856/343145]\n",
      "train: 0.25302054081112146 [315392/343145]\n",
      "train: 0.254593459268411 test: 0.25336856501443045 [339968/343145]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.26069048660642963 [40960/343145]\n",
      "train: 0.25238430593162775 [106496/343145]\n",
      "train: 0.2510463437065482 [172032/343145]\n",
      "train: 0.2566346265375614 [237568/343145]\n",
      "train: 0.25232595950365067 [303104/343145]\n",
      "train: 0.25477777421474457 test: 0.25198986416771296 [339968/343145]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.25506085858625527 [28672/343145]\n",
      "train: 0.25278804637491703 [94208/343145]\n",
      "train: 0.2526314640417695 [159744/343145]\n",
      "train: 0.2514213044196367 [225280/343145]\n",
      "train: 0.25678026396781206 [290816/343145]\n",
      "train: 0.25215669473012287 test: 0.2510357456547873 [339968/343145]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2518700475201887 [16384/343145]\n",
      "train: 0.25056216679513454 [81920/343145]\n",
      "train: 0.2547815553843975 [147456/343145]\n",
      "train: 0.2513926289975643 [212992/343145]\n",
      "train: 0.2506721094250679 [278528/343145]\n",
      "train: 0.25812107721964517 test: 0.25049089533942087 [339968/343145]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.25700519365422864 [ 4096/343145]\n",
      "train: 0.2518953587859869 [69632/343145]\n",
      "train: 0.24852044321596622 [135168/343145]\n",
      "train: 0.25360647309571505 [200704/343145]\n",
      "train: 0.2510186806321144 [266240/343145]\n",
      "train: 0.254949115216732 [331776/343145]\n",
      "train: 0.25143925845623016 test: 0.24986313567275092 [339968/343145]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.25032195974798765 [57344/343145]\n",
      "train: 0.25396386440843344 [122880/343145]\n",
      "train: 0.25100985635071993 [188416/343145]\n",
      "train: 0.24953971803188324 [253952/343145]\n",
      "train: 0.25148193445056677 [319488/343145]\n",
      "train: 0.24904203414916992 test: 0.24933202919505892 [339968/343145]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2508022723829045 [45056/343145]\n",
      "train: 0.2512016035616398 [110592/343145]\n",
      "train: 0.25750913470983505 [176128/343145]\n",
      "train: 0.24779629427939653 [241664/343145]\n",
      "train: 0.24966203421354294 [307200/343145]\n",
      "train: 0.24510030075907707 test: 0.24899146315597354 [339968/343145]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24788880260551677 [32768/343145]\n",
      "train: 0.25431758165359497 [98304/343145]\n",
      "train: 0.24872906599193811 [163840/343145]\n",
      "train: 0.2487788088619709 [229376/343145]\n",
      "train: 0.2488843072205782 [294912/343145]\n",
      "train: 0.2512342198328538 test: 0.24860424938656034 [339968/343145]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24955513459794662 [20480/343145]\n",
      "train: 0.24917738884687424 [86016/343145]\n",
      "train: 0.24798157438635826 [151552/343145]\n",
      "train: 0.24824637733399868 [217088/343145]\n",
      "train: 0.24773864913731813 [282624/343145]\n",
      "train: 0.2584223044770105 test: 0.24853353344258808 [339968/343145]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2562605519505108 [ 8192/343145]\n",
      "train: 0.24809113796800375 [73728/343145]\n",
      "train: 0.2504242733120918 [139264/343145]\n",
      "train: 0.24861452914774418 [204800/343145]\n",
      "train: 0.24891831632703543 [270336/343145]\n",
      "train: 0.25130155589431524 [335872/343145]\n",
      "train: 0.24624256789684296 test: 0.24833484703586214 [339968/343145]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24946906724396875 [61440/343145]\n",
      "train: 0.25296021718531847 [126976/343145]\n",
      "train: 0.24805550277233124 [192512/343145]\n",
      "train: 0.24807788338512182 [258048/343145]\n",
      "train: 0.24653671775013208 [323584/343145]\n",
      "train: 0.25101082026958466 test: 0.24786193172136942 [339968/343145]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2485764377257403 [49152/343145]\n",
      "train: 0.24651320185512304 [114688/343145]\n",
      "train: 0.24930611066520214 [180224/343145]\n",
      "train: 0.2493228605017066 [245760/343145]\n",
      "train: 0.251663263887167 [311296/343145]\n",
      "train: 0.24753453688962118 test: 0.24775704315730504 [339968/343145]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24763169884681702 [36864/343145]\n",
      "train: 0.25175876822322607 [102400/343145]\n",
      "train: 0.24798657558858395 [167936/343145]\n",
      "train: 0.2504303241148591 [233472/343145]\n",
      "train: 0.2492030831053853 [299008/343145]\n",
      "train: 0.24421297013759613 test: 0.2476038769597099 [339968/343145]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24566995045718024 [24576/343145]\n",
      "train: 0.2517594425007701 [90112/343145]\n",
      "train: 0.24704362358897924 [155648/343145]\n",
      "train: 0.24702961277216673 [221184/343145]\n",
      "train: 0.24716557655483484 [286720/343145]\n",
      "train: 0.2490963374192898 test: 0.24715362702097213 [339968/343145]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2535814458833021 [12288/343145]\n",
      "train: 0.24581725988537073 [77824/343145]\n",
      "train: 0.24692180007696152 [143360/343145]\n",
      "train: 0.24629421532154083 [208896/343145]\n",
      "train: 0.24952752143144608 [274432/343145]\n",
      "train: 0.24618373718112707 [339968/343145]\n",
      "train: nan test: 0.24733686021396092 [339968/343145]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24718058109283447 [    0/343145]\n",
      "train: 0.24780360329896212 [65536/343145]\n",
      "train: 0.24789844825863838 [131072/343145]\n",
      "train: 0.24576527066528797 [196608/343145]\n",
      "train: 0.24744899664074183 [262144/343145]\n",
      "train: 0.24978292547166348 [327680/343145]\n",
      "train: 0.2497541755437851 test: 0.24718897399448214 [339968/343145]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2507939776953529 [53248/343145]\n",
      "train: 0.2453192537650466 [118784/343145]\n",
      "train: 0.24739385303109884 [184320/343145]\n",
      "train: 0.25003266893327236 [249856/343145]\n",
      "train: 0.24520278349518776 [315392/343145]\n",
      "train: 0.24515417466561 test: 0.24694637741361344 [339968/343145]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24696507962311015 [40960/343145]\n",
      "train: 0.24657509289681911 [106496/343145]\n",
      "train: 0.24977799504995346 [172032/343145]\n",
      "train: 0.24656357895582914 [237568/343145]\n",
      "train: 0.24677519034594297 [303104/343145]\n",
      "train: 0.24473580883608925 test: 0.2468818724155426 [339968/343145]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24633660649552064 [28672/343145]\n",
      "train: 0.24913298804312944 [94208/343145]\n",
      "train: 0.2449640603736043 [159744/343145]\n",
      "train: 0.24653851334005594 [225280/343145]\n",
      "train: 0.247241354547441 [290816/343145]\n",
      "train: 0.24778141329685846 test: 0.24666097192537217 [339968/343145]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2507562453255934 [16384/343145]\n",
      "train: 0.24568594060838223 [81920/343145]\n",
      "train: 0.24496971908956766 [147456/343145]\n",
      "train: 0.2478707516565919 [212992/343145]\n",
      "train: 0.24638811312615871 [278528/343145]\n",
      "train: 0.24694803555806477 test: 0.2464645313365119 [339968/343145]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24647216761813445 [ 4096/343145]\n",
      "train: 0.2474883794784546 [69632/343145]\n",
      "train: 0.24553632829338312 [135168/343145]\n",
      "train: 0.24982000421732664 [200704/343145]\n",
      "train: 0.24573001358658075 [266240/343145]\n",
      "train: 0.24558568466454744 [331776/343145]\n",
      "train: 0.2472180351614952 test: 0.24628564360595884 [339968/343145]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24720756358960094 [57344/343145]\n",
      "train: 0.24710822105407715 [122880/343145]\n",
      "train: 0.24543659016489983 [188416/343145]\n",
      "train: 0.24865670688450336 [253952/343145]\n",
      "train: 0.2448133584111929 [319488/343145]\n",
      "train: 0.2457360565662384 test: 0.24630704947880336 [339968/343145]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24820380877046025 [45056/343145]\n",
      "train: 0.24544992856681347 [110592/343145]\n",
      "train: 0.24459351785480976 [176128/343145]\n",
      "train: 0.24620235431939363 [241664/343145]\n",
      "train: 0.24659682344645262 [307200/343145]\n",
      "train: 0.24637233093380928 test: 0.24642678811436608 [339968/343145]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2454166368526571 [32768/343145]\n",
      "train: 0.2460339916869998 [98304/343145]\n",
      "train: 0.24933569971472025 [163840/343145]\n",
      "train: 0.24577595107257366 [229376/343145]\n",
      "train: 0.2454314474016428 [294912/343145]\n",
      "train: 0.24524408714337784 test: 0.24609860068275816 [339968/343145]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24467589399393866 [20480/343145]\n",
      "train: 0.24589981231838465 [86016/343145]\n",
      "train: 0.24486511386930943 [151552/343145]\n",
      "train: 0.24673642124980688 [217088/343145]\n",
      "train: 0.24779661558568478 [282624/343145]\n",
      "train: 0.24541899029697692 test: 0.24602045402640388 [339968/343145]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24587056303725524 [ 8192/343145]\n",
      "train: 0.24773787055164576 [73728/343145]\n",
      "train: 0.24643042590469122 [139264/343145]\n",
      "train: 0.24297413136810064 [204800/343145]\n",
      "train: 0.24672358483076096 [270336/343145]\n",
      "train: 0.24583763722330332 [335872/343145]\n",
      "train: 0.24628067016601562 test: 0.2462437493460519 [339968/343145]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24824766288785374 [61440/343145]\n",
      "train: 0.24489316437393427 [126976/343145]\n",
      "train: 0.24593506660312414 [192512/343145]\n",
      "train: 0.24401402659714222 [258048/343145]\n",
      "train: 0.24514306336641312 [323584/343145]\n",
      "train: 0.24557193368673325 test: 0.24597204937821343 [339968/343145]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2453780630055596 [49152/343145]\n",
      "train: 0.24441275466233492 [114688/343145]\n",
      "train: 0.24819896183907986 [180224/343145]\n",
      "train: 0.24456577841192484 [245760/343145]\n",
      "train: 0.24551589507609606 [311296/343145]\n",
      "train: 0.24446722439357213 test: 0.2455511007990156 [339968/343145]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24477609115488388 [36864/343145]\n",
      "train: 0.24417329113930464 [102400/343145]\n",
      "train: 0.24612793140113354 [167936/343145]\n",
      "train: 0.24741747323423624 [233472/343145]\n",
      "train: 0.24441806692630053 [299008/343145]\n",
      "train: 0.24534797221422194 test: 0.24591306135767982 [339968/343145]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24453566179556005 [24576/343145]\n",
      "train: 0.24558591190725565 [90112/343145]\n",
      "train: 0.24388810340315104 [155648/343145]\n",
      "train: 0.2459438405930996 [221184/343145]\n",
      "train: 0.24462267104536295 [286720/343145]\n",
      "train: 0.24857076085530794 test: 0.24570417617048537 [339968/343145]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2476385104305604 [12288/343145]\n",
      "train: 0.2464799741283059 [77824/343145]\n",
      "train: 0.2458969596773386 [143360/343145]\n",
      "train: 0.24567921832203865 [208896/343145]\n",
      "train: 0.24386752396821976 [274432/343145]\n",
      "train: 0.24522157572209835 [339968/343145]\n",
      "train: nan test: 0.2456716001033783 [339968/343145]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24288469552993774 [    0/343145]\n",
      "train: 0.24601357243955135 [65536/343145]\n",
      "train: 0.24640376958996058 [131072/343145]\n",
      "train: 0.24638644326478243 [196608/343145]\n",
      "train: 0.24415080714970827 [262144/343145]\n",
      "train: 0.24432507064193487 [327680/343145]\n",
      "train: 0.24392354488372803 test: 0.2455450672478903 [339968/343145]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24458908771767335 [53248/343145]\n",
      "train: 0.24382903147488832 [118784/343145]\n",
      "train: 0.2459090081974864 [184320/343145]\n",
      "train: 0.24369042180478573 [249856/343145]\n",
      "train: 0.24848178587853909 [315392/343145]\n",
      "train: 0.24315756311019263 test: 0.24561147817543574 [339968/343145]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24466336562353022 [40960/343145]\n",
      "train: 0.24348185677081347 [106496/343145]\n",
      "train: 0.24458332546055317 [172032/343145]\n",
      "train: 0.24476880952715874 [237568/343145]\n",
      "train: 0.24595560505986214 [303104/343145]\n",
      "train: 0.2475309951437844 test: 0.24571488159043448 [339968/343145]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2462520353934344 [28672/343145]\n",
      "train: 0.24530236888676882 [94208/343145]\n",
      "train: 0.2483400721102953 [159744/343145]\n",
      "train: 0.24422114808112383 [225280/343145]\n",
      "train: 0.24444189853966236 [290816/343145]\n",
      "train: 0.24268169328570366 test: 0.24577330620515914 [339968/343145]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24448783871005564 [16384/343145]\n",
      "train: 0.244865239597857 [81920/343145]\n",
      "train: 0.2445521205663681 [147456/343145]\n",
      "train: 0.245167494751513 [212992/343145]\n",
      "train: 0.2436801427975297 [278528/343145]\n",
      "train: 0.24429890712102253 test: 0.2453461033957345 [339968/343145]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24474954868064208 [ 4096/343145]\n",
      "train: 0.24412743654102087 [69632/343145]\n",
      "train: 0.2464988585561514 [135168/343145]\n",
      "train: 0.24420482106506824 [200704/343145]\n",
      "train: 0.24445632472634315 [266240/343145]\n",
      "train: 0.2440163465216756 [331776/343145]\n",
      "train: 0.24378175288438797 test: 0.24564400173368908 [339968/343145]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24403956532478333 [57344/343145]\n",
      "train: 0.24517986923456192 [122880/343145]\n",
      "train: 0.24405890330672264 [188416/343145]\n",
      "train: 0.24572135973721743 [253952/343145]\n",
      "train: 0.24399760738015175 [319488/343145]\n",
      "train: 0.2449095904827118 test: 0.2452769492353712 [339968/343145]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24434976279735565 [45056/343145]\n",
      "train: 0.24375733453780413 [110592/343145]\n",
      "train: 0.2445322796702385 [176128/343145]\n",
      "train: 0.24431383423507214 [241664/343145]\n",
      "train: 0.24608549010008574 [307200/343145]\n",
      "train: 0.24480125308036804 test: 0.24547881597564333 [339968/343145]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24521019528893864 [32768/343145]\n",
      "train: 0.2437671311199665 [98304/343145]\n",
      "train: 0.24496133346110582 [163840/343145]\n",
      "train: 0.2434828169643879 [229376/343145]\n",
      "train: 0.24366485234349966 [294912/343145]\n",
      "train: 0.2464287199757316 test: 0.24536548554897308 [339968/343145]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24679445782128503 [20480/343145]\n",
      "train: 0.2451521037146449 [86016/343145]\n",
      "train: 0.2428502207621932 [151552/343145]\n",
      "train: 0.2447833837941289 [217088/343145]\n",
      "train: 0.2426259806379676 [282624/343145]\n",
      "train: 0.24623134093625204 test: 0.24542870691844396 [339968/343145]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24613106864340165 [ 8192/343145]\n",
      "train: 0.24430118966847658 [73728/343145]\n",
      "train: 0.24356184341013432 [139264/343145]\n",
      "train: 0.24265986867249012 [204800/343145]\n",
      "train: 0.246667655184865 [270336/343145]\n",
      "train: 0.24390001595020294 [335872/343145]\n",
      "train: 0.24656414985656738 test: 0.24573080383595966 [339968/343145]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24468439203851364 [61440/343145]\n",
      "train: 0.24522879719734192 [126976/343145]\n",
      "train: 0.24508375860750675 [192512/343145]\n",
      "train: 0.24313407111912966 [258048/343145]\n",
      "train: 0.24257068894803524 [323584/343145]\n",
      "train: 0.24811672046780586 test: 0.24540297899927413 [339968/343145]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24497179687023163 [49152/343145]\n",
      "train: 0.24486779514700174 [114688/343145]\n",
      "train: 0.24472963344305754 [180224/343145]\n",
      "train: 0.244703090749681 [245760/343145]\n",
      "train: 0.24326873570680618 [311296/343145]\n",
      "train: 0.2403520154101508 test: 0.24511767001379103 [339968/343145]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24172700590947094 [36864/343145]\n",
      "train: 0.24332916643470526 [102400/343145]\n",
      "train: 0.24436673428863287 [167936/343145]\n",
      "train: 0.24513248540461063 [233472/343145]\n",
      "train: 0.2450416088104248 [299008/343145]\n",
      "train: 0.24304697513580323 test: 0.2452255224897748 [339968/343145]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2431234918973025 [24576/343145]\n",
      "train: 0.24339130986481905 [90112/343145]\n",
      "train: 0.2443066705018282 [155648/343145]\n",
      "train: 0.2454924425110221 [221184/343145]\n",
      "train: 0.2440397311002016 [286720/343145]\n",
      "train: 0.24433079820412856 test: 0.24518801059041703 [339968/343145]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24454805780859554 [12288/343145]\n",
      "train: 0.24228101689368486 [77824/343145]\n",
      "train: 0.24478790163993835 [143360/343145]\n",
      "train: 0.24479839857667685 [208896/343145]\n",
      "train: 0.24376629572361708 [274432/343145]\n",
      "train: 0.24441168177872896 [339968/343145]\n",
      "train: nan test: 0.245132178068161 [339968/343145]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2407417744398117 [    0/343145]\n",
      "train: 0.24567765463143587 [65536/343145]\n",
      "train: 0.24436215963214636 [131072/343145]\n",
      "train: 0.24462698306888342 [196608/343145]\n",
      "train: 0.24351641442626715 [262144/343145]\n",
      "train: 0.24207020550966263 [327680/343145]\n",
      "train: 0.24558986723423004 test: 0.24499842595486415 [339968/343145]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24304236646960764 [53248/343145]\n",
      "train: 0.24465645756572485 [118784/343145]\n",
      "train: 0.2449369840323925 [184320/343145]\n",
      "train: 0.24329400155693293 [249856/343145]\n",
      "train: 0.24429896753281355 [315392/343145]\n",
      "train: 0.24144876499970755 test: 0.24494624634583792 [339968/343145]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24275459787424872 [40960/343145]\n",
      "train: 0.2439909540116787 [106496/343145]\n",
      "train: 0.24569518771022558 [172032/343145]\n",
      "train: 0.24230363965034485 [237568/343145]\n",
      "train: 0.2437751293182373 [303104/343145]\n",
      "train: 0.24280407693650988 test: 0.24537894910290128 [339968/343145]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24273567602914922 [28672/343145]\n",
      "train: 0.24471050035208464 [94208/343145]\n",
      "train: 0.24311607610434294 [159744/343145]\n",
      "train: 0.24312119372189045 [225280/343145]\n",
      "train: 0.2435044590383768 [290816/343145]\n",
      "train: 0.2439489501218001 test: 0.24510449312982105 [339968/343145]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2435493784792283 [16384/343145]\n",
      "train: 0.24308989197015762 [81920/343145]\n",
      "train: 0.24390769097954035 [147456/343145]\n",
      "train: 0.24336230661720037 [212992/343145]\n",
      "train: 0.24374537263065577 [278528/343145]\n",
      "train: 0.24447957277297974 test: 0.24501576168196543 [339968/343145]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24393217440913706 [ 4096/343145]\n",
      "train: 0.2424140479415655 [69632/343145]\n",
      "train: 0.2445256970822811 [135168/343145]\n",
      "train: 0.24283691495656967 [200704/343145]\n",
      "train: 0.24614820163697004 [266240/343145]\n",
      "train: 0.24263210128992796 [331776/343145]\n",
      "train: 0.24448513239622116 test: 0.24512433438074022 [339968/343145]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24464745644260855 [57344/343145]\n",
      "train: 0.24656784161925316 [122880/343145]\n",
      "train: 0.24291059281677008 [188416/343145]\n",
      "train: 0.2417797800153494 [253952/343145]\n",
      "train: 0.2425174554809928 [319488/343145]\n",
      "train: 0.24511368572711945 test: 0.24504439461798894 [339968/343145]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24328837762860692 [45056/343145]\n",
      "train: 0.24382197298109531 [110592/343145]\n",
      "train: 0.24326794408261776 [176128/343145]\n",
      "train: 0.24419596139341593 [241664/343145]\n",
      "train: 0.2425222722813487 [307200/343145]\n",
      "train: 0.24444547854363918 test: 0.24530660112698874 [339968/343145]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2430452213567846 [32768/343145]\n",
      "train: 0.2445066813379526 [98304/343145]\n",
      "train: 0.2444406310096383 [163840/343145]\n",
      "train: 0.24342173151671886 [229376/343145]\n",
      "train: 0.24144399259239435 [294912/343145]\n",
      "train: 0.24463429911570114 test: 0.24505882036118282 [339968/343145]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24464208238265095 [20480/343145]\n",
      "train: 0.24300983734428883 [86016/343145]\n",
      "train: 0.24404331855475903 [151552/343145]\n",
      "train: 0.24294767249375582 [217088/343145]\n",
      "train: 0.24457748141139746 [282624/343145]\n",
      "train: 0.24133669372115815 test: 0.24543083423659914 [339968/343145]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2419033927076003 [ 8192/343145]\n",
      "train: 0.24401799030601978 [73728/343145]\n",
      "train: 0.24246496707201004 [139264/343145]\n",
      "train: 0.24384353961795568 [204800/343145]\n",
      "train: 0.2432747082784772 [270336/343145]\n",
      "train: 0.2428753860294819 [335872/343145]\n",
      "train: 0.24135155975818634 test: 0.24499647390274776 [339968/343145]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24246570818564472 [61440/343145]\n",
      "train: 0.243787101469934 [126976/343145]\n",
      "train: 0.24345852248370647 [192512/343145]\n",
      "train: 0.24279548041522503 [258048/343145]\n",
      "train: 0.24358541704714298 [323584/343145]\n",
      "train: 0.24705371633172035 test: 0.24509761943703606 [339968/343145]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24482055884950302 [49152/343145]\n",
      "train: 0.2423196230083704 [114688/343145]\n",
      "train: 0.2424263283610344 [180224/343145]\n",
      "train: 0.24372979626059532 [245760/343145]\n",
      "train: 0.24413557536900043 [311296/343145]\n",
      "train: 0.24248551896640233 test: 0.24540268381436667 [339968/343145]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24332853625802434 [36864/343145]\n",
      "train: 0.24361882265657187 [102400/343145]\n",
      "train: 0.24390219151973724 [167936/343145]\n",
      "train: 0.2418827787041664 [233472/343145]\n",
      "train: 0.2425184827297926 [299008/343145]\n",
      "train: 0.24448248445987703 test: 0.24480788693541572 [339968/343145]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24333014821304993 [24576/343145]\n",
      "train: 0.2430640896782279 [90112/343145]\n",
      "train: 0.2429822338744998 [155648/343145]\n",
      "train: 0.24263115227222443 [221184/343145]\n",
      "train: 0.2446998506784439 [286720/343145]\n",
      "train: 0.24227284009640032 test: 0.24519067860784985 [339968/343145]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2426481974475524 [12288/343145]\n",
      "train: 0.2445366196334362 [77824/343145]\n",
      "train: 0.24330298136919737 [143360/343145]\n",
      "train: 0.24245961010456085 [208896/343145]\n",
      "train: 0.2419476332142949 [274432/343145]\n",
      "train: 0.24303767085075378 [339968/343145]\n",
      "train: nan test: 0.24499977699347905 [339968/343145]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2524711787700653 [    0/343145]\n",
      "train: 0.24199157487601042 [65536/343145]\n",
      "train: 0.24362680595368147 [131072/343145]\n",
      "train: 0.24388535041362047 [196608/343145]\n",
      "train: 0.24301834125071764 [262144/343145]\n",
      "train: 0.242534046061337 [327680/343145]\n",
      "train: 0.24084221323331198 test: 0.24511076084205083 [339968/343145]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24287712749312906 [53248/343145]\n",
      "train: 0.2433094596490264 [118784/343145]\n",
      "train: 0.24212205596268177 [184320/343145]\n",
      "train: 0.24481251370161772 [249856/343145]\n",
      "train: 0.24258437100797892 [315392/343145]\n",
      "train: 0.2407513385017713 test: 0.24530075845264254 [339968/343145]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24161718961070566 [40960/343145]\n",
      "train: 0.24332538712769747 [106496/343145]\n",
      "train: 0.24289331305772066 [172032/343145]\n",
      "train: 0.24295765068382025 [237568/343145]\n",
      "train: 0.24256331846117973 [303104/343145]\n",
      "train: 0.24260175062550438 test: 0.24497789357389724 [339968/343145]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24207337989526637 [28672/343145]\n",
      "train: 0.24274420738220215 [94208/343145]\n",
      "train: 0.2434043027460575 [159744/343145]\n",
      "train: 0.24395197816193104 [225280/343145]\n",
      "train: 0.2430759146809578 [290816/343145]\n",
      "train: 0.2415445658067862 test: 0.24484156143097652 [339968/343145]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24175663905985215 [16384/343145]\n",
      "train: 0.24178902339190245 [81920/343145]\n",
      "train: 0.24317816738039255 [147456/343145]\n",
      "train: 0.2419085456058383 [212992/343145]\n",
      "train: 0.24343042634427547 [278528/343145]\n",
      "train: 0.2445469816525777 test: 0.24490144848823547 [339968/343145]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24459416901364045 [ 4096/343145]\n",
      "train: 0.24218426458537579 [69632/343145]\n",
      "train: 0.24400767870247364 [135168/343145]\n",
      "train: 0.2425775583833456 [200704/343145]\n",
      "train: 0.2447962686419487 [266240/343145]\n",
      "train: 0.24098217394202948 [331776/343145]\n",
      "train: 0.23582042753696442 test: 0.24488078838302976 [339968/343145]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24319766374195323 [57344/343145]\n",
      "train: 0.2419899431988597 [122880/343145]\n",
      "train: 0.24149314686655998 [188416/343145]\n",
      "train: 0.24335159454494715 [253952/343145]\n",
      "train: 0.24202483985573053 [319488/343145]\n",
      "train: 0.24189667999744416 test: 0.24505925675233206 [339968/343145]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24321842368911295 [45056/343145]\n",
      "train: 0.24222710449248552 [110592/343145]\n",
      "train: 0.24236288387328386 [176128/343145]\n",
      "train: 0.24334406293928623 [241664/343145]\n",
      "train: 0.24271166883409023 [307200/343145]\n",
      "train: 0.24094025418162346 test: 0.2450993728070032 [339968/343145]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24145996833548827 [32768/343145]\n",
      "train: 0.24176972266286612 [98304/343145]\n",
      "train: 0.24395062774419785 [163840/343145]\n",
      "train: 0.24298594426363707 [229376/343145]\n",
      "train: 0.24414340686053038 [294912/343145]\n",
      "train: 0.24166464805603027 test: 0.24486888945102692 [339968/343145]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24166342616081238 [20480/343145]\n",
      "train: 0.2433578846976161 [86016/343145]\n",
      "train: 0.2405039081349969 [151552/343145]\n",
      "train: 0.243695885874331 [217088/343145]\n",
      "train: 0.24232628475874662 [282624/343145]\n",
      "train: 0.2426742815545627 test: 0.2450985638868241 [339968/343145]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2433355310383965 [ 8192/343145]\n",
      "train: 0.24218474049121141 [73728/343145]\n",
      "train: 0.24184664897620678 [139264/343145]\n",
      "train: 0.2426694743335247 [204800/343145]\n",
      "train: 0.2412398187443614 [270336/343145]\n",
      "train: 0.24319435749202967 [335872/343145]\n",
      "train: 0.25526803731918335 test: 0.24508094219934373 [339968/343145]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24371905975482044 [61440/343145]\n",
      "train: 0.2423125682398677 [126976/343145]\n",
      "train: 0.24189483746886253 [192512/343145]\n",
      "train: 0.2425804203376174 [258048/343145]\n",
      "train: 0.24341126065701246 [323584/343145]\n",
      "train: 0.23935391381382942 test: 0.24486883481343588 [339968/343145]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24132747334592483 [49152/343145]\n",
      "train: 0.24321588687598705 [114688/343145]\n",
      "train: 0.242540517821908 [180224/343145]\n",
      "train: 0.24307881575077772 [245760/343145]\n",
      "train: 0.24180667661130428 [311296/343145]\n",
      "train: 0.2416110954114369 test: 0.24507389253094083 [339968/343145]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2416132653460783 [36864/343145]\n",
      "train: 0.24117701407521963 [102400/343145]\n",
      "train: 0.24249538499861956 [167936/343145]\n",
      "train: 0.24382769595831633 [233472/343145]\n",
      "train: 0.2430305201560259 [299008/343145]\n",
      "train: 0.24100849628448487 test: 0.2448672013623374 [339968/343145]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24225581656484044 [24576/343145]\n",
      "train: 0.24308915063738823 [90112/343145]\n",
      "train: 0.2415303261950612 [155648/343145]\n",
      "train: 0.24235695973038673 [221184/343145]\n",
      "train: 0.24111889395862818 [286720/343145]\n",
      "train: 0.24240234264960656 test: 0.24546713559400468 [339968/343145]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24197919053189895 [12288/343145]\n",
      "train: 0.24279363825917244 [77824/343145]\n",
      "train: 0.2427745582535863 [143360/343145]\n",
      "train: 0.2415481423959136 [208896/343145]\n",
      "train: 0.24191826488822699 [274432/343145]\n",
      "train: 0.24255149718374014 [339968/343145]\n",
      "train: nan test: 0.24470398752462297 [339968/343145]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23822882771492004 [    0/343145]\n",
      "train: 0.24246841855347157 [65536/343145]\n",
      "train: 0.24301148764789104 [131072/343145]\n",
      "train: 0.24344673939049244 [196608/343145]\n",
      "train: 0.2420537555590272 [262144/343145]\n",
      "train: 0.24152793921530247 [327680/343145]\n",
      "train: 0.2400933007399241 test: 0.2447509467601776 [339968/343145]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2414122241384843 [53248/343145]\n",
      "train: 0.24306461680680513 [118784/343145]\n",
      "train: 0.2429364835843444 [184320/343145]\n",
      "train: 0.24115478340536356 [249856/343145]\n",
      "train: 0.2421258371323347 [315392/343145]\n",
      "train: 0.24098573128382364 test: 0.24491049491223835 [339968/343145]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24196059563580682 [40960/343145]\n",
      "train: 0.24185017216950655 [106496/343145]\n",
      "train: 0.24202055390924215 [172032/343145]\n",
      "train: 0.24211490154266357 [237568/343145]\n",
      "train: 0.24314351100474596 [303104/343145]\n",
      "train: 0.24203852812449136 test: 0.24468611677487692 [339968/343145]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24287029574899113 [28672/343145]\n",
      "train: 0.2436296995729208 [94208/343145]\n",
      "train: 0.24178675562143326 [159744/343145]\n",
      "train: 0.23963074013590813 [225280/343145]\n",
      "train: 0.24318772926926613 [290816/343145]\n",
      "train: 0.24194478119413057 test: 0.24485038008008683 [339968/343145]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24113844598040862 [16384/343145]\n",
      "train: 0.2419038861989975 [81920/343145]\n",
      "train: 0.24160655494779348 [147456/343145]\n",
      "train: 0.2441570358350873 [212992/343145]\n",
      "train: 0.24209376890212297 [278528/343145]\n",
      "train: 0.2418521076440811 test: 0.24481572281746639 [339968/343145]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24184446124469533 [ 4096/343145]\n",
      "train: 0.24144641496241093 [69632/343145]\n",
      "train: 0.24347135424613953 [135168/343145]\n",
      "train: 0.24211400374770164 [200704/343145]\n",
      "train: 0.24304220918565989 [266240/343145]\n",
      "train: 0.24075378943234682 [331776/343145]\n",
      "train: 0.2396417334675789 test: 0.24498000315257482 [339968/343145]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24221442201558283 [57344/343145]\n",
      "train: 0.24122214317321777 [122880/343145]\n",
      "train: 0.24259837064892054 [188416/343145]\n",
      "train: 0.24224124290049076 [253952/343145]\n",
      "train: 0.24121513962745667 [319488/343145]\n",
      "train: 0.2429373323917389 test: 0.244965869755972 [339968/343145]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2426865635549321 [45056/343145]\n",
      "train: 0.24236915074288845 [110592/343145]\n",
      "train: 0.24190623220056295 [176128/343145]\n",
      "train: 0.23940174374729395 [241664/343145]\n",
      "train: 0.24343240819871426 [307200/343145]\n",
      "train: 0.2442860808223486 test: 0.2449683795372645 [339968/343145]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24254910735523 [32768/343145]\n",
      "train: 0.24311247933655977 [98304/343145]\n",
      "train: 0.24220586102455854 [163840/343145]\n",
      "train: 0.24011053424328566 [229376/343145]\n",
      "train: 0.2420573951676488 [294912/343145]\n",
      "train: 0.24295005066828293 test: 0.24482251277991704 [339968/343145]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24218298670123606 [20480/343145]\n",
      "train: 0.24133756570518017 [86016/343145]\n",
      "train: 0.24179743975400925 [151552/343145]\n",
      "train: 0.24226334318518639 [217088/343145]\n",
      "train: 0.24244534224271774 [282624/343145]\n",
      "train: 0.2416437885590962 test: 0.24495654091948554 [339968/343145]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24166757394285762 [ 8192/343145]\n",
      "train: 0.24042038340121508 [73728/343145]\n",
      "train: 0.24313535541296005 [139264/343145]\n",
      "train: 0.24131260998547077 [204800/343145]\n",
      "train: 0.2427104003727436 [270336/343145]\n",
      "train: 0.24179221969097853 [335872/343145]\n",
      "train: 0.2393522560596466 test: 0.2449315885702769 [339968/343145]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2429471857407514 [61440/343145]\n",
      "train: 0.24130396265536547 [126976/343145]\n",
      "train: 0.24201049655675888 [192512/343145]\n",
      "train: 0.2408880703151226 [258048/343145]\n",
      "train: 0.24171282351016998 [323584/343145]\n",
      "train: 0.2427964024245739 test: 0.2449064396676563 [339968/343145]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24178086396525889 [49152/343145]\n",
      "train: 0.24188634473830462 [114688/343145]\n",
      "train: 0.24045666493475437 [180224/343145]\n",
      "train: 0.2423566160723567 [245760/343145]\n",
      "train: 0.241537569090724 [311296/343145]\n",
      "train: 0.2423063793352672 test: 0.24492388537951879 [339968/343145]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24315361152676976 [36864/343145]\n",
      "train: 0.24075136613100767 [102400/343145]\n",
      "train: 0.24195262882858515 [167936/343145]\n",
      "train: 0.24218622874468565 [233472/343145]\n",
      "train: 0.24051883071660995 [299008/343145]\n",
      "train: 0.2426058456301689 test: 0.2450988973890032 [339968/343145]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24200203313547022 [24576/343145]\n",
      "train: 0.2425291072577238 [90112/343145]\n",
      "train: 0.24236291274428368 [155648/343145]\n",
      "train: 0.24221878126263618 [221184/343145]\n",
      "train: 0.2405507955700159 [286720/343145]\n",
      "train: 0.2406881978878608 test: 0.244831335686502 [339968/343145]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24005691356518688 [12288/343145]\n",
      "train: 0.24252028297632933 [77824/343145]\n",
      "train: 0.24146320205181837 [143360/343145]\n",
      "train: 0.2423219382762909 [208896/343145]\n",
      "train: 0.24198702536523342 [274432/343145]\n",
      "train: 0.2409315425902605 [339968/343145]\n",
      "train: nan test: 0.24490375816822052 [339968/343145]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2430095076560974 [    0/343145]\n",
      "train: 0.24248586129397154 [65536/343145]\n",
      "train: 0.24158571008592844 [131072/343145]\n",
      "train: 0.24158470425754786 [196608/343145]\n",
      "train: 0.24202433042228222 [262144/343145]\n",
      "train: 0.24020426906645298 [327680/343145]\n",
      "train: 0.23984170953432718 test: 0.24477933134351457 [339968/343145]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24113567962365992 [53248/343145]\n",
      "train: 0.2414936125278473 [118784/343145]\n",
      "train: 0.24090793915092945 [184320/343145]\n",
      "train: 0.24181756377220154 [249856/343145]\n",
      "train: 0.24195569194853306 [315392/343145]\n",
      "train: 0.24365278830130896 test: 0.24476936104751768 [339968/343145]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24194256084806778 [40960/343145]\n",
      "train: 0.24247939139604568 [106496/343145]\n",
      "train: 0.24162140395492315 [172032/343145]\n",
      "train: 0.2411058535799384 [237568/343145]\n",
      "train: 0.2420411566272378 [303104/343145]\n",
      "train: 0.240900832745764 test: 0.245047913420768 [339968/343145]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24035091873477488 [28672/343145]\n",
      "train: 0.2408753065392375 [94208/343145]\n",
      "train: 0.24311312939971685 [159744/343145]\n",
      "train: 0.24052072037011385 [225280/343145]\n",
      "train: 0.2419926794245839 [290816/343145]\n",
      "train: 0.2428799644112587 test: 0.2450380353700547 [339968/343145]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24209308010690353 [16384/343145]\n",
      "train: 0.24179009906947613 [81920/343145]\n",
      "train: 0.24163676239550114 [147456/343145]\n",
      "train: 0.24093771073967218 [212992/343145]\n",
      "train: 0.24105405062437057 [278528/343145]\n",
      "train: 0.24212605853875477 test: 0.2448267333564304 [339968/343145]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24193539251299465 [ 4096/343145]\n",
      "train: 0.24261450488120317 [69632/343145]\n",
      "train: 0.2408960284665227 [135168/343145]\n",
      "train: 0.242437694221735 [200704/343145]\n",
      "train: 0.23981351498514414 [266240/343145]\n",
      "train: 0.24176130257546902 [331776/343145]\n",
      "train: 0.2417318969964981 test: 0.2447149938061124 [339968/343145]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24051294081351338 [57344/343145]\n",
      "train: 0.24191902484744787 [122880/343145]\n",
      "train: 0.2422677194699645 [188416/343145]\n",
      "train: 0.24179559852927923 [253952/343145]\n",
      "train: 0.24039642699062824 [319488/343145]\n",
      "train: 0.24212662279605865 test: 0.24473725897925241 [339968/343145]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2413363912526299 [45056/343145]\n",
      "train: 0.2420471180230379 [110592/343145]\n",
      "train: 0.24107594415545464 [176128/343145]\n",
      "train: 0.24147496558725834 [241664/343145]\n",
      "train: 0.24024225305765867 [307200/343145]\n",
      "train: 0.24393638968467712 test: 0.24498302950745537 [339968/343145]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24308812267640056 [32768/343145]\n",
      "train: 0.2410291163250804 [98304/343145]\n",
      "train: 0.2420896179974079 [163840/343145]\n",
      "train: 0.2401001648977399 [229376/343145]\n",
      "train: 0.2415478676557541 [294912/343145]\n",
      "train: 0.24110444296490063 test: 0.24492400671754563 [339968/343145]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24139855363789728 [20480/343145]\n",
      "train: 0.24127895943820477 [86016/343145]\n",
      "train: 0.24104416463524103 [151552/343145]\n",
      "train: 0.24176064226776361 [217088/343145]\n",
      "train: 0.2408291958272457 [282624/343145]\n",
      "train: 0.24142563343048096 test: 0.2447091511317662 [339968/343145]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2411553623045192 [ 8192/343145]\n",
      "train: 0.2418930772691965 [73728/343145]\n",
      "train: 0.2420207615941763 [139264/343145]\n",
      "train: 0.24095766711980104 [204800/343145]\n",
      "train: 0.2404651027172804 [270336/343145]\n",
      "train: 0.24100758414715528 [335872/343145]\n",
      "train: 0.23949317634105682 test: 0.24497185079824357 [339968/343145]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24104428729590247 [61440/343145]\n",
      "train: 0.24110366683453321 [126976/343145]\n",
      "train: 0.241090077906847 [192512/343145]\n",
      "train: 0.2407727325335145 [258048/343145]\n",
      "train: 0.2414715075865388 [323584/343145]\n",
      "train: 0.23920869454741478 test: 0.24471681671483175 [339968/343145]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24043345100739422 [49152/343145]\n",
      "train: 0.24160098936408758 [114688/343145]\n",
      "train: 0.24265263229608536 [180224/343145]\n",
      "train: 0.24050221219658852 [245760/343145]\n",
      "train: 0.24049691762775183 [311296/343145]\n",
      "train: 0.24111761578491755 test: 0.2448908778883162 [339968/343145]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24138715600266175 [36864/343145]\n",
      "train: 0.24096577614545822 [102400/343145]\n",
      "train: 0.24119665380567312 [167936/343145]\n",
      "train: 0.24058780446648598 [233472/343145]\n",
      "train: 0.24094182439148426 [299008/343145]\n",
      "train: 0.2432546943426132 test: 0.24483817248117357 [339968/343145]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24178018464761622 [24576/343145]\n",
      "train: 0.2414517942816019 [90112/343145]\n",
      "train: 0.24343503080308437 [155648/343145]\n",
      "train: 0.24013875238597393 [221184/343145]\n",
      "train: 0.23955559358000755 [286720/343145]\n",
      "train: 0.24066154200297135 test: 0.244914364247095 [339968/343145]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24072734660962047 [12288/343145]\n",
      "train: 0.24136972334235907 [77824/343145]\n",
      "train: 0.23960442375391722 [143360/343145]\n",
      "train: 0.2415426429361105 [208896/343145]\n",
      "train: 0.24081586860120296 [274432/343145]\n",
      "train: 0.24102642852813005 [339968/343145]\n",
      "train: nan test: 0.2448069808028993 [339968/343145]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23635262250900269 [    0/343145]\n",
      "train: 0.2418168829753995 [65536/343145]\n",
      "train: 0.2419622978195548 [131072/343145]\n",
      "train: 0.24090647511184216 [196608/343145]\n",
      "train: 0.2400361094623804 [262144/343145]\n",
      "train: 0.2410900816321373 [327680/343145]\n",
      "train: 0.24111988643805185 test: 0.24497658936750322 [339968/343145]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2407486806897556 [53248/343145]\n",
      "train: 0.24068504571914673 [118784/343145]\n",
      "train: 0.24136234540492296 [184320/343145]\n",
      "train: 0.24164254777133465 [249856/343145]\n",
      "train: 0.23986302595585585 [315392/343145]\n",
      "train: 0.24199261019627252 test: 0.2451416729461579 [339968/343145]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24134865666137023 [40960/343145]\n",
      "train: 0.24123688507825136 [106496/343145]\n",
      "train: 0.24076052010059357 [172032/343145]\n",
      "train: 0.24227951746433973 [237568/343145]\n",
      "train: 0.2399930665269494 [303104/343145]\n",
      "train: 0.24035309255123138 test: 0.24473606050014496 [339968/343145]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24110276821781607 [28672/343145]\n",
      "train: 0.23985243402421474 [94208/343145]\n",
      "train: 0.24176262225955725 [159744/343145]\n",
      "train: 0.24089476466178894 [225280/343145]\n",
      "train: 0.24117808882147074 [290816/343145]\n",
      "train: 0.23983986303210258 test: 0.2448939574616296 [339968/343145]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23980009205201092 [16384/343145]\n",
      "train: 0.24039000179618597 [81920/343145]\n",
      "train: 0.24117599334567785 [147456/343145]\n",
      "train: 0.23979662731289864 [212992/343145]\n",
      "train: 0.24143771920353174 [278528/343145]\n",
      "train: 0.24201337496439615 test: 0.2446033457914988 [339968/343145]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24164651684901295 [ 4096/343145]\n",
      "train: 0.23855885490775108 [69632/343145]\n",
      "train: 0.24216718412935734 [135168/343145]\n",
      "train: 0.24212510138750076 [200704/343145]\n",
      "train: 0.24075496569275856 [266240/343145]\n",
      "train: 0.24096299055963755 [331776/343145]\n",
      "train: 0.24709144979715347 test: 0.24514399894646235 [339968/343145]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24098585458362803 [57344/343145]\n",
      "train: 0.2405276820063591 [122880/343145]\n",
      "train: 0.2407466061413288 [188416/343145]\n",
      "train: 0.24120032880455256 [253952/343145]\n",
      "train: 0.24136728048324585 [319488/343145]\n",
      "train: 0.2404911607503891 test: 0.24488044849463872 [339968/343145]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24114718594971826 [45056/343145]\n",
      "train: 0.24009724520146847 [110592/343145]\n",
      "train: 0.24163057189434767 [176128/343145]\n",
      "train: 0.2410365790128708 [241664/343145]\n",
      "train: 0.2404363863170147 [307200/343145]\n",
      "train: 0.23917916417121887 test: 0.24471013389882587 [339968/343145]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24053964457091162 [32768/343145]\n",
      "train: 0.24139731749892235 [98304/343145]\n",
      "train: 0.24060814641416073 [163840/343145]\n",
      "train: 0.24008608423173428 [229376/343145]\n",
      "train: 0.2400129484012723 [294912/343145]\n",
      "train: 0.24162179231643677 test: 0.24485562245051065 [339968/343145]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2403271461234373 [20480/343145]\n",
      "train: 0.2415901506319642 [86016/343145]\n",
      "train: 0.24064546544104815 [151552/343145]\n",
      "train: 0.2403954016044736 [217088/343145]\n",
      "train: 0.24067530781030655 [282624/343145]\n",
      "train: 0.24014788759606226 test: 0.24477281385944002 [339968/343145]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23990269969491398 [ 8192/343145]\n",
      "train: 0.24159699212759733 [73728/343145]\n",
      "train: 0.2399829812347889 [139264/343145]\n",
      "train: 0.24064574111253023 [204800/343145]\n",
      "train: 0.2407421600073576 [270336/343145]\n",
      "train: 0.23921429831534624 [335872/343145]\n",
      "train: 0.24543863534927368 test: 0.24486048164821805 [339968/343145]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24014939718386707 [61440/343145]\n",
      "train: 0.24201359134167433 [126976/343145]\n",
      "train: 0.2385497773066163 [192512/343145]\n",
      "train: 0.2410539584234357 [258048/343145]\n",
      "train: 0.24106422439217567 [323584/343145]\n",
      "train: 0.2380947545170784 test: 0.24474042795953296 [339968/343145]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23919576231171102 [49152/343145]\n",
      "train: 0.23817456793040037 [114688/343145]\n",
      "train: 0.24244711361825466 [180224/343145]\n",
      "train: 0.2404314549639821 [245760/343145]\n",
      "train: 0.24240518268197775 [311296/343145]\n",
      "train: 0.24154566015516007 test: 0.2448520234652928 [339968/343145]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2412175746525035 [36864/343145]\n",
      "train: 0.23963667079806328 [102400/343145]\n",
      "train: 0.24059577379375696 [167936/343145]\n",
      "train: 0.24101038184016943 [233472/343145]\n",
      "train: 0.24097151588648558 [299008/343145]\n",
      "train: 0.24123674631118774 test: 0.2448734286285582 [339968/343145]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24099155997528748 [24576/343145]\n",
      "train: 0.24090914614498615 [90112/343145]\n",
      "train: 0.23975582048296928 [155648/343145]\n",
      "train: 0.24159726593643427 [221184/343145]\n",
      "train: 0.23998035676777363 [286720/343145]\n",
      "train: 0.23967310442374304 test: 0.24481973477772304 [339968/343145]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2399450908688938 [12288/343145]\n",
      "train: 0.24001575354486704 [77824/343145]\n",
      "train: 0.2401405842974782 [143360/343145]\n",
      "train: 0.24119605589658022 [208896/343145]\n",
      "train: 0.24047782458364964 [274432/343145]\n",
      "train: 0.24040138814598322 [339968/343145]\n",
      "train: nan test: 0.24486723258381798 [339968/343145]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23552824556827545 [    0/343145]\n",
      "train: 0.2406293647363782 [65536/343145]\n",
      "train: 0.23958638031035662 [131072/343145]\n",
      "train: 0.24012050405144691 [196608/343145]\n",
      "train: 0.2414322393015027 [262144/343145]\n",
      "train: 0.2393419723957777 [327680/343145]\n",
      "train: 0.24165878196557364 test: 0.2449681716305869 [339968/343145]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24082755341249354 [53248/343145]\n",
      "train: 0.24074594490230083 [118784/343145]\n",
      "train: 0.2400862080976367 [184320/343145]\n",
      "train: 0.24105820525437593 [249856/343145]\n",
      "train: 0.24016361590474844 [315392/343145]\n",
      "train: 0.23863339920838675 test: 0.24481082743122465 [339968/343145]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23985804442097158 [40960/343145]\n",
      "train: 0.239861898124218 [106496/343145]\n",
      "train: 0.24068234395235777 [172032/343145]\n",
      "train: 0.24060431495308876 [237568/343145]\n",
      "train: 0.23939029313623905 [303104/343145]\n",
      "train: 0.242066267463896 test: 0.24487117997237615 [339968/343145]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24122999520862803 [28672/343145]\n",
      "train: 0.2401986289769411 [94208/343145]\n",
      "train: 0.23992560058832169 [159744/343145]\n",
      "train: 0.24129022099077702 [225280/343145]\n",
      "train: 0.23946969769895077 [290816/343145]\n",
      "train: 0.23966798931360245 test: 0.24471994453952425 [339968/343145]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23932212941786823 [16384/343145]\n",
      "train: 0.23927893303334713 [81920/343145]\n",
      "train: 0.24132478423416615 [147456/343145]\n",
      "train: 0.23955801501870155 [212992/343145]\n",
      "train: 0.24110461492091417 [278528/343145]\n",
      "train: 0.24105618794759115 test: 0.24528989905402773 [339968/343145]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24119017667630138 [ 4096/343145]\n",
      "train: 0.2412779312580824 [69632/343145]\n",
      "train: 0.239146682433784 [135168/343145]\n",
      "train: 0.241219618357718 [200704/343145]\n",
      "train: 0.23962890077382326 [266240/343145]\n",
      "train: 0.23958167247474194 [331776/343145]\n",
      "train: 0.24172472953796387 test: 0.24488174702439988 [339968/343145]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2399222500184003 [57344/343145]\n",
      "train: 0.2403943259268999 [122880/343145]\n",
      "train: 0.23959914222359657 [188416/343145]\n",
      "train: 0.2404759395867586 [253952/343145]\n",
      "train: 0.24002982955425978 [319488/343145]\n",
      "train: 0.23994262218475343 test: 0.24468409447442918 [339968/343145]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23940136415116928 [45056/343145]\n",
      "train: 0.24001249484717846 [110592/343145]\n",
      "train: 0.24026888236403465 [176128/343145]\n",
      "train: 0.23995569813996553 [241664/343145]\n",
      "train: 0.2401598421856761 [307200/343145]\n",
      "train: 0.24062265269458294 test: 0.24487319730577015 [339968/343145]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.24094031488194184 [32768/343145]\n",
      "train: 0.23940755147486925 [98304/343145]\n",
      "train: 0.24050103407353163 [163840/343145]\n",
      "train: 0.23918860591948032 [229376/343145]\n",
      "train: 0.23962478525936604 [294912/343145]\n",
      "train: 0.2393158877437765 test: 0.24469262787273952 [339968/343145]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23879067687427297 [20480/343145]\n",
      "train: 0.23888146318495274 [86016/343145]\n",
      "train: 0.24055035505443811 [151552/343145]\n",
      "train: 0.24080232251435518 [217088/343145]\n",
      "train: 0.2411613678559661 [282624/343145]\n",
      "train: 0.23867918018783843 test: 0.24480639965761275 [339968/343145]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23859009584959814 [ 8192/343145]\n",
      "train: 0.24002904817461967 [73728/343145]\n",
      "train: 0.23941568471491337 [139264/343145]\n",
      "train: 0.24095516838133335 [204800/343145]\n",
      "train: 0.2392163621261716 [270336/343145]\n",
      "train: 0.24096139427274466 [335872/343145]\n",
      "train: 0.23725192248821259 test: 0.2447294160014107 [339968/343145]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23993088918573716 [61440/343145]\n",
      "train: 0.24106112215667963 [126976/343145]\n",
      "train: 0.2393902949988842 [192512/343145]\n",
      "train: 0.23990289960056543 [258048/343145]\n",
      "train: 0.23916691076010466 [323584/343145]\n",
      "train: 0.23909717798233032 test: 0.24478383504209064 [339968/343145]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23931199399863973 [49152/343145]\n",
      "train: 0.24088582210242748 [114688/343145]\n",
      "train: 0.23977743182331324 [180224/343145]\n",
      "train: 0.24001021683216095 [245760/343145]\n",
      "train: 0.23839782923460007 [311296/343145]\n",
      "train: 0.24147010913916997 test: 0.24490659080800556 [339968/343145]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2405263387105044 [36864/343145]\n",
      "train: 0.23953355476260185 [102400/343145]\n",
      "train: 0.24035047460347414 [167936/343145]\n",
      "train: 0.2408649930730462 [233472/343145]\n",
      "train: 0.23956173285841942 [299008/343145]\n",
      "train: 0.2393675610423088 test: 0.24457476465474992 [339968/343145]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23977004780488856 [24576/343145]\n",
      "train: 0.23945239279419184 [90112/343145]\n",
      "train: 0.23888104408979416 [155648/343145]\n",
      "train: 0.24016791116446257 [221184/343145]\n",
      "train: 0.23987300228327513 [286720/343145]\n",
      "train: 0.23994733966313875 test: 0.24482571794873192 [339968/343145]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.23998700257609873 [12288/343145]\n",
      "train: 0.23825677204877138 [77824/343145]\n",
      "train: 0.2410525158047676 [143360/343145]\n",
      "train: 0.24043327011168003 [208896/343145]\n",
      "train: 0.23926895949989557 [274432/343145]\n",
      "train: 0.2387895481660962 [339968/343145]\n",
      "train: nan test: 0.24479372657480694 [339968/343145]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_4096 ----------\n",
      "train: 0.2387426793575287 [    0/343145]\n",
      "train: 0.2390839010477066 [65536/343145]\n",
      "train: 0.2397747728973627 [131072/343145]\n",
      "train: 0.24085614550858736 [196608/343145]\n",
      "train: 0.23910991195589304 [262144/343145]\n",
      "train: 0.24008451402187347 [327680/343145]\n",
      "train: 0.23855186998844147 test: 0.2450711712950752 [339968/343145]\n",
      "DEVICE: cuda:0\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.9958353638648987 [50000/343145]\n",
      "train: 0.9903436005115509 [110000/343145]\n",
      "train: 0.982795923948288 [170000/343145]\n",
      "train: 0.9721012314160665 [230000/343145]\n",
      "train: 0.9567392369111379 [290000/343145]\n",
      "train: 0.9372921228408814 test: 0.924970891740587 [340000/343145]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.9330425943647113 [10000/343145]\n",
      "train: 0.9013107518355051 [70000/343145]\n",
      "train: 0.861969123284022 [130000/343145]\n",
      "train: 0.8122184673945109 [190000/343145]\n",
      "train: 0.7525836726029714 [250000/343145]\n",
      "train: 0.6841724912325541 [310000/343145]\n",
      "train: 0.6294172803560892 test: 0.6047414011425443 [340000/343145]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.6069430538586208 [30000/343145]\n",
      "train: 0.5462747315565745 [90000/343145]\n",
      "train: 0.5235629777113596 [150000/343145]\n",
      "train: 0.5332906643549601 [210000/343145]\n",
      "train: 0.5356568296750387 [270000/343145]\n",
      "train: 0.5182610948880514 [330000/343145]\n",
      "train: 0.5195391178131104 test: 0.5120454695489671 [340000/343145]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.5141550983701434 [50000/343145]\n",
      "train: 0.5253550708293915 [110000/343145]\n",
      "train: 0.5097343226273855 [170000/343145]\n",
      "train: 0.5068416744470596 [230000/343145]\n",
      "train: 0.5133621692657471 [290000/343145]\n",
      "train: 0.5077599048614502 test: 0.49949509236547684 [340000/343145]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.5085883097989219 [10000/343145]\n",
      "train: 0.5074354062477747 [70000/343145]\n",
      "train: 0.4970066696405411 [130000/343145]\n",
      "train: 0.49516457319259644 [190000/343145]\n",
      "train: 0.4873441954453786 [250000/343145]\n",
      "train: 0.4935492177804311 [310000/343145]\n",
      "train: 0.4991817871729533 test: 0.47808289527893066 [340000/343145]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.4886813036033085 [30000/343145]\n",
      "train: 0.47555481890837353 [90000/343145]\n",
      "train: 0.47606997688611347 [150000/343145]\n",
      "train: 0.4653537372748057 [210000/343145]\n",
      "train: 0.466030016541481 [270000/343145]\n",
      "train: 0.44543324907620746 [330000/343145]\n",
      "train: 0.4322400391101837 test: 0.43564076556099784 [340000/343145]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.43723708391189575 [50000/343145]\n",
      "train: 0.42676064868768054 [110000/343145]\n",
      "train: 0.4166545818249385 [170000/343145]\n",
      "train: 0.40733733773231506 [230000/343145]\n",
      "train: 0.3920886317888896 [290000/343145]\n",
      "train: 0.39495143890380857 test: 0.36960988574557835 [340000/343145]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.3979618719645909 [10000/343145]\n",
      "train: 0.3750179360310237 [70000/343145]\n",
      "train: 0.365010733405749 [130000/343145]\n",
      "train: 0.3606186509132385 [190000/343145]\n",
      "train: 0.3486969918012619 [250000/343145]\n",
      "train: 0.34575555721918744 [310000/343145]\n",
      "train: 0.33761419852574664 test: 0.32346752948231167 [340000/343145]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.33711402331079754 [30000/343145]\n",
      "train: 0.33580588301022846 [90000/343145]\n",
      "train: 0.3353940049807231 [150000/343145]\n",
      "train: 0.3281540522972743 [210000/343145]\n",
      "train: 0.3224385778109233 [270000/343145]\n",
      "train: 0.33209948241710663 [330000/343145]\n",
      "train: 0.3181941509246826 test: 0.3130507866541545 [340000/343145]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.33124118617602755 [50000/343145]\n",
      "train: 0.3217666844526927 [110000/343145]\n",
      "train: 0.3154707799355189 [170000/343145]\n",
      "train: 0.3121422628561656 [230000/343145]\n",
      "train: 0.3174448112646739 [290000/343145]\n",
      "train: 0.3365850687026978 test: 0.30410876539018417 [340000/343145]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.33084698234285626 [10000/343145]\n",
      "train: 0.3107445687055588 [70000/343145]\n",
      "train: 0.31534762183825177 [130000/343145]\n",
      "train: 0.3078690518935521 [190000/343145]\n",
      "train: 0.31743763387203217 [250000/343145]\n",
      "train: 0.30392999450365704 [310000/343145]\n",
      "train: 0.29805484414100647 test: 0.29079852832688224 [340000/343145]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.29922257150922504 [30000/343145]\n",
      "train: 0.29997317492961884 [90000/343145]\n",
      "train: 0.294330174724261 [150000/343145]\n",
      "train: 0.2994728734095891 [210000/343145]\n",
      "train: 0.3047907203435898 [270000/343145]\n",
      "train: 0.29079069197177887 [330000/343145]\n",
      "train: 0.28208455443382263 test: 0.2774273157119751 [340000/343145]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2895758705479758 [50000/343145]\n",
      "train: 0.27921225627263385 [110000/343145]\n",
      "train: 0.29329314827919006 [170000/343145]\n",
      "train: 0.28224876523017883 [230000/343145]\n",
      "train: 0.2850046555201213 [290000/343145]\n",
      "train: 0.27674304246902465 test: 0.2662457525730133 [340000/343145]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2764657863548824 [10000/343145]\n",
      "train: 0.27606234451135 [70000/343145]\n",
      "train: 0.2788204997777939 [130000/343145]\n",
      "train: 0.2703593671321869 [190000/343145]\n",
      "train: 0.2828861673672994 [250000/343145]\n",
      "train: 0.27332479258378345 [310000/343145]\n",
      "train: 0.26036739349365234 test: 0.25797758830918205 [340000/343145]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2670857948916299 [30000/343145]\n",
      "train: 0.27475064992904663 [90000/343145]\n",
      "train: 0.2667797803878784 [150000/343145]\n",
      "train: 0.2671055346727371 [210000/343145]\n",
      "train: 0.2608790993690491 [270000/343145]\n",
      "train: 0.2703123490015666 [330000/343145]\n",
      "train: 0.26479753851890564 test: 0.25724953413009644 [340000/343145]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.26746462072644916 [50000/343145]\n",
      "train: 0.26659536361694336 [110000/343145]\n",
      "train: 0.2705146372318268 [170000/343145]\n",
      "train: 0.262214258313179 [230000/343145]\n",
      "train: 0.26343033214410144 [290000/343145]\n",
      "train: 0.2605576038360596 test: 0.2532291379239824 [340000/343145]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2589977766786303 [10000/343145]\n",
      "train: 0.2698068420092265 [70000/343145]\n",
      "train: 0.2578638245662053 [130000/343145]\n",
      "train: 0.2600770940383275 [190000/343145]\n",
      "train: 0.25855446855227154 [250000/343145]\n",
      "train: 0.2735431392987569 [310000/343145]\n",
      "train: 0.25998373826344806 test: 0.25417549080318874 [340000/343145]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2581112001623426 [30000/343145]\n",
      "train: 0.2620177020629247 [90000/343145]\n",
      "train: 0.2673642635345459 [150000/343145]\n",
      "train: 0.26246945559978485 [210000/343145]\n",
      "train: 0.26219114164511365 [270000/343145]\n",
      "train: 0.2603214532136917 [330000/343145]\n",
      "train: 0.24996310472488403 test: 0.25458012686835396 [340000/343145]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.26157220772334505 [50000/343145]\n",
      "train: 0.2583324760198593 [110000/343145]\n",
      "train: 0.261751726269722 [170000/343145]\n",
      "train: 0.264704296986262 [230000/343145]\n",
      "train: 0.2594996790091197 [290000/343145]\n",
      "train: 0.259115594625473 test: 0.2532528026236428 [340000/343145]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2594939342566899 [10000/343145]\n",
      "train: 0.2591182788213094 [70000/343145]\n",
      "train: 0.26650690535704297 [130000/343145]\n",
      "train: 0.257035031914711 [190000/343145]\n",
      "train: 0.26090946793556213 [250000/343145]\n",
      "train: 0.2584742953379949 [310000/343145]\n",
      "train: 0.25501521428426105 test: 0.2522101104259491 [340000/343145]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2535122164658138 [30000/343145]\n",
      "train: 0.26299408078193665 [90000/343145]\n",
      "train: 0.26352908710638684 [150000/343145]\n",
      "train: 0.2596282660961151 [210000/343145]\n",
      "train: 0.26437409222126007 [270000/343145]\n",
      "train: 0.25576279560724896 [330000/343145]\n",
      "train: 0.2572267949581146 test: 0.254281888405482 [340000/343145]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2577299177646637 [50000/343145]\n",
      "train: 0.26611222326755524 [110000/343145]\n",
      "train: 0.25470204651355743 [170000/343145]\n",
      "train: 0.25937677919864655 [230000/343145]\n",
      "train: 0.26182109614213306 [290000/343145]\n",
      "train: 0.25490125417709353 test: 0.25139335956838393 [340000/343145]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2548501874719347 [10000/343145]\n",
      "train: 0.25766850014527637 [70000/343145]\n",
      "train: 0.25913987308740616 [130000/343145]\n",
      "train: 0.2573263694842656 [190000/343145]\n",
      "train: 0.25569503009319305 [250000/343145]\n",
      "train: 0.26551036536693573 [310000/343145]\n",
      "train: 0.2557932535807292 test: 0.251716994576984 [340000/343145]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25743263959884644 [30000/343145]\n",
      "train: 0.2564784089724223 [90000/343145]\n",
      "train: 0.25628907481829327 [150000/343145]\n",
      "train: 0.2571236789226532 [210000/343145]\n",
      "train: 0.26478127638498944 [270000/343145]\n",
      "train: 0.25402384003003436 [330000/343145]\n",
      "train: 0.2724565863609314 test: 0.2506465133693483 [340000/343145]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.26053234934806824 [50000/343145]\n",
      "train: 0.2574109807610512 [110000/343145]\n",
      "train: 0.2610787699619929 [170000/343145]\n",
      "train: 0.25486599405606586 [230000/343145]\n",
      "train: 0.2572663153211276 [290000/343145]\n",
      "train: 0.25695295333862306 test: 0.25037187337875366 [340000/343145]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2558853562389101 [10000/343145]\n",
      "train: 0.25480013340711594 [70000/343145]\n",
      "train: 0.2586582452058792 [130000/343145]\n",
      "train: 0.25808117787043255 [190000/343145]\n",
      "train: 0.2574305534362793 [250000/343145]\n",
      "train: 0.2584504435459773 [310000/343145]\n",
      "train: 0.2551950216293335 test: 0.25232497023211586 [340000/343145]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25501517738614765 [30000/343145]\n",
      "train: 0.25531162321567535 [90000/343145]\n",
      "train: 0.2562530040740967 [150000/343145]\n",
      "train: 0.2503790631890297 [210000/343145]\n",
      "train: 0.25802915294965106 [270000/343145]\n",
      "train: 0.2588678151369095 [330000/343145]\n",
      "train: 0.36184996366500854 test: 0.25408318638801575 [340000/343145]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.27045233973434996 [50000/343145]\n",
      "train: 0.2618943552176158 [110000/343145]\n",
      "train: 0.2553989614049594 [170000/343145]\n",
      "train: 0.253904049595197 [230000/343145]\n",
      "train: 0.2593274811903636 [290000/343145]\n",
      "train: 0.25373930037021636 test: 0.24970560603671604 [340000/343145]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25411829565252575 [10000/343145]\n",
      "train: 0.25996045023202896 [70000/343145]\n",
      "train: 0.2599776089191437 [130000/343145]\n",
      "train: 0.25492100417613983 [190000/343145]\n",
      "train: 0.253143606086572 [250000/343145]\n",
      "train: 0.2526129136482875 [310000/343145]\n",
      "train: 0.2532568871974945 test: 0.2509079807334476 [340000/343145]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25856430189950125 [30000/343145]\n",
      "train: 0.2528981640934944 [90000/343145]\n",
      "train: 0.2524419203400612 [150000/343145]\n",
      "train: 0.25777847568194073 [210000/343145]\n",
      "train: 0.25235550850629807 [270000/343145]\n",
      "train: 0.2556423842906952 [330000/343145]\n",
      "train: 0.24589405953884125 test: 0.2489775319894155 [340000/343145]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2552032598427364 [50000/343145]\n",
      "train: 0.2560182462135951 [110000/343145]\n",
      "train: 0.2536412850022316 [170000/343145]\n",
      "train: 0.2612339109182358 [230000/343145]\n",
      "train: 0.2511536478996277 [290000/343145]\n",
      "train: 0.2534481108188629 test: 0.2498512003156874 [340000/343145]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2521152879510607 [10000/343145]\n",
      "train: 0.2598895827929179 [70000/343145]\n",
      "train: 0.2553221980730693 [130000/343145]\n",
      "train: 0.25698083142439526 [190000/343145]\n",
      "train: 0.2522009735306104 [250000/343145]\n",
      "train: 0.25735828280448914 [310000/343145]\n",
      "train: 0.25060152510801953 test: 0.24890484081374276 [340000/343145]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25588491346154896 [30000/343145]\n",
      "train: 0.2548281252384186 [90000/343145]\n",
      "train: 0.2510750740766525 [150000/343145]\n",
      "train: 0.25738003849983215 [210000/343145]\n",
      "train: 0.2522852619489034 [270000/343145]\n",
      "train: 0.2538604388634364 [330000/343145]\n",
      "train: 0.25243839621543884 test: 0.2492637170685662 [340000/343145]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2528479461159025 [50000/343145]\n",
      "train: 0.25386616339286167 [110000/343145]\n",
      "train: 0.2564390276869138 [170000/343145]\n",
      "train: 0.25110602130492526 [230000/343145]\n",
      "train: 0.25411440928777057 [290000/343145]\n",
      "train: 0.25770297944545745 test: 0.24911841750144958 [340000/343145]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2562146463564464 [10000/343145]\n",
      "train: 0.2563748011986415 [70000/343145]\n",
      "train: 0.25136179476976395 [130000/343145]\n",
      "train: 0.25264101723829907 [190000/343145]\n",
      "train: 0.2587531531850497 [250000/343145]\n",
      "train: 0.2542966827750206 [310000/343145]\n",
      "train: 0.2521623770395915 test: 0.24733710123433006 [340000/343145]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.254956705229623 [30000/343145]\n",
      "train: 0.25549909720818204 [90000/343145]\n",
      "train: 0.25439922014872235 [150000/343145]\n",
      "train: 0.2520911271373431 [210000/343145]\n",
      "train: 0.2509869709610939 [270000/343145]\n",
      "train: 0.2544490918517113 [330000/343145]\n",
      "train: 0.28338199853897095 test: 0.2514774153629939 [340000/343145]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25580224820545744 [50000/343145]\n",
      "train: 0.25362056742111844 [110000/343145]\n",
      "train: 0.2526538521051407 [170000/343145]\n",
      "train: 0.2581883246699969 [230000/343145]\n",
      "train: 0.25058117012182873 [290000/343145]\n",
      "train: 0.26193536520004274 test: 0.25331862767537433 [340000/343145]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25873946292059763 [10000/343145]\n",
      "train: 0.2566670700907707 [70000/343145]\n",
      "train: 0.2551001086831093 [130000/343145]\n",
      "train: 0.2527522047360738 [190000/343145]\n",
      "train: 0.2556022182106972 [250000/343145]\n",
      "train: 0.2509068126479785 [310000/343145]\n",
      "train: 0.2537961353858312 test: 0.24896453320980072 [340000/343145]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2527055782931192 [30000/343145]\n",
      "train: 0.25262972960869473 [90000/343145]\n",
      "train: 0.25222358852624893 [150000/343145]\n",
      "train: 0.2567877446611722 [210000/343145]\n",
      "train: 0.2524712880452474 [270000/343145]\n",
      "train: 0.2519497101505597 [330000/343145]\n",
      "train: 0.2485441416501999 test: 0.24907139274809095 [340000/343145]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25544079499585287 [50000/343145]\n",
      "train: 0.24988112847010294 [110000/343145]\n",
      "train: 0.2551064044237137 [170000/343145]\n",
      "train: 0.25045224527517956 [230000/343145]\n",
      "train: 0.25360457599163055 [290000/343145]\n",
      "train: 0.25027115643024445 test: 0.24745383030838436 [340000/343145]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25128766681466785 [10000/343145]\n",
      "train: 0.25712742159763974 [70000/343145]\n",
      "train: 0.24958160519599915 [130000/343145]\n",
      "train: 0.25169769674539566 [190000/343145]\n",
      "train: 0.25271834433078766 [250000/343145]\n",
      "train: 0.2530403633912404 [310000/343145]\n",
      "train: 0.25200217962265015 test: 0.24809271759457058 [340000/343145]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2529205594744001 [30000/343145]\n",
      "train: 0.256621852517128 [90000/343145]\n",
      "train: 0.249427559475104 [150000/343145]\n",
      "train: 0.2523650750517845 [210000/343145]\n",
      "train: 0.25121212005615234 [270000/343145]\n",
      "train: 0.24848259488741556 [330000/343145]\n",
      "train: 0.24742302298545837 test: 0.24661821954780155 [340000/343145]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2516149899789265 [50000/343145]\n",
      "train: 0.25374280164639157 [110000/343145]\n",
      "train: 0.24947363138198853 [170000/343145]\n",
      "train: 0.25114138176043826 [230000/343145]\n",
      "train: 0.25329118718703586 [290000/343145]\n",
      "train: 0.2515665054321289 test: 0.24800869325796762 [340000/343145]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2502556634800775 [10000/343145]\n",
      "train: 0.2512105430165927 [70000/343145]\n",
      "train: 0.25126121441523236 [130000/343145]\n",
      "train: 0.25047944486141205 [190000/343145]\n",
      "train: 0.2554389387369156 [250000/343145]\n",
      "train: 0.2510092755158742 [310000/343145]\n",
      "train: 0.254848192135493 test: 0.24912778867615593 [340000/343145]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25286145721163067 [30000/343145]\n",
      "train: 0.2515072499712308 [90000/343145]\n",
      "train: 0.24943416565656662 [150000/343145]\n",
      "train: 0.25202171752850216 [210000/343145]\n",
      "train: 0.2520295977592468 [270000/343145]\n",
      "train: 0.2510136142373085 [330000/343145]\n",
      "train: 0.25699037313461304 test: 0.24608273141913944 [340000/343145]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24950504302978516 [50000/343145]\n",
      "train: 0.2528674751520157 [110000/343145]\n",
      "train: 0.24988956252733865 [170000/343145]\n",
      "train: 0.2488930175701777 [230000/343145]\n",
      "train: 0.2563202778498332 [290000/343145]\n",
      "train: 0.251136314868927 test: 0.24571315778626335 [340000/343145]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25071197961057934 [10000/343145]\n",
      "train: 0.24925080438454947 [70000/343145]\n",
      "train: 0.2507681225736936 [130000/343145]\n",
      "train: 0.25085653613011044 [190000/343145]\n",
      "train: 0.2494459276398023 [250000/343145]\n",
      "train: 0.2543596302469571 [310000/343145]\n",
      "train: 0.24937551220258078 test: 0.24633564220534432 [340000/343145]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24902004855019705 [30000/343145]\n",
      "train: 0.24927936494350433 [90000/343145]\n",
      "train: 0.25023727615674335 [150000/343145]\n",
      "train: 0.24941546221574148 [210000/343145]\n",
      "train: 0.24918955316146216 [270000/343145]\n",
      "train: 0.255326787630717 [330000/343145]\n",
      "train: 0.2562929391860962 test: 0.24647903939088187 [340000/343145]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2510052961962564 [50000/343145]\n",
      "train: 0.25222062816222507 [110000/343145]\n",
      "train: 0.25009356439113617 [170000/343145]\n",
      "train: 0.25130103280146915 [230000/343145]\n",
      "train: 0.2502923955519994 [290000/343145]\n",
      "train: 0.24776739478111268 test: 0.24616755545139313 [340000/343145]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24909376246588572 [10000/343145]\n",
      "train: 0.2494264617562294 [70000/343145]\n",
      "train: 0.24890954792499542 [130000/343145]\n",
      "train: 0.2507023935516675 [190000/343145]\n",
      "train: 0.251472145318985 [250000/343145]\n",
      "train: 0.24958572536706924 [310000/343145]\n",
      "train: 0.24975657959779105 test: 0.2465707047118081 [340000/343145]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2503426798752376 [30000/343145]\n",
      "train: 0.2508295824130376 [90000/343145]\n",
      "train: 0.24890279273192087 [150000/343145]\n",
      "train: 0.25069082776705426 [210000/343145]\n",
      "train: 0.2502395634849866 [270000/343145]\n",
      "train: 0.24925827731688818 [330000/343145]\n",
      "train: 0.24554474651813507 test: 0.24494268165694344 [340000/343145]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25114166736602783 [50000/343145]\n",
      "train: 0.2488920936981837 [110000/343145]\n",
      "train: 0.24995864679416022 [170000/343145]\n",
      "train: 0.24976421147584915 [230000/343145]\n",
      "train: 0.24793628603219986 [290000/343145]\n",
      "train: 0.25138424038887025 test: 0.24694413443406424 [340000/343145]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2503000008208411 [10000/343145]\n",
      "train: 0.2459831659992536 [70000/343145]\n",
      "train: 0.2502635369698207 [130000/343145]\n",
      "train: 0.24906491984923682 [190000/343145]\n",
      "train: 0.2501511052250862 [250000/343145]\n",
      "train: 0.254412184158961 [310000/343145]\n",
      "train: 0.2502253403266271 test: 0.247258346941736 [340000/343145]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24990147352218628 [30000/343145]\n",
      "train: 0.2507070650657018 [90000/343145]\n",
      "train: 0.2496022234360377 [150000/343145]\n",
      "train: 0.24930166949828467 [210000/343145]\n",
      "train: 0.25047901024421054 [270000/343145]\n",
      "train: 0.24838042010863623 [330000/343145]\n",
      "train: 0.24547997117042542 test: 0.24557879236009386 [340000/343145]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24900896847248077 [50000/343145]\n",
      "train: 0.25028513620297116 [110000/343145]\n",
      "train: 0.24663331111272177 [170000/343145]\n",
      "train: 0.250366431971391 [230000/343145]\n",
      "train: 0.249399167795976 [290000/343145]\n",
      "train: 0.2477622002363205 test: 0.24452875388993156 [340000/343145]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24754612573555537 [10000/343145]\n",
      "train: 0.24809293448925018 [70000/343145]\n",
      "train: 0.24901183942953745 [130000/343145]\n",
      "train: 0.25069162746270496 [190000/343145]\n",
      "train: 0.24908684442440668 [250000/343145]\n",
      "train: 0.24823820342620215 [310000/343145]\n",
      "train: 0.2500148167212804 test: 0.24550162586900923 [340000/343145]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2481131191764559 [30000/343145]\n",
      "train: 0.2518267333507538 [90000/343145]\n",
      "train: 0.24821681280930838 [150000/343145]\n",
      "train: 0.2472090149919192 [210000/343145]\n",
      "train: 0.25036010642846424 [270000/343145]\n",
      "train: 0.2477489560842514 [330000/343145]\n",
      "train: 0.2479037493467331 test: 0.24570050007767147 [340000/343145]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2491766938141414 [50000/343145]\n",
      "train: 0.24725444118181863 [110000/343145]\n",
      "train: 0.24885748823483786 [170000/343145]\n",
      "train: 0.24799553801616034 [230000/343145]\n",
      "train: 0.24789982040723166 [290000/343145]\n",
      "train: 0.25106130838394164 test: 0.2455246564414766 [340000/343145]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.25043560351644245 [10000/343145]\n",
      "train: 0.24699850380420685 [70000/343145]\n",
      "train: 0.2496585100889206 [130000/343145]\n",
      "train: 0.24744430681069693 [190000/343145]\n",
      "train: 0.24660583337148032 [250000/343145]\n",
      "train: 0.2512268126010895 [310000/343145]\n",
      "train: 0.24694139262040457 test: 0.24595914781093597 [340000/343145]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24922543338366918 [30000/343145]\n",
      "train: 0.24986045559247336 [90000/343145]\n",
      "train: 0.24691384037335715 [150000/343145]\n",
      "train: 0.2514991834759712 [210000/343145]\n",
      "train: 0.24703722447156906 [270000/343145]\n",
      "train: 0.2474251240491867 [330000/343145]\n",
      "train: 0.23942877352237701 test: 0.24406705796718597 [340000/343145]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2499640711716243 [50000/343145]\n",
      "train: 0.2461391563216845 [110000/343145]\n",
      "train: 0.24693704893191656 [170000/343145]\n",
      "train: 0.2452912504474322 [230000/343145]\n",
      "train: 0.2473822385072708 [290000/343145]\n",
      "train: 0.2512256443500519 test: 0.24518128401703304 [340000/343145]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24896421815667832 [10000/343145]\n",
      "train: 0.24860529353221258 [70000/343145]\n",
      "train: 0.2457087536652883 [130000/343145]\n",
      "train: 0.24965093284845352 [190000/343145]\n",
      "train: 0.2492142617702484 [250000/343145]\n",
      "train: 0.25010889023542404 [310000/343145]\n",
      "train: 0.24856653809547424 test: 0.24505708118279776 [340000/343145]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24775072506495885 [30000/343145]\n",
      "train: 0.24851739158233008 [90000/343145]\n",
      "train: 0.2486876348654429 [150000/343145]\n",
      "train: 0.24718188991149267 [210000/343145]\n",
      "train: 0.24801057328780493 [270000/343145]\n",
      "train: 0.2476216976841291 [330000/343145]\n",
      "train: 0.2605822682380676 test: 0.24502016603946686 [340000/343145]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24765544065407344 [50000/343145]\n",
      "train: 0.24895119667053223 [110000/343145]\n",
      "train: 0.24766902377208075 [170000/343145]\n",
      "train: 0.24680237720410028 [230000/343145]\n",
      "train: 0.24991619090239206 [290000/343145]\n",
      "train: 0.24755237102508545 test: 0.2444730152686437 [340000/343145]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2484130093029567 [10000/343145]\n",
      "train: 0.24800088008244833 [70000/343145]\n",
      "train: 0.24647625535726547 [130000/343145]\n",
      "train: 0.24771945923566818 [190000/343145]\n",
      "train: 0.2465487321217855 [250000/343145]\n",
      "train: 0.2488007719318072 [310000/343145]\n",
      "train: 0.24734841287136078 test: 0.2450244426727295 [340000/343145]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2457180129630225 [30000/343145]\n",
      "train: 0.24969098716974258 [90000/343145]\n",
      "train: 0.24892099698384604 [150000/343145]\n",
      "train: 0.24744170904159546 [210000/343145]\n",
      "train: 0.24546144157648087 [270000/343145]\n",
      "train: 0.2496380234758059 [330000/343145]\n",
      "train: 0.24789904057979584 test: 0.24477195077472264 [340000/343145]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24788251944950648 [50000/343145]\n",
      "train: 0.2500741208593051 [110000/343145]\n",
      "train: 0.24666385352611542 [170000/343145]\n",
      "train: 0.2471193571885427 [230000/343145]\n",
      "train: 0.24728605399529138 [290000/343145]\n",
      "train: 0.24868695437908173 test: 0.24407052993774414 [340000/343145]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24915623239108495 [10000/343145]\n",
      "train: 0.24844237913688025 [70000/343145]\n",
      "train: 0.24632501105467478 [130000/343145]\n",
      "train: 0.24707027524709702 [190000/343145]\n",
      "train: 0.2488216683268547 [250000/343145]\n",
      "train: 0.24631281197071075 [310000/343145]\n",
      "train: 0.2455784479777018 test: 0.24397018055121103 [340000/343145]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24625957437923976 [30000/343145]\n",
      "train: 0.2480543628334999 [90000/343145]\n",
      "train: 0.24677189936240515 [150000/343145]\n",
      "train: 0.24771164109309515 [210000/343145]\n",
      "train: 0.2494945079088211 [270000/343145]\n",
      "train: 0.2447976147135099 [330000/343145]\n",
      "train: 0.2437109798192978 test: 0.24404161671797434 [340000/343145]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24535393289157323 [50000/343145]\n",
      "train: 0.24672299126784006 [110000/343145]\n",
      "train: 0.24707700312137604 [170000/343145]\n",
      "train: 0.2474807153145472 [230000/343145]\n",
      "train: 0.2476429045200348 [290000/343145]\n",
      "train: 0.24615540802478791 test: 0.24362066884835562 [340000/343145]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24543986788817815 [10000/343145]\n",
      "train: 0.2454041043917338 [70000/343145]\n",
      "train: 0.24674312273661295 [130000/343145]\n",
      "train: 0.2504667143026988 [190000/343145]\n",
      "train: 0.2470035875837008 [250000/343145]\n",
      "train: 0.24792810529470444 [310000/343145]\n",
      "train: 0.25307322045167285 test: 0.2437920222679774 [340000/343145]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24907368634428298 [30000/343145]\n",
      "train: 0.2480063115557035 [90000/343145]\n",
      "train: 0.2468629057208697 [150000/343145]\n",
      "train: 0.24866349498430887 [210000/343145]\n",
      "train: 0.24655652791261673 [270000/343145]\n",
      "train: 0.24699249863624573 [330000/343145]\n",
      "train: 0.24149762094020844 test: 0.24484308063983917 [340000/343145]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24611090336527144 [50000/343145]\n",
      "train: 0.24482805281877518 [110000/343145]\n",
      "train: 0.247062548995018 [170000/343145]\n",
      "train: 0.24647246797879538 [230000/343145]\n",
      "train: 0.24778171380360922 [290000/343145]\n",
      "train: 0.2495215505361557 test: 0.24478919804096222 [340000/343145]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2483771847827094 [10000/343145]\n",
      "train: 0.2464894081155459 [70000/343145]\n",
      "train: 0.24701308707396188 [130000/343145]\n",
      "train: 0.24861016124486923 [190000/343145]\n",
      "train: 0.24653037389119467 [250000/343145]\n",
      "train: 0.247133307158947 [310000/343145]\n",
      "train: 0.24629720052083334 test: 0.24425797164440155 [340000/343145]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2456422277859279 [30000/343145]\n",
      "train: 0.2456002657612165 [90000/343145]\n",
      "train: 0.2500184004505475 [150000/343145]\n",
      "train: 0.24549738566080728 [210000/343145]\n",
      "train: 0.24740186085303625 [270000/343145]\n",
      "train: 0.24769428372383118 [330000/343145]\n",
      "train: 0.24310550093650818 test: 0.24371889895863003 [340000/343145]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24528851253645761 [50000/343145]\n",
      "train: 0.24641973773638406 [110000/343145]\n",
      "train: 0.2504844094316165 [170000/343145]\n",
      "train: 0.24485463152329126 [230000/343145]\n",
      "train: 0.2464765508969625 [290000/343145]\n",
      "train: 0.24933434128761292 test: 0.2440176159143448 [340000/343145]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24856305973870413 [10000/343145]\n",
      "train: 0.24568090587854385 [70000/343145]\n",
      "train: 0.25083286811908084 [130000/343145]\n",
      "train: 0.24499018987019858 [190000/343145]\n",
      "train: 0.24591456353664398 [250000/343145]\n",
      "train: 0.2466480111082395 [310000/343145]\n",
      "train: 0.24642698963483176 test: 0.24357217053572336 [340000/343145]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24616374288286483 [30000/343145]\n",
      "train: 0.24643820772568384 [90000/343145]\n",
      "train: 0.24766820669174194 [150000/343145]\n",
      "train: 0.24517484505971274 [210000/343145]\n",
      "train: 0.24661535521348318 [270000/343145]\n",
      "train: 0.24621461580197015 [330000/343145]\n",
      "train: 0.2391257882118225 test: 0.2434631801313824 [340000/343145]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24379948420184 [50000/343145]\n",
      "train: 0.24847598373889923 [110000/343145]\n",
      "train: 0.24641713748375574 [170000/343145]\n",
      "train: 0.24577565491199493 [230000/343145]\n",
      "train: 0.2450864389538765 [290000/343145]\n",
      "train: 0.24807812869548798 test: 0.24466807146867117 [340000/343145]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2476036697626114 [10000/343145]\n",
      "train: 0.24774640798568726 [70000/343145]\n",
      "train: 0.24601969619592032 [130000/343145]\n",
      "train: 0.2441364973783493 [190000/343145]\n",
      "train: 0.24661302318175635 [250000/343145]\n",
      "train: 0.24639678994814554 [310000/343145]\n",
      "train: 0.24558816850185394 test: 0.24352936943372092 [340000/343145]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24479619094303676 [30000/343145]\n",
      "train: 0.24878312150637308 [90000/343145]\n",
      "train: 0.2453096235791842 [150000/343145]\n",
      "train: 0.24670295168956122 [210000/343145]\n",
      "train: 0.24657829602559408 [270000/343145]\n",
      "train: 0.24459832906723022 [330000/343145]\n",
      "train: 0.24310706555843353 test: 0.2441067331367069 [340000/343145]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24842787640435354 [50000/343145]\n",
      "train: 0.245279960334301 [110000/343145]\n",
      "train: 0.24615770081679025 [170000/343145]\n",
      "train: 0.24561073134342828 [230000/343145]\n",
      "train: 0.2444548433025678 [290000/343145]\n",
      "train: 0.2479637771844864 test: 0.24274137285020617 [340000/343145]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24709983382906234 [10000/343145]\n",
      "train: 0.24579909443855286 [70000/343145]\n",
      "train: 0.24570203324158987 [130000/343145]\n",
      "train: 0.2457250952720642 [190000/343145]\n",
      "train: 0.24660869936148325 [250000/343145]\n",
      "train: 0.2475100060304006 [310000/343145]\n",
      "train: 0.24985856314500174 test: 0.24426070352395376 [340000/343145]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24802440192018235 [30000/343145]\n",
      "train: 0.24571621666351953 [90000/343145]\n",
      "train: 0.2456868663430214 [150000/343145]\n",
      "train: 0.24554783602555594 [210000/343145]\n",
      "train: 0.24641451239585876 [270000/343145]\n",
      "train: 0.24547950675090155 [330000/343145]\n",
      "train: 0.24636128544807434 test: 0.24477374222543505 [340000/343145]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24647419154644012 [50000/343145]\n",
      "train: 0.24841978897651038 [110000/343145]\n",
      "train: 0.2459861213962237 [170000/343145]\n",
      "train: 0.24451415737469992 [230000/343145]\n",
      "train: 0.24441146850585938 [290000/343145]\n",
      "train: 0.24700204133987427 test: 0.24365967015425363 [340000/343145]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24646858445235661 [10000/343145]\n",
      "train: 0.24626131107409796 [70000/343145]\n",
      "train: 0.24678082515796027 [130000/343145]\n",
      "train: 0.24334674825270972 [190000/343145]\n",
      "train: 0.24539805203676224 [250000/343145]\n",
      "train: 0.24595795075098673 [310000/343145]\n",
      "train: 0.24953822294871011 test: 0.24442804025279152 [340000/343145]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24731110036373138 [30000/343145]\n",
      "train: 0.24655243754386902 [90000/343145]\n",
      "train: 0.24571473399798074 [150000/343145]\n",
      "train: 0.24717592199643454 [210000/343145]\n",
      "train: 0.24742228786150613 [270000/343145]\n",
      "train: 0.24348162611325583 [330000/343145]\n",
      "train: 0.24611295759677887 test: 0.2429205940829383 [340000/343145]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24680387122290476 [50000/343145]\n",
      "train: 0.24634157369534174 [110000/343145]\n",
      "train: 0.2460512121518453 [170000/343145]\n",
      "train: 0.2460412159562111 [230000/343145]\n",
      "train: 0.2443846936027209 [290000/343145]\n",
      "train: 0.24490283131599427 test: 0.2441463073094686 [340000/343145]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24516212940216064 [10000/343145]\n",
      "train: 0.24557431787252426 [70000/343145]\n",
      "train: 0.24468146016200384 [130000/343145]\n",
      "train: 0.2452403282125791 [190000/343145]\n",
      "train: 0.2442862167954445 [250000/343145]\n",
      "train: 0.24612392236789069 [310000/343145]\n",
      "train: 0.25013340016206104 test: 0.24354196091492972 [340000/343145]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24681324618203299 [30000/343145]\n",
      "train: 0.24549892048041025 [90000/343145]\n",
      "train: 0.24565173933903375 [150000/343145]\n",
      "train: 0.24454335868358612 [210000/343145]\n",
      "train: 0.24623596171538034 [270000/343145]\n",
      "train: 0.24642842759688696 [330000/343145]\n",
      "train: 0.2423999011516571 test: 0.2427621003654268 [340000/343145]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24526575420584 [50000/343145]\n",
      "train: 0.24625554432471594 [110000/343145]\n",
      "train: 0.24576890716950098 [170000/343145]\n",
      "train: 0.24460667868455252 [230000/343145]\n",
      "train: 0.24630741526683173 [290000/343145]\n",
      "train: 0.24325833320617676 test: 0.24397742913828957 [340000/343145]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24347434512206487 [10000/343145]\n",
      "train: 0.24704239765803018 [70000/343145]\n",
      "train: 0.24373928954203924 [130000/343145]\n",
      "train: 0.24576299637556076 [190000/343145]\n",
      "train: 0.24497643609841666 [250000/343145]\n",
      "train: 0.24676107615232468 [310000/343145]\n",
      "train: 0.2444000095129013 test: 0.2437884079085456 [340000/343145]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24529870067323958 [30000/343145]\n",
      "train: 0.24474201599756876 [90000/343145]\n",
      "train: 0.2451536605755488 [150000/343145]\n",
      "train: 0.24531085540850958 [210000/343145]\n",
      "train: 0.2454780861735344 [270000/343145]\n",
      "train: 0.24669713775316873 [330000/343145]\n",
      "train: 0.2421278953552246 test: 0.2437937872277366 [340000/343145]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24438187905720302 [50000/343145]\n",
      "train: 0.2444311504562696 [110000/343145]\n",
      "train: 0.2451375350356102 [170000/343145]\n",
      "train: 0.24603501707315445 [230000/343145]\n",
      "train: 0.24587828914324442 [290000/343145]\n",
      "train: 0.24500433802604676 test: 0.24289983676539528 [340000/343145]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24600621632167272 [10000/343145]\n",
      "train: 0.24641522268454233 [70000/343145]\n",
      "train: 0.24461689094702402 [130000/343145]\n",
      "train: 0.24339738488197327 [190000/343145]\n",
      "train: 0.24568921575943628 [250000/343145]\n",
      "train: 0.24385292331377664 [310000/343145]\n",
      "train: 0.24421248336633047 test: 0.243482596344418 [340000/343145]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24511714705399104 [30000/343145]\n",
      "train: 0.24302233507235846 [90000/343145]\n",
      "train: 0.24494804938634238 [150000/343145]\n",
      "train: 0.24849320451418558 [210000/343145]\n",
      "train: 0.2447869082291921 [270000/343145]\n",
      "train: 0.24508164823055267 [330000/343145]\n",
      "train: 0.24397419393062592 test: 0.24326640201939476 [340000/343145]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24456717286791121 [50000/343145]\n",
      "train: 0.24626684188842773 [110000/343145]\n",
      "train: 0.24327266464630762 [170000/343145]\n",
      "train: 0.2458860178788503 [230000/343145]\n",
      "train: 0.24547483026981354 [290000/343145]\n",
      "train: 0.24424941539764405 test: 0.2437935537762112 [340000/343145]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24476178841931479 [10000/343145]\n",
      "train: 0.24619237581888834 [70000/343145]\n",
      "train: 0.24389363825321198 [130000/343145]\n",
      "train: 0.24417992681264877 [190000/343145]\n",
      "train: 0.2446815843383471 [250000/343145]\n",
      "train: 0.24429540584484735 [310000/343145]\n",
      "train: 0.24711563189824423 test: 0.2439745846721861 [340000/343145]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24666019422667368 [30000/343145]\n",
      "train: 0.2446145365635554 [90000/343145]\n",
      "train: 0.24542479465405145 [150000/343145]\n",
      "train: 0.2440700406829516 [210000/343145]\n",
      "train: 0.24351989726225534 [270000/343145]\n",
      "train: 0.24610153088967004 [330000/343145]\n",
      "train: 0.24383117258548737 test: 0.24260305364926657 [340000/343145]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24357123247214726 [50000/343145]\n",
      "train: 0.24373612056175867 [110000/343145]\n",
      "train: 0.24583086371421814 [170000/343145]\n",
      "train: 0.24763829509417215 [230000/343145]\n",
      "train: 0.24412469565868378 [290000/343145]\n",
      "train: 0.2465079665184021 test: 0.2429351823197471 [340000/343145]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24602273532322474 [10000/343145]\n",
      "train: 0.24425727625687918 [70000/343145]\n",
      "train: 0.24452699224154154 [130000/343145]\n",
      "train: 0.2469018946091334 [190000/343145]\n",
      "train: 0.2432430535554886 [250000/343145]\n",
      "train: 0.24611431856950125 [310000/343145]\n",
      "train: 0.2445287803808848 test: 0.24337957468297747 [340000/343145]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24340409253324782 [30000/343145]\n",
      "train: 0.2460703949133555 [90000/343145]\n",
      "train: 0.2469578062494596 [150000/343145]\n",
      "train: 0.2453367238243421 [210000/343145]\n",
      "train: 0.2421876589457194 [270000/343145]\n",
      "train: 0.24474918097257614 [330000/343145]\n",
      "train: 0.2517092227935791 test: 0.24419079389837053 [340000/343145]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24401275174958365 [50000/343145]\n",
      "train: 0.24368638545274734 [110000/343145]\n",
      "train: 0.2473179449637731 [170000/343145]\n",
      "train: 0.24506706496079764 [230000/343145]\n",
      "train: 0.24496241907278696 [290000/343145]\n",
      "train: 0.24549564123153686 test: 0.2446127798822191 [340000/343145]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24564406062875474 [10000/343145]\n",
      "train: 0.24621311326821646 [70000/343145]\n",
      "train: 0.24538986633221307 [130000/343145]\n",
      "train: 0.24386442452669144 [190000/343145]\n",
      "train: 0.2441631779074669 [250000/343145]\n",
      "train: 0.2449055885275205 [310000/343145]\n",
      "train: 0.2425648421049118 test: 0.24248183435863918 [340000/343145]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24375710317066737 [30000/343145]\n",
      "train: 0.24473165720701218 [90000/343145]\n",
      "train: 0.2454415038228035 [150000/343145]\n",
      "train: 0.24518017719189325 [210000/343145]\n",
      "train: 0.24329056590795517 [270000/343145]\n",
      "train: 0.245477594435215 [330000/343145]\n",
      "train: 0.23679915070533752 test: 0.24359586172633702 [340000/343145]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24495106296879904 [50000/343145]\n",
      "train: 0.24600152919689813 [110000/343145]\n",
      "train: 0.24220392107963562 [170000/343145]\n",
      "train: 0.24546676377455393 [230000/343145]\n",
      "train: 0.24612481892108917 [290000/343145]\n",
      "train: 0.24177007973194123 test: 0.24325709210501778 [340000/343145]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2433035671710968 [10000/343145]\n",
      "train: 0.2441355586051941 [70000/343145]\n",
      "train: 0.24768990526596704 [130000/343145]\n",
      "train: 0.24310201406478882 [190000/343145]\n",
      "train: 0.24440471827983856 [250000/343145]\n",
      "train: 0.24403927475214005 [310000/343145]\n",
      "train: 0.2436468650897344 test: 0.243659978111585 [340000/343145]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24373296328953334 [30000/343145]\n",
      "train: 0.24380414684613547 [90000/343145]\n",
      "train: 0.2433604747056961 [150000/343145]\n",
      "train: 0.24522730459769568 [210000/343145]\n",
      "train: 0.24511374284823736 [270000/343145]\n",
      "train: 0.24641696363687515 [330000/343145]\n",
      "train: 0.2521076798439026 test: 0.2429554263750712 [340000/343145]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24619659994329726 [50000/343145]\n",
      "train: 0.2441726898153623 [110000/343145]\n",
      "train: 0.2432605723539988 [170000/343145]\n",
      "train: 0.24428799003362656 [230000/343145]\n",
      "train: 0.24592600762844086 [290000/343145]\n",
      "train: 0.2437025338411331 test: 0.24227390852239397 [340000/343145]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24393655785492488 [10000/343145]\n",
      "train: 0.24383333573738733 [70000/343145]\n",
      "train: 0.2446658412615458 [130000/343145]\n",
      "train: 0.2440334434310595 [190000/343145]\n",
      "train: 0.24254562457402548 [250000/343145]\n",
      "train: 0.24595983574787775 [310000/343145]\n",
      "train: 0.24574322501818338 test: 0.2429521315627628 [340000/343145]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2455674899475915 [30000/343145]\n",
      "train: 0.2438237468401591 [90000/343145]\n",
      "train: 0.24367270370324454 [150000/343145]\n",
      "train: 0.24426363656918207 [210000/343145]\n",
      "train: 0.24529383579889932 [270000/343145]\n",
      "train: 0.2445571149388949 [330000/343145]\n",
      "train: 0.2441016435623169 test: 0.2435082561439938 [340000/343145]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24393394802297866 [50000/343145]\n",
      "train: 0.24472767114639282 [110000/343145]\n",
      "train: 0.24528013666470846 [170000/343145]\n",
      "train: 0.24517753223578134 [230000/343145]\n",
      "train: 0.2429974153637886 [290000/343145]\n",
      "train: 0.2448619544506073 test: 0.24262217183907828 [340000/343145]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24580599154744828 [10000/343145]\n",
      "train: 0.24526223788658777 [70000/343145]\n",
      "train: 0.24375238021214804 [130000/343145]\n",
      "train: 0.24463672439257303 [190000/343145]\n",
      "train: 0.24351720760265985 [250000/343145]\n",
      "train: 0.24307371179262796 [310000/343145]\n",
      "train: 0.24177023271719614 test: 0.24353606171078152 [340000/343145]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24392423459461757 [30000/343145]\n",
      "train: 0.24396590143442154 [90000/343145]\n",
      "train: 0.24546177685260773 [150000/343145]\n",
      "train: 0.24394984543323517 [210000/343145]\n",
      "train: 0.24231759210427603 [270000/343145]\n",
      "train: 0.2448726842800776 [330000/343145]\n",
      "train: 0.23962289094924927 test: 0.2428810993830363 [340000/343145]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2437768897839955 [50000/343145]\n",
      "train: 0.2435899277528127 [110000/343145]\n",
      "train: 0.2453092858195305 [170000/343145]\n",
      "train: 0.24477279682954153 [230000/343145]\n",
      "train: 0.2440626174211502 [290000/343145]\n",
      "train: 0.24510749578475952 test: 0.24274122880564797 [340000/343145]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24470190490995133 [10000/343145]\n",
      "train: 0.24323822806278864 [70000/343145]\n",
      "train: 0.24434376507997513 [130000/343145]\n",
      "train: 0.2455879251162211 [190000/343145]\n",
      "train: 0.2421911656856537 [250000/343145]\n",
      "train: 0.24545132865508398 [310000/343145]\n",
      "train: 0.24558545152346292 test: 0.24329856203662026 [340000/343145]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24535711109638214 [30000/343145]\n",
      "train: 0.24405216425657272 [90000/343145]\n",
      "train: 0.24453924347956976 [150000/343145]\n",
      "train: 0.2435705785950025 [210000/343145]\n",
      "train: 0.2441362589597702 [270000/343145]\n",
      "train: 0.24277330438296 [330000/343145]\n",
      "train: 0.23869585990905762 test: 0.24249267246988085 [340000/343145]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24438542340482985 [50000/343145]\n",
      "train: 0.24386932949225107 [110000/343145]\n",
      "train: 0.243923249344031 [170000/343145]\n",
      "train: 0.2443788026769956 [230000/343145]\n",
      "train: 0.2442433387041092 [290000/343145]\n",
      "train: 0.24319811463356017 test: 0.2431104431549708 [340000/343145]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2424964223589216 [10000/343145]\n",
      "train: 0.24422873556613922 [70000/343145]\n",
      "train: 0.24447929114103317 [130000/343145]\n",
      "train: 0.24402514845132828 [190000/343145]\n",
      "train: 0.244846872985363 [250000/343145]\n",
      "train: 0.2431895931561788 [310000/343145]\n",
      "train: 0.24576261639595032 test: 0.24435820016596052 [340000/343145]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2456182667187282 [30000/343145]\n",
      "train: 0.24369887510935465 [90000/343145]\n",
      "train: 0.24463089058796564 [150000/343145]\n",
      "train: 0.24491086105505624 [210000/343145]\n",
      "train: 0.2439789672692617 [270000/343145]\n",
      "train: 0.24222592264413834 [330000/343145]\n",
      "train: 0.24665594100952148 test: 0.24404274258348677 [340000/343145]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24286956659385137 [50000/343145]\n",
      "train: 0.24268134435017905 [110000/343145]\n",
      "train: 0.24374185502529144 [170000/343145]\n",
      "train: 0.24608343094587326 [230000/343145]\n",
      "train: 0.24421193699042001 [290000/343145]\n",
      "train: 0.24537345468997956 test: 0.2435573803053962 [340000/343145]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24524987595421927 [10000/343145]\n",
      "train: 0.24493884295225143 [70000/343145]\n",
      "train: 0.2424143006404241 [130000/343145]\n",
      "train: 0.24370106309652328 [190000/343145]\n",
      "train: 0.243795578678449 [250000/343145]\n",
      "train: 0.24411660432815552 [310000/343145]\n",
      "train: 0.24239560465017954 test: 0.2437158011727863 [340000/343145]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2430206494671958 [30000/343145]\n",
      "train: 0.24341151614983877 [90000/343145]\n",
      "train: 0.2455876817305883 [150000/343145]\n",
      "train: 0.24511434137821198 [210000/343145]\n",
      "train: 0.24383835991223654 [270000/343145]\n",
      "train: 0.24153786649306616 [330000/343145]\n",
      "train: 0.24107277393341064 test: 0.24213318030039468 [340000/343145]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24292371315615519 [50000/343145]\n",
      "train: 0.24301155159870783 [110000/343145]\n",
      "train: 0.24563719580570856 [170000/343145]\n",
      "train: 0.2433794910709063 [230000/343145]\n",
      "train: 0.24367592483758926 [290000/343145]\n",
      "train: 0.24314663410186768 test: 0.24236512018574607 [340000/343145]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24257150718144008 [10000/343145]\n",
      "train: 0.2435597206155459 [70000/343145]\n",
      "train: 0.24326386054356894 [130000/343145]\n",
      "train: 0.24397018303473791 [190000/343145]\n",
      "train: 0.24403092016776404 [250000/343145]\n",
      "train: 0.245241679251194 [310000/343145]\n",
      "train: 0.24069691697756448 test: 0.24195406172010633 [340000/343145]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2443786689213344 [30000/343145]\n",
      "train: 0.24368240435918173 [90000/343145]\n",
      "train: 0.24421328802903494 [150000/343145]\n",
      "train: 0.244516891737779 [210000/343145]\n",
      "train: 0.24273241311311722 [270000/343145]\n",
      "train: 0.24272391448418298 [330000/343145]\n",
      "train: 0.2448984533548355 test: 0.24201952086554634 [340000/343145]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2451354456799371 [50000/343145]\n",
      "train: 0.24346385399500528 [110000/343145]\n",
      "train: 0.24270935356616974 [170000/343145]\n",
      "train: 0.24260842551787695 [230000/343145]\n",
      "train: 0.24450178196032843 [290000/343145]\n",
      "train: 0.24423129856586456 test: 0.24343056811226738 [340000/343145]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2437653797013419 [10000/343145]\n",
      "train: 0.24183561156193414 [70000/343145]\n",
      "train: 0.2464067687590917 [130000/343145]\n",
      "train: 0.24322903901338577 [190000/343145]\n",
      "train: 0.24536331494649252 [250000/343145]\n",
      "train: 0.2420604998866717 [310000/343145]\n",
      "train: 0.24386166036128998 test: 0.2431586335102717 [340000/343145]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24325899354049138 [30000/343145]\n",
      "train: 0.24526903281609216 [90000/343145]\n",
      "train: 0.24280309428771338 [150000/343145]\n",
      "train: 0.2433840980132421 [210000/343145]\n",
      "train: 0.24352892488241196 [270000/343145]\n",
      "train: 0.24329116692145666 [330000/343145]\n",
      "train: 0.2360469251871109 test: 0.2420453412665261 [340000/343145]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24279730021953583 [50000/343145]\n",
      "train: 0.24432647228240967 [110000/343145]\n",
      "train: 0.24443713575601578 [170000/343145]\n",
      "train: 0.24174461513757706 [230000/343145]\n",
      "train: 0.2428737829128901 [290000/343145]\n",
      "train: 0.24559175372123718 test: 0.24318276014592913 [340000/343145]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24452001282146998 [10000/343145]\n",
      "train: 0.2431048353513082 [70000/343145]\n",
      "train: 0.24298849950234094 [130000/343145]\n",
      "train: 0.24308017641305923 [190000/343145]\n",
      "train: 0.2458870659271876 [250000/343145]\n",
      "train: 0.2433121750752131 [310000/343145]\n",
      "train: 0.24245619773864746 test: 0.24360467493534088 [340000/343145]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24281142226287297 [30000/343145]\n",
      "train: 0.24364601572354636 [90000/343145]\n",
      "train: 0.2425659423073133 [150000/343145]\n",
      "train: 0.24294185638427734 [210000/343145]\n",
      "train: 0.24385138601064682 [270000/343145]\n",
      "train: 0.2449778119723002 [330000/343145]\n",
      "train: 0.24709118902683258 test: 0.24337482452392578 [340000/343145]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24429278714316233 [50000/343145]\n",
      "train: 0.2430990586678187 [110000/343145]\n",
      "train: 0.2421659156680107 [170000/343145]\n",
      "train: 0.24273513505856195 [230000/343145]\n",
      "train: 0.24362704157829285 [290000/343145]\n",
      "train: 0.24483015835285188 test: 0.24305586516857147 [340000/343145]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24478780158928462 [10000/343145]\n",
      "train: 0.24430806189775467 [70000/343145]\n",
      "train: 0.24426982551813126 [130000/343145]\n",
      "train: 0.24258711685736975 [190000/343145]\n",
      "train: 0.2429629291097323 [250000/343145]\n",
      "train: 0.24344315379858017 [310000/343145]\n",
      "train: 0.24095230797926584 test: 0.24327762093808916 [340000/343145]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.242970272898674 [30000/343145]\n",
      "train: 0.24456605315208435 [90000/343145]\n",
      "train: 0.24499009052912393 [150000/343145]\n",
      "train: 0.2440489505728086 [210000/343145]\n",
      "train: 0.24203354368607202 [270000/343145]\n",
      "train: 0.24192729592323303 [330000/343145]\n",
      "train: 0.2346411794424057 test: 0.24335363507270813 [340000/343145]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24197478805269515 [50000/343145]\n",
      "train: 0.24582773447036743 [110000/343145]\n",
      "train: 0.2428951933979988 [170000/343145]\n",
      "train: 0.24270493040482202 [230000/343145]\n",
      "train: 0.24187789112329483 [290000/343145]\n",
      "train: 0.2433325707912445 test: 0.24311616354518467 [340000/343145]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24354274570941925 [10000/343145]\n",
      "train: 0.24456710368394852 [70000/343145]\n",
      "train: 0.24449720482031503 [130000/343145]\n",
      "train: 0.24329695602258047 [190000/343145]\n",
      "train: 0.24344433595736822 [250000/343145]\n",
      "train: 0.241653710603714 [310000/343145]\n",
      "train: 0.24270757039388022 test: 0.24228796859582266 [340000/343145]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24338748625346593 [30000/343145]\n",
      "train: 0.24254397054513296 [90000/343145]\n",
      "train: 0.2427226354678472 [150000/343145]\n",
      "train: 0.24223320931196213 [210000/343145]\n",
      "train: 0.24397211521863937 [270000/343145]\n",
      "train: 0.2436176265279452 [330000/343145]\n",
      "train: 0.23898470401763916 test: 0.24328582651085323 [340000/343145]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24382479275975907 [50000/343145]\n",
      "train: 0.24341153105099997 [110000/343145]\n",
      "train: 0.24420386056105295 [170000/343145]\n",
      "train: 0.2436831295490265 [230000/343145]\n",
      "train: 0.24177473038434982 [290000/343145]\n",
      "train: 0.24272024035453796 test: 0.24262688557306925 [340000/343145]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24302171809332712 [10000/343145]\n",
      "train: 0.24411322176456451 [70000/343145]\n",
      "train: 0.24356244504451752 [130000/343145]\n",
      "train: 0.24327165881792703 [190000/343145]\n",
      "train: 0.24342164397239685 [250000/343145]\n",
      "train: 0.24213446180025736 [310000/343145]\n",
      "train: 0.24226349095503488 test: 0.2440529531902737 [340000/343145]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2420515183891569 [30000/343145]\n",
      "train: 0.2445719912648201 [90000/343145]\n",
      "train: 0.24353077014287314 [150000/343145]\n",
      "train: 0.24268759290377298 [210000/343145]\n",
      "train: 0.24337011078993478 [270000/343145]\n",
      "train: 0.2427455261349678 [330000/343145]\n",
      "train: 0.23803575336933136 test: 0.24360619485378265 [340000/343145]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2422128873211997 [50000/343145]\n",
      "train: 0.24338995665311813 [110000/343145]\n",
      "train: 0.24275297919909158 [170000/343145]\n",
      "train: 0.24312189718087515 [230000/343145]\n",
      "train: 0.2421592871348063 [290000/343145]\n",
      "train: 0.24304034411907197 test: 0.242609860168563 [340000/343145]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24263882849897658 [10000/343145]\n",
      "train: 0.2438162292043368 [70000/343145]\n",
      "train: 0.24247523645559946 [130000/343145]\n",
      "train: 0.2426098013917605 [190000/343145]\n",
      "train: 0.2431773046652476 [250000/343145]\n",
      "train: 0.24363566686709723 [310000/343145]\n",
      "train: 0.24224684139092764 test: 0.24190897080633375 [340000/343145]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24337215508733476 [30000/343145]\n",
      "train: 0.2423184116681417 [90000/343145]\n",
      "train: 0.24342629065116247 [150000/343145]\n",
      "train: 0.24312962591648102 [210000/343145]\n",
      "train: 0.2426305959622065 [270000/343145]\n",
      "train: 0.24322494119405746 [330000/343145]\n",
      "train: 0.24364224076271057 test: 0.24226686855157217 [340000/343145]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2433468805892127 [50000/343145]\n",
      "train: 0.24280638992786407 [110000/343145]\n",
      "train: 0.24327262242635092 [170000/343145]\n",
      "train: 0.24306118736664453 [230000/343145]\n",
      "train: 0.24314145743846893 [290000/343145]\n",
      "train: 0.24442377984523772 test: 0.2422107756137848 [340000/343145]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24438714342457907 [10000/343145]\n",
      "train: 0.24457853535811105 [70000/343145]\n",
      "train: 0.24274950722853342 [130000/343145]\n",
      "train: 0.24330556144316992 [190000/343145]\n",
      "train: 0.24223098903894424 [250000/343145]\n",
      "train: 0.24220651388168335 [310000/343145]\n",
      "train: 0.24270594120025635 test: 0.24275212321016523 [340000/343145]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24298241095883505 [30000/343145]\n",
      "train: 0.2428565596540769 [90000/343145]\n",
      "train: 0.24145193894704184 [150000/343145]\n",
      "train: 0.24402612944444022 [210000/343145]\n",
      "train: 0.24204297115405402 [270000/343145]\n",
      "train: 0.2434579779704412 [330000/343145]\n",
      "train: 0.24464452266693115 test: 0.2417235705587599 [340000/343145]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.24370778884206498 [50000/343145]\n",
      "train: 0.2414947673678398 [110000/343145]\n",
      "train: 0.2425559163093567 [170000/343145]\n",
      "train: 0.24428730954726538 [230000/343145]\n",
      "train: 0.24351120988527933 [290000/343145]\n",
      "train: 0.24160752296447754 test: 0.24175529347525704 [340000/343145]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2415769100189209 [10000/343145]\n",
      "train: 0.24328515926996866 [70000/343145]\n",
      "train: 0.24209115157524744 [130000/343145]\n",
      "train: 0.24362082531054816 [190000/343145]\n",
      "train: 0.2424556463956833 [250000/343145]\n",
      "train: 0.24360674619674683 [310000/343145]\n",
      "train: 0.24468791484832764 test: 0.24339886009693146 [340000/343145]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_10000 ----------\n",
      "train: 0.2437161590371813 [30000/343145]\n",
      "train: 0.24380957335233688 [90000/343145]\n",
      "train: 0.24338611215353012 [150000/343145]\n",
      "train: 0.2433019826809565 [210000/343145]\n",
      "train: 0.24288460115591684 [270000/343145]\n",
      "train: 0.24100183695554733 [330000/343145]\n",
      "train: 0.2408490628004074 test: 0.24265184998512268 [340000/343145]\n",
      "DEVICE: cuda:0\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.44340689357981755 [68480/343145]\n",
      "train: 0.2622746083496222 [137088/343145]\n",
      "train: 0.25502994008807106 [205696/343145]\n",
      "train: 0.2531454618742217 [274304/343145]\n",
      "train: 0.250723312622798 [342912/343145]\n",
      "train: 0.2404753565788269 test: 0.255904715857989 [343040/343145]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24853426420599833 [68480/343145]\n",
      "train: 0.25057156083743964 [137088/343145]\n",
      "train: 0.24976279469790744 [205696/343145]\n",
      "train: 0.24855548691060117 [274304/343145]\n",
      "train: 0.24736667571783955 [342912/343145]\n",
      "train: 0.2543865740299225 test: 0.2535852999738716 [343040/343145]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24942065722671522 [68480/343145]\n",
      "train: 0.24613364974954235 [137088/343145]\n",
      "train: 0.24634443729448674 [205696/343145]\n",
      "train: 0.24664854158216448 [274304/343145]\n",
      "train: 0.24828038200624844 [342912/343145]\n",
      "train: 0.2782421112060547 test: 0.2569488467074009 [343040/343145]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24662194152673086 [68480/343145]\n",
      "train: 0.24726933991508698 [137088/343145]\n",
      "train: 0.24570074891532534 [205696/343145]\n",
      "train: 0.24657934929119119 [274304/343145]\n",
      "train: 0.24712994110895625 [342912/343145]\n",
      "train: 0.24176202714443207 test: 0.24980563491627286 [343040/343145]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24626841511251318 [68480/343145]\n",
      "train: 0.24806487112681366 [137088/343145]\n",
      "train: 0.24492124162280737 [205696/343145]\n",
      "train: 0.24574527836668847 [274304/343145]\n",
      "train: 0.24597518209979605 [342912/343145]\n",
      "train: 0.24132613837718964 test: 0.24582682534408284 [343040/343145]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24697629286035258 [68480/343145]\n",
      "train: 0.24434369699612482 [137088/343145]\n",
      "train: 0.2454467331017576 [205696/343145]\n",
      "train: 0.24584677509629904 [274304/343145]\n",
      "train: 0.24663030100402547 [342912/343145]\n",
      "train: 0.26560458540916443 test: 0.25529107551372177 [343040/343145]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24477037196385795 [68480/343145]\n",
      "train: 0.24439122608459707 [137088/343145]\n",
      "train: 0.24498860916094994 [205696/343145]\n",
      "train: 0.24781413837822516 [274304/343145]\n",
      "train: 0.2456116386369538 [342912/343145]\n",
      "train: 0.24417759478092194 test: 0.24852176292642572 [343040/343145]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24610460215218685 [68480/343145]\n",
      "train: 0.24538126857534273 [137088/343145]\n",
      "train: 0.24312992527413724 [205696/343145]\n",
      "train: 0.24512719969028857 [274304/343145]\n",
      "train: 0.2450394189791448 [342912/343145]\n",
      "train: 0.2796988785266876 test: 0.2464874981057271 [343040/343145]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24764022755556267 [68480/343145]\n",
      "train: 0.24348887386940307 [137088/343145]\n",
      "train: 0.24424219570720374 [205696/343145]\n",
      "train: 0.24592353701035477 [274304/343145]\n",
      "train: 0.24309087997830625 [342912/343145]\n",
      "train: 0.24524065852165222 test: 0.24775982715866782 [343040/343145]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24419203897317251 [68480/343145]\n",
      "train: 0.24546397407886697 [137088/343145]\n",
      "train: 0.2453196071533125 [205696/343145]\n",
      "train: 0.24490304402451016 [274304/343145]\n",
      "train: 0.24333132002780686 [342912/343145]\n",
      "train: 0.2382851392030716 test: 0.24822975501928884 [343040/343145]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24486934503252503 [68480/343145]\n",
      "train: 0.24340805019349304 [137088/343145]\n",
      "train: 0.2460187866783409 [205696/343145]\n",
      "train: 0.24464627296955727 [274304/343145]\n",
      "train: 0.2440609770979899 [342912/343145]\n",
      "train: 0.2773328125476837 test: 0.24870967449711973 [343040/343145]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24677855456230582 [68480/343145]\n",
      "train: 0.24490665866812664 [137088/343145]\n",
      "train: 0.24344190012719205 [205696/343145]\n",
      "train: 0.2428718314075203 [274304/343145]\n",
      "train: 0.24371192593183091 [342912/343145]\n",
      "train: 0.2365817278623581 test: 0.24903838964936986 [343040/343145]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24427438389988584 [68480/343145]\n",
      "train: 0.24435259821588423 [137088/343145]\n",
      "train: 0.24435547013669762 [205696/343145]\n",
      "train: 0.24454138578096432 [274304/343145]\n",
      "train: 0.24307807849080704 [342912/343145]\n",
      "train: 0.2117987424135208 test: 0.24438965729203202 [343040/343145]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2436152380271997 [68480/343145]\n",
      "train: 0.2437364975852308 [137088/343145]\n",
      "train: 0.24488743205568683 [205696/343145]\n",
      "train: 0.24461287282296082 [274304/343145]\n",
      "train: 0.242938771093292 [342912/343145]\n",
      "train: 0.22152754664421082 test: 0.24671051885527398 [343040/343145]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24522857809199966 [68480/343145]\n",
      "train: 0.2447122332097879 [137088/343145]\n",
      "train: 0.24223793548212122 [205696/343145]\n",
      "train: 0.24252413374496928 [274304/343145]\n",
      "train: 0.24355884118756252 [342912/343145]\n",
      "train: 0.2565770149230957 test: 0.24713619681833043 [343040/343145]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24550841729290215 [68480/343145]\n",
      "train: 0.24409626390951783 [137088/343145]\n",
      "train: 0.2423158754219315 [205696/343145]\n",
      "train: 0.24262551740923924 [274304/343145]\n",
      "train: 0.24222308358372147 [342912/343145]\n",
      "train: 0.24359184503555298 test: 0.24733253349668044 [343040/343145]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2446455615858792 [68480/343145]\n",
      "train: 0.24267616642833645 [137088/343145]\n",
      "train: 0.24397598304299276 [205696/343145]\n",
      "train: 0.2421187960556639 [274304/343145]\n",
      "train: 0.24360674597434143 [342912/343145]\n",
      "train: 0.25511977076530457 test: 0.24475459461329413 [343040/343145]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24350572453752797 [68480/343145]\n",
      "train: 0.2424527447003482 [137088/343145]\n",
      "train: 0.2427845808830279 [205696/343145]\n",
      "train: 0.24485919835852155 [274304/343145]\n",
      "train: 0.24202114004474967 [342912/343145]\n",
      "train: 0.24908800423145294 test: 0.24727480699781512 [343040/343145]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24451776767354216 [68480/343145]\n",
      "train: 0.2413831253383142 [137088/343145]\n",
      "train: 0.2432655783564742 [205696/343145]\n",
      "train: 0.24126125994458128 [274304/343145]\n",
      "train: 0.24369231808875033 [342912/343145]\n",
      "train: 0.25457531213760376 test: 0.2460464776317338 [343040/343145]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24315143655465302 [68480/343145]\n",
      "train: 0.2422314567852821 [137088/343145]\n",
      "train: 0.24192324945174937 [205696/343145]\n",
      "train: 0.2423610825147202 [274304/343145]\n",
      "train: 0.24390339192503424 [342912/343145]\n",
      "train: 0.22386105358600616 test: 0.24495527046092755 [343040/343145]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24150715088489114 [68480/343145]\n",
      "train: 0.24324729340845969 [137088/343145]\n",
      "train: 0.243638020981826 [205696/343145]\n",
      "train: 0.24264731283174523 [274304/343145]\n",
      "train: 0.24247467237065978 [342912/343145]\n",
      "train: 0.22987812757492065 test: 0.244894836636485 [343040/343145]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24218857288360596 [68480/343145]\n",
      "train: 0.24285147500349513 [137088/343145]\n",
      "train: 0.24294764662522877 [205696/343145]\n",
      "train: 0.24208000613682307 [274304/343145]\n",
      "train: 0.24311904998412773 [342912/343145]\n",
      "train: 0.2915707528591156 test: 0.24210758562770224 [343040/343145]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24191757742475087 [68480/343145]\n",
      "train: 0.24367240949797986 [137088/343145]\n",
      "train: 0.23997333042545996 [205696/343145]\n",
      "train: 0.2444837823676974 [274304/343145]\n",
      "train: 0.24160927236636184 [342912/343145]\n",
      "train: 0.26707252860069275 test: 0.24631328165708818 [343040/343145]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2404965149790215 [68480/343145]\n",
      "train: 0.24472282857481223 [137088/343145]\n",
      "train: 0.2417978909867468 [205696/343145]\n",
      "train: 0.24196201954870972 [274304/343145]\n",
      "train: 0.2426757006002451 [342912/343145]\n",
      "train: 0.28848186135292053 test: 0.2415333832163036 [343040/343145]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2407561667693616 [68480/343145]\n",
      "train: 0.24134526952211535 [137088/343145]\n",
      "train: 0.2425365422421427 [205696/343145]\n",
      "train: 0.24326463683105226 [274304/343145]\n",
      "train: 0.2437145400569955 [342912/343145]\n",
      "train: 0.22907862067222595 test: 0.24232858916863956 [343040/343145]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24183831812061188 [68480/343145]\n",
      "train: 0.24162693738714972 [137088/343145]\n",
      "train: 0.24120812268177075 [205696/343145]\n",
      "train: 0.24040655285787227 [274304/343145]\n",
      "train: 0.24465267001581725 [342912/343145]\n",
      "train: 0.21746933460235596 test: 0.24915610515858128 [343040/343145]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2425070989953295 [68480/343145]\n",
      "train: 0.24062806543018392 [137088/343145]\n",
      "train: 0.24190499441725993 [205696/343145]\n",
      "train: 0.24215100602761133 [274304/343145]\n",
      "train: 0.241675812389646 [342912/343145]\n",
      "train: 0.24287541210651398 test: 0.2439275995985051 [343040/343145]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.240572643540869 [68480/343145]\n",
      "train: 0.2432293230528707 [137088/343145]\n",
      "train: 0.24242479807294126 [205696/343145]\n",
      "train: 0.24159149244538883 [274304/343145]\n",
      "train: 0.23993817252565675 [342912/343145]\n",
      "train: 0.267945796251297 test: 0.24482871816339508 [343040/343145]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24241504913934783 [68480/343145]\n",
      "train: 0.24234198414678895 [137088/343145]\n",
      "train: 0.24019561908138332 [205696/343145]\n",
      "train: 0.24075124571238882 [274304/343145]\n",
      "train: 0.2411687433886439 [342912/343145]\n",
      "train: 0.2599984407424927 test: 0.24630686052243508 [343040/343145]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2410777124057713 [68480/343145]\n",
      "train: 0.2409860147580282 [137088/343145]\n",
      "train: 0.24238067064712296 [205696/343145]\n",
      "train: 0.24102607302701295 [274304/343145]\n",
      "train: 0.2399627492387793 [342912/343145]\n",
      "train: 0.21292656660079956 test: 0.24342139664865287 [343040/343145]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24006185568244764 [68480/343145]\n",
      "train: 0.24029420385721015 [137088/343145]\n",
      "train: 0.2411894316771137 [205696/343145]\n",
      "train: 0.24166623464048798 [274304/343145]\n",
      "train: 0.2413913344046963 [342912/343145]\n",
      "train: 0.23161309957504272 test: 0.2451612060187293 [343040/343145]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24027068180411887 [68480/343145]\n",
      "train: 0.24019327106426902 [137088/343145]\n",
      "train: 0.24177604035210254 [205696/343145]\n",
      "train: 0.2423249524253518 [274304/343145]\n",
      "train: 0.24005981195551246 [342912/343145]\n",
      "train: 0.23147445917129517 test: 0.24333652016747015 [343040/343145]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2405696041757168 [68480/343145]\n",
      "train: 0.2394961250751321 [137088/343145]\n",
      "train: 0.24064337089657784 [205696/343145]\n",
      "train: 0.24140965335293493 [274304/343145]\n",
      "train: 0.24158097472764664 [342912/343145]\n",
      "train: 0.24558863043785095 test: 0.2425490789193155 [343040/343145]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23916240422197338 [68480/343145]\n",
      "train: 0.24037250420495646 [137088/343145]\n",
      "train: 0.2407084256132592 [205696/343145]\n",
      "train: 0.24165384396354653 [274304/343145]\n",
      "train: 0.23979948119107466 [342912/343145]\n",
      "train: 0.2161065638065338 test: 0.24104959256780484 [343040/343145]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2403506079699074 [68480/343145]\n",
      "train: 0.24195301188017004 [137088/343145]\n",
      "train: 0.23925675485116332 [205696/343145]\n",
      "train: 0.2405117500795802 [274304/343145]\n",
      "train: 0.24027891643345356 [342912/343145]\n",
      "train: 0.2315850406885147 test: 0.24277840687958566 [343040/343145]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24259722116273208 [68480/343145]\n",
      "train: 0.23882319491857024 [137088/343145]\n",
      "train: 0.23921426393981302 [205696/343145]\n",
      "train: 0.241307549206401 [274304/343145]\n",
      "train: 0.23764780569654792 [342912/343145]\n",
      "train: 0.2579540014266968 test: 0.2425084241767221 [343040/343145]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2398016077346642 [68480/343145]\n",
      "train: 0.239906052683494 [137088/343145]\n",
      "train: 0.2400191998137022 [205696/343145]\n",
      "train: 0.23898757048952046 [274304/343145]\n",
      "train: 0.2407839028025741 [342912/343145]\n",
      "train: 0.2651914656162262 test: 0.24233076726981673 [343040/343145]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.24126269225745672 [68480/343145]\n",
      "train: 0.23952058285697184 [137088/343145]\n",
      "train: 0.23918024255935824 [205696/343145]\n",
      "train: 0.2394895456842522 [274304/343145]\n",
      "train: 0.23942206494176566 [342912/343145]\n",
      "train: 0.22111976146697998 test: 0.24425803855527886 [343040/343145]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2383583085940981 [68480/343145]\n",
      "train: 0.24124051455352732 [137088/343145]\n",
      "train: 0.2389036402551096 [205696/343145]\n",
      "train: 0.24092070302411692 [274304/343145]\n",
      "train: 0.2389980587107477 [342912/343145]\n",
      "train: 0.20841024816036224 test: 0.24036293966493025 [343040/343145]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23834146462117273 [68480/343145]\n",
      "train: 0.23964462582188756 [137088/343145]\n",
      "train: 0.238220635523547 [205696/343145]\n",
      "train: 0.23982131964902378 [274304/343145]\n",
      "train: 0.24074836047505266 [342912/343145]\n",
      "train: 0.23632624745368958 test: 0.240618974636635 [343040/343145]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2393602666686145 [68480/343145]\n",
      "train: 0.23840347293819955 [137088/343145]\n",
      "train: 0.2384218461255529 [205696/343145]\n",
      "train: 0.23941290734419182 [274304/343145]\n",
      "train: 0.23916150946448098 [342912/343145]\n",
      "train: 0.21864193677902222 test: 0.24086198079692625 [343040/343145]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23799254882602053 [68480/343145]\n",
      "train: 0.23796876806265382 [137088/343145]\n",
      "train: 0.2377607290313315 [205696/343145]\n",
      "train: 0.23898139646026625 [274304/343145]\n",
      "train: 0.24017323439579402 [342912/343145]\n",
      "train: 0.22522760927677155 test: 0.24096033867620675 [343040/343145]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23808923926988348 [68480/343145]\n",
      "train: 0.2377737710780617 [137088/343145]\n",
      "train: 0.23888752412106565 [205696/343145]\n",
      "train: 0.23763798041018977 [274304/343145]\n",
      "train: 0.2402319271784665 [342912/343145]\n",
      "train: 0.2392224818468094 test: 0.24311088094412836 [343040/343145]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23883430640346734 [68480/343145]\n",
      "train: 0.23730868017717974 [137088/343145]\n",
      "train: 0.2384439028187919 [205696/343145]\n",
      "train: 0.2380788084675572 [274304/343145]\n",
      "train: 0.23842029965746758 [342912/343145]\n",
      "train: 0.223630890250206 test: 0.2398586537017197 [343040/343145]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2376458994780617 [68480/343145]\n",
      "train: 0.23881735246795327 [137088/343145]\n",
      "train: 0.23720669248766862 [205696/343145]\n",
      "train: 0.2386750624751422 [274304/343145]\n",
      "train: 0.23781274247970155 [342912/343145]\n",
      "train: 0.23027408123016357 test: 0.24178819043003855 [343040/343145]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23813568688304732 [68480/343145]\n",
      "train: 0.23881141410501144 [137088/343145]\n",
      "train: 0.23747826045128836 [205696/343145]\n",
      "train: 0.23815667779365582 [274304/343145]\n",
      "train: 0.2371555651579775 [342912/343145]\n",
      "train: 0.25972577929496765 test: 0.24078914589746875 [343040/343145]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23793715149774675 [68480/343145]\n",
      "train: 0.23887227914893805 [137088/343145]\n",
      "train: 0.23586664646307923 [205696/343145]\n",
      "train: 0.23818836330589074 [274304/343145]\n",
      "train: 0.23754965299879438 [342912/343145]\n",
      "train: 0.21909232437610626 test: 0.24002545363590366 [343040/343145]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23699702866361572 [68480/343145]\n",
      "train: 0.23751184602837955 [137088/343145]\n",
      "train: 0.23772931237941358 [205696/343145]\n",
      "train: 0.2374773023844655 [274304/343145]\n",
      "train: 0.23757039497036542 [342912/343145]\n",
      "train: 0.23597672581672668 test: 0.2403706841603832 [343040/343145]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23760152986928737 [68480/343145]\n",
      "train: 0.23710113202235591 [137088/343145]\n",
      "train: 0.23585078245334662 [205696/343145]\n",
      "train: 0.23716395640217547 [274304/343145]\n",
      "train: 0.23737294490991243 [342912/343145]\n",
      "train: 0.23841744661331177 test: 0.2403002144149803 [343040/343145]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23683652034795927 [68480/343145]\n",
      "train: 0.23622850653951738 [137088/343145]\n",
      "train: 0.2359075458414519 [205696/343145]\n",
      "train: 0.23753274966086915 [274304/343145]\n",
      "train: 0.23775400618897446 [342912/343145]\n",
      "train: 0.22627434134483337 test: 0.24143993827873833 [343040/343145]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23682176628370302 [68480/343145]\n",
      "train: 0.23634071475756702 [137088/343145]\n",
      "train: 0.23728037483767786 [205696/343145]\n",
      "train: 0.23707178207253343 [274304/343145]\n",
      "train: 0.23634436431882985 [342912/343145]\n",
      "train: 0.23894931375980377 test: 0.24242134629880618 [343040/343145]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2362683156238144 [68480/343145]\n",
      "train: 0.2366964192921991 [137088/343145]\n",
      "train: 0.23652554000380324 [205696/343145]\n",
      "train: 0.23715672653112838 [274304/343145]\n",
      "train: 0.2356382114951735 [342912/343145]\n",
      "train: 0.2564612030982971 test: 0.2415423385698998 [343040/343145]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23608215000598345 [68480/343145]\n",
      "train: 0.23654717982593756 [137088/343145]\n",
      "train: 0.23655759568201074 [205696/343145]\n",
      "train: 0.235304622424405 [274304/343145]\n",
      "train: 0.2355669052131585 [342912/343145]\n",
      "train: 0.24668405950069427 test: 0.24067698501261442 [343040/343145]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23664506717656134 [68480/343145]\n",
      "train: 0.2357235788298187 [137088/343145]\n",
      "train: 0.23545746452439187 [205696/343145]\n",
      "train: 0.23607491593418725 [274304/343145]\n",
      "train: 0.2360283705447592 [342912/343145]\n",
      "train: 0.21077202260494232 test: 0.24022125855821078 [343040/343145]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23513293110902528 [68480/343145]\n",
      "train: 0.23540321604084613 [137088/343145]\n",
      "train: 0.23600355646948315 [205696/343145]\n",
      "train: 0.23582564174795329 [274304/343145]\n",
      "train: 0.2353851650633029 [342912/343145]\n",
      "train: 0.24816210567951202 test: 0.23998657399691342 [343040/343145]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23554509761613174 [68480/343145]\n",
      "train: 0.23569248394290013 [137088/343145]\n",
      "train: 0.23501427844166756 [205696/343145]\n",
      "train: 0.23583639357517014 [274304/343145]\n",
      "train: 0.23402655188605856 [342912/343145]\n",
      "train: 0.21949215233325958 test: 0.24014467171958234 [343040/343145]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23448005021728394 [68480/343145]\n",
      "train: 0.23446793045236994 [137088/343145]\n",
      "train: 0.23548245377171395 [205696/343145]\n",
      "train: 0.23502852053228598 [274304/343145]\n",
      "train: 0.2355488748637153 [342912/343145]\n",
      "train: 0.21607160568237305 test: 0.24001974598039635 [343040/343145]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23382012898473545 [68480/343145]\n",
      "train: 0.23385674678790036 [137088/343145]\n",
      "train: 0.2335843361302543 [205696/343145]\n",
      "train: 0.23664637118466755 [274304/343145]\n",
      "train: 0.2356833648492596 [342912/343145]\n",
      "train: 0.21505206823349 test: 0.23984961789073603 [343040/343145]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2343237709455206 [68480/343145]\n",
      "train: 0.23433329523610535 [137088/343145]\n",
      "train: 0.2344794149941473 [205696/343145]\n",
      "train: 0.23448708586728395 [274304/343145]\n",
      "train: 0.23583729840370257 [342912/343145]\n",
      "train: 0.19571711122989655 test: 0.24122436273559905 [343040/343145]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23464259277730903 [68480/343145]\n",
      "train: 0.2344382940444039 [137088/343145]\n",
      "train: 0.23370047010926168 [205696/343145]\n",
      "train: 0.23360969874062645 [274304/343145]\n",
      "train: 0.23523850052325584 [342912/343145]\n",
      "train: 0.21357227861881256 test: 0.24217432264332978 [343040/343145]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23385530133043145 [68480/343145]\n",
      "train: 0.23365763091106914 [137088/343145]\n",
      "train: 0.23434272330643527 [205696/343145]\n",
      "train: 0.2347878846826393 [274304/343145]\n",
      "train: 0.23476382675789184 [342912/343145]\n",
      "train: 0.22991983592510223 test: 0.24052365062044914 [343040/343145]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23276084525514137 [68480/343145]\n",
      "train: 0.23438157358053904 [137088/343145]\n",
      "train: 0.2342812825383535 [205696/343145]\n",
      "train: 0.23408098179680198 [274304/343145]\n",
      "train: 0.23400921724847892 [342912/343145]\n",
      "train: 0.26466017961502075 test: 0.240581386624079 [343040/343145]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2338677390827147 [68480/343145]\n",
      "train: 0.23389596539313223 [137088/343145]\n",
      "train: 0.23299378765496745 [205696/343145]\n",
      "train: 0.2332925647775184 [274304/343145]\n",
      "train: 0.23314851258339278 [342912/343145]\n",
      "train: 0.2116362303495407 test: 0.2401917152184488 [343040/343145]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23321913732163732 [68480/343145]\n",
      "train: 0.2326424503281935 [137088/343145]\n",
      "train: 0.23452547815308641 [205696/343145]\n",
      "train: 0.23322119658340268 [274304/343145]\n",
      "train: 0.23309330047288937 [342912/343145]\n",
      "train: 0.21988485753536224 test: 0.24019030844667807 [343040/343145]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23294968586727227 [68480/343145]\n",
      "train: 0.2329349839754069 [137088/343145]\n",
      "train: 0.23305787204472878 [205696/343145]\n",
      "train: 0.23285531391625974 [274304/343145]\n",
      "train: 0.23278633038054652 [342912/343145]\n",
      "train: 0.2461167424917221 test: 0.24014664720049914 [343040/343145]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2330701433025037 [68480/343145]\n",
      "train: 0.23257508426348664 [137088/343145]\n",
      "train: 0.23217520170580985 [205696/343145]\n",
      "train: 0.23267020059944088 [274304/343145]\n",
      "train: 0.2338228016924947 [342912/343145]\n",
      "train: 0.23528988659381866 test: 0.24088317959745667 [343040/343145]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23338219628875703 [68480/343145]\n",
      "train: 0.23312897721666898 [137088/343145]\n",
      "train: 0.23183840029497646 [205696/343145]\n",
      "train: 0.23204168638409073 [274304/343145]\n",
      "train: 0.23194552204613364 [342912/343145]\n",
      "train: 0.24089385569095612 test: 0.24035686494341196 [343040/343145]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.232458106410348 [68480/343145]\n",
      "train: 0.23094189080840616 [137088/343145]\n",
      "train: 0.23194942231387344 [205696/343145]\n",
      "train: 0.23235802980723666 [274304/343145]\n",
      "train: 0.2338381837775458 [342912/343145]\n",
      "train: 0.23849987983703613 test: 0.2411173970262269 [343040/343145]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23269397098036895 [68480/343145]\n",
      "train: 0.2314028611490086 [137088/343145]\n",
      "train: 0.23154101117666978 [205696/343145]\n",
      "train: 0.23269379072224916 [274304/343145]\n",
      "train: 0.23270284965523144 [342912/343145]\n",
      "train: 0.21303194761276245 test: 0.24041024967472885 [343040/343145]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23129342843256406 [68480/343145]\n",
      "train: 0.23209964178168951 [137088/343145]\n",
      "train: 0.2318064306598546 [205696/343145]\n",
      "train: 0.23370785925036935 [274304/343145]\n",
      "train: 0.2310409789988354 [342912/343145]\n",
      "train: 0.216427281498909 test: 0.24186414688958852 [343040/343145]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23207595947179493 [68480/343145]\n",
      "train: 0.23179919486726397 [137088/343145]\n",
      "train: 0.23194304584011213 [205696/343145]\n",
      "train: 0.23174838521587315 [274304/343145]\n",
      "train: 0.23067361210931592 [342912/343145]\n",
      "train: 0.21848569810390472 test: 0.24097942730797742 [343040/343145]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2315354614728434 [68480/343145]\n",
      "train: 0.2305648837850165 [137088/343145]\n",
      "train: 0.23181290079408617 [205696/343145]\n",
      "train: 0.23138988348863906 [274304/343145]\n",
      "train: 0.23208354088241484 [342912/343145]\n",
      "train: 0.2191995233297348 test: 0.24139280106467034 [343040/343145]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2314482056284306 [68480/343145]\n",
      "train: 0.22996170927228324 [137088/343145]\n",
      "train: 0.23212167526136585 [205696/343145]\n",
      "train: 0.23107651509900592 [274304/343145]\n",
      "train: 0.23181901507969224 [342912/343145]\n",
      "train: 0.21134890615940094 test: 0.2411340661180357 [343040/343145]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2310826397974398 [68480/343145]\n",
      "train: 0.2303970318788023 [137088/343145]\n",
      "train: 0.23075656203636483 [205696/343145]\n",
      "train: 0.23123595988683737 [274304/343145]\n",
      "train: 0.23198057099509595 [342912/343145]\n",
      "train: 0.21903307735919952 test: 0.2414349912930885 [343040/343145]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2304224895809394 [68480/343145]\n",
      "train: 0.23202430851646325 [137088/343145]\n",
      "train: 0.23102876877606804 [205696/343145]\n",
      "train: 0.2314766703534927 [274304/343145]\n",
      "train: 0.22957779911916648 [342912/343145]\n",
      "train: 0.2424330860376358 test: 0.24144316594575804 [343040/343145]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.23115479016548207 [68480/343145]\n",
      "train: 0.23005779696378245 [137088/343145]\n",
      "train: 0.23099799343009494 [205696/343145]\n",
      "train: 0.22968481703480678 [274304/343145]\n",
      "train: 0.2313176946742321 [342912/343145]\n",
      "train: 0.23226577043533325 test: 0.24079809796437066 [343040/343145]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22999166479434824 [68480/343145]\n",
      "train: 0.22981761824061622 [137088/343145]\n",
      "train: 0.23052241397437764 [205696/343145]\n",
      "train: 0.2316386730257255 [274304/343145]\n",
      "train: 0.23025364729005898 [342912/343145]\n",
      "train: 0.21910694241523743 test: 0.24149290388991332 [343040/343145]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22986515601698024 [68480/343145]\n",
      "train: 0.23007735512705882 [137088/343145]\n",
      "train: 0.2293556281156949 [205696/343145]\n",
      "train: 0.23049158005238468 [274304/343145]\n",
      "train: 0.23152684534329976 [342912/343145]\n",
      "train: 0.22350230813026428 test: 0.2413499454583212 [343040/343145]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22979730478656138 [68480/343145]\n",
      "train: 0.2303644809871912 [137088/343145]\n",
      "train: 0.2297552393943961 [205696/343145]\n",
      "train: 0.23031297684716645 [274304/343145]\n",
      "train: 0.23039567092461372 [342912/343145]\n",
      "train: 0.2192130833864212 test: 0.24169084258743975 [343040/343145]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22953384776133176 [68480/343145]\n",
      "train: 0.2304113562316147 [137088/343145]\n",
      "train: 0.22870633626050912 [205696/343145]\n",
      "train: 0.2300786660956358 [274304/343145]\n",
      "train: 0.23020561064468392 [342912/343145]\n",
      "train: 0.22318848967552185 test: 0.24076360222035478 [343040/343145]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2286961134696584 [68480/343145]\n",
      "train: 0.22899742938800535 [137088/343145]\n",
      "train: 0.2285164226013333 [205696/343145]\n",
      "train: 0.23043624931640588 [274304/343145]\n",
      "train: 0.2305636334775099 [342912/343145]\n",
      "train: 0.2639550268650055 test: 0.24188928865729076 [343040/343145]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22862776672706925 [68480/343145]\n",
      "train: 0.23020949626146858 [137088/343145]\n",
      "train: 0.22937319055199623 [205696/343145]\n",
      "train: 0.22943734380402672 [274304/343145]\n",
      "train: 0.22970350217352162 [342912/343145]\n",
      "train: 0.23006775975227356 test: 0.24302575256447856 [343040/343145]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2289334873857889 [68480/343145]\n",
      "train: 0.2296988642427014 [137088/343145]\n",
      "train: 0.22851313911934398 [205696/343145]\n",
      "train: 0.22978078282035108 [274304/343145]\n",
      "train: 0.2287711029622092 [342912/343145]\n",
      "train: 0.19410011172294617 test: 0.242546164243303 [343040/343145]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22802545918321698 [68480/343145]\n",
      "train: 0.2296070099822176 [137088/343145]\n",
      "train: 0.22959030372326944 [205696/343145]\n",
      "train: 0.23003919419846428 [274304/343145]\n",
      "train: 0.22844996625807748 [342912/343145]\n",
      "train: 0.2174692004919052 test: 0.24160304841003902 [343040/343145]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22853900728056994 [68480/343145]\n",
      "train: 0.22864434729093935 [137088/343145]\n",
      "train: 0.22931991642646826 [205696/343145]\n",
      "train: 0.22870769676988695 [274304/343145]\n",
      "train: 0.22932550783700018 [342912/343145]\n",
      "train: 0.230973020195961 test: 0.24116927625170054 [343040/343145]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22899851774592195 [68480/343145]\n",
      "train: 0.22946339017197268 [137088/343145]\n",
      "train: 0.2287134004951413 [205696/343145]\n",
      "train: 0.22765696098777785 [274304/343145]\n",
      "train: 0.22885463492416624 [342912/343145]\n",
      "train: 0.23956657946109772 test: 0.24119371522201333 [343040/343145]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2300817023275951 [68480/343145]\n",
      "train: 0.22759887695646108 [137088/343145]\n",
      "train: 0.2290976866801728 [205696/343145]\n",
      "train: 0.22855347875894896 [274304/343145]\n",
      "train: 0.2284513621577131 [342912/343145]\n",
      "train: 0.23497667908668518 test: 0.24431409017250896 [343040/343145]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22830126455376268 [68480/343145]\n",
      "train: 0.22764926795750412 [137088/343145]\n",
      "train: 0.2285285288217797 [205696/343145]\n",
      "train: 0.2284354871667143 [274304/343145]\n",
      "train: 0.2299042216210223 [342912/343145]\n",
      "train: 0.1983688771724701 test: 0.24152276090911176 [343040/343145]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22863852045389527 [68480/343145]\n",
      "train: 0.22856384980033584 [137088/343145]\n",
      "train: 0.22816725814742828 [205696/343145]\n",
      "train: 0.22846954643948755 [274304/343145]\n",
      "train: 0.22742974249395861 [342912/343145]\n",
      "train: 0.24620676040649414 test: 0.24219767513911167 [343040/343145]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22740074964430967 [68480/343145]\n",
      "train: 0.22862700617580273 [137088/343145]\n",
      "train: 0.22846347257606128 [205696/343145]\n",
      "train: 0.22781284356406376 [274304/343145]\n",
      "train: 0.22817576429181136 [342912/343145]\n",
      "train: 0.23249535262584686 test: 0.24339808477019412 [343040/343145]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22783666571647318 [68480/343145]\n",
      "train: 0.22879361455787472 [137088/343145]\n",
      "train: 0.2271088636688777 [205696/343145]\n",
      "train: 0.22767495405651741 [274304/343145]\n",
      "train: 0.2281904452160668 [342912/343145]\n",
      "train: 0.2229987233877182 test: 0.24169736687543672 [343040/343145]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22737719631949838 [68480/343145]\n",
      "train: 0.22691527781869048 [137088/343145]\n",
      "train: 0.22842327505350113 [205696/343145]\n",
      "train: 0.22799853677513884 [274304/343145]\n",
      "train: 0.22812097547436827 [342912/343145]\n",
      "train: 0.2330581545829773 test: 0.24182380662589778 [343040/343145]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.228300560619578 [68480/343145]\n",
      "train: 0.22735907721208104 [137088/343145]\n",
      "train: 0.22742868476171993 [205696/343145]\n",
      "train: 0.22832146086799565 [274304/343145]\n",
      "train: 0.226527659361487 [342912/343145]\n",
      "train: 0.21419350802898407 test: 0.24170583164549797 [343040/343145]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2268396798292352 [68480/343145]\n",
      "train: 0.22692779243103603 [137088/343145]\n",
      "train: 0.22851868112807844 [205696/343145]\n",
      "train: 0.22755010704051204 [274304/343145]\n",
      "train: 0.2278859812988719 [342912/343145]\n",
      "train: 0.20748628675937653 test: 0.24256980956577864 [343040/343145]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22679273667615218 [68480/343145]\n",
      "train: 0.2278110248717799 [137088/343145]\n",
      "train: 0.22738708883746347 [205696/343145]\n",
      "train: 0.2270424030165174 [274304/343145]\n",
      "train: 0.2275964528489024 [342912/343145]\n",
      "train: 0.22588923573493958 test: 0.24164968065018091 [343040/343145]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22675506637416074 [68480/343145]\n",
      "train: 0.22655758898316034 [137088/343145]\n",
      "train: 0.22741689427352663 [205696/343145]\n",
      "train: 0.22671612382713538 [274304/343145]\n",
      "train: 0.22796272066658113 [342912/343145]\n",
      "train: 0.23792529106140137 test: 0.24254024457380774 [343040/343145]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22688636175414037 [68480/343145]\n",
      "train: 0.22680420673160412 [137088/343145]\n",
      "train: 0.22715821976203526 [205696/343145]\n",
      "train: 0.22750944780436025 [274304/343145]\n",
      "train: 0.2272344284704817 [342912/343145]\n",
      "train: 0.21535830199718475 test: 0.24241517395358506 [343040/343145]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22809609862346222 [68480/343145]\n",
      "train: 0.22528445414865195 [137088/343145]\n",
      "train: 0.2269740742978765 [205696/343145]\n",
      "train: 0.22706692932701822 [274304/343145]\n",
      "train: 0.2267187616384741 [342912/343145]\n",
      "train: 0.23170106112957 test: 0.24225922974850844 [343040/343145]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2268553809358199 [68480/343145]\n",
      "train: 0.226267708632261 [137088/343145]\n",
      "train: 0.22658411021441666 [205696/343145]\n",
      "train: 0.22693495663689145 [274304/343145]\n",
      "train: 0.22753456993890342 [342912/343145]\n",
      "train: 0.21860291063785553 test: 0.24289421586183785 [343040/343145]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2263900102350299 [68480/343145]\n",
      "train: 0.2266713093076624 [137088/343145]\n",
      "train: 0.22598584402185767 [205696/343145]\n",
      "train: 0.22625017188378235 [274304/343145]\n",
      "train: 0.2275494580893819 [342912/343145]\n",
      "train: 0.2439228743314743 test: 0.2428407080127301 [343040/343145]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22626165510111904 [68480/343145]\n",
      "train: 0.22677121556072094 [137088/343145]\n",
      "train: 0.22636336460709572 [205696/343145]\n",
      "train: 0.2255034646325147 [274304/343145]\n",
      "train: 0.22720083335775937 [342912/343145]\n",
      "train: 0.22689343988895416 test: 0.2421902034170759 [343040/343145]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22502019923714509 [68480/343145]\n",
      "train: 0.22655387297828697 [137088/343145]\n",
      "train: 0.22792631604555827 [205696/343145]\n",
      "train: 0.22648283733583208 [274304/343145]\n",
      "train: 0.22613744254210102 [342912/343145]\n",
      "train: 0.21321192383766174 test: 0.2421937947079606 [343040/343145]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2260414186580665 [68480/343145]\n",
      "train: 0.22640085412161565 [137088/343145]\n",
      "train: 0.22584691590893624 [205696/343145]\n",
      "train: 0.22628312738640094 [274304/343145]\n",
      "train: 0.22721045200170867 [342912/343145]\n",
      "train: 0.23433834314346313 test: 0.24240757840312185 [343040/343145]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22599363163307837 [68480/343145]\n",
      "train: 0.22749671087002576 [137088/343145]\n",
      "train: 0.2250493173834993 [205696/343145]\n",
      "train: 0.2260708295976493 [274304/343145]\n",
      "train: 0.22587433296130666 [342912/343145]\n",
      "train: 0.24022069573402405 test: 0.24215869372363594 [343040/343145]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22607896048263465 [68480/343145]\n",
      "train: 0.22565185273093963 [137088/343145]\n",
      "train: 0.2255438542577313 [205696/343145]\n",
      "train: 0.22660420657093847 [274304/343145]\n",
      "train: 0.22627452224381825 [342912/343145]\n",
      "train: 0.23727479577064514 test: 0.24204934700413006 [343040/343145]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22525962324226811 [68480/343145]\n",
      "train: 0.2262858803759315 [137088/343145]\n",
      "train: 0.22600660956840016 [205696/343145]\n",
      "train: 0.2259093251412929 [274304/343145]\n",
      "train: 0.22602562926042435 [342912/343145]\n",
      "train: 0.2148510366678238 test: 0.24241923926128894 [343040/343145]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2255629073252669 [68480/343145]\n",
      "train: 0.225516929138285 [137088/343145]\n",
      "train: 0.2254346693907656 [205696/343145]\n",
      "train: 0.2254810221771251 [274304/343145]\n",
      "train: 0.226041181958211 [342912/343145]\n",
      "train: 0.26433059573173523 test: 0.24220226831656455 [343040/343145]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22527200261085836 [68480/343145]\n",
      "train: 0.22531200141937874 [137088/343145]\n",
      "train: 0.2252445843126347 [205696/343145]\n",
      "train: 0.22537588303102485 [274304/343145]\n",
      "train: 0.22659402235007997 [342912/343145]\n",
      "train: 0.215381920337677 test: 0.242676169524072 [343040/343145]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22358040919517005 [68480/343145]\n",
      "train: 0.2261325046976111 [137088/343145]\n",
      "train: 0.22542781405039689 [205696/343145]\n",
      "train: 0.2258672155161847 [274304/343145]\n",
      "train: 0.22617061805925262 [342912/343145]\n",
      "train: 0.2004280537366867 test: 0.24265727283080538 [343040/343145]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22521319333290477 [68480/343145]\n",
      "train: 0.22527594783746485 [137088/343145]\n",
      "train: 0.22468153998922946 [205696/343145]\n",
      "train: 0.22542433065376175 [274304/343145]\n",
      "train: 0.2254009486189974 [342912/343145]\n",
      "train: 0.22804176807403564 test: 0.24279233040468526 [343040/343145]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22404955410757543 [68480/343145]\n",
      "train: 0.22519940154543563 [137088/343145]\n",
      "train: 0.22539096011488297 [205696/343145]\n",
      "train: 0.22591273550555777 [274304/343145]\n",
      "train: 0.22610539075598787 [342912/343145]\n",
      "train: 0.21133291721343994 test: 0.24288591811358484 [343040/343145]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22470972025194647 [68480/343145]\n",
      "train: 0.22529879343042622 [137088/343145]\n",
      "train: 0.22395873581295583 [205696/343145]\n",
      "train: 0.22572841525856238 [274304/343145]\n",
      "train: 0.2268431121066435 [342912/343145]\n",
      "train: 0.24190932512283325 test: 0.2435074258046072 [343040/343145]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22468427983520195 [68480/343145]\n",
      "train: 0.2249590858761499 [137088/343145]\n",
      "train: 0.22522151206077926 [205696/343145]\n",
      "train: 0.2250601744918681 [274304/343145]\n",
      "train: 0.2242797733242832 [342912/343145]\n",
      "train: 0.19817696511745453 test: 0.24224794968052166 [343040/343145]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22464219590361115 [68480/343145]\n",
      "train: 0.22468044767295248 [137088/343145]\n",
      "train: 0.22427586732960458 [205696/343145]\n",
      "train: 0.22497075557041524 [274304/343145]\n",
      "train: 0.22498169749864003 [342912/343145]\n",
      "train: 0.21799997985363007 test: 0.24355445111561816 [343040/343145]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22468709607142087 [68480/343145]\n",
      "train: 0.22420237010428265 [137088/343145]\n",
      "train: 0.22469372318974182 [205696/343145]\n",
      "train: 0.22501444049290756 [274304/343145]\n",
      "train: 0.22410696155544538 [342912/343145]\n",
      "train: 0.20813652873039246 test: 0.24335793524580812 [343040/343145]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22360091050132916 [68480/343145]\n",
      "train: 0.22402334330019666 [137088/343145]\n",
      "train: 0.22441270249659445 [205696/343145]\n",
      "train: 0.2259961490366441 [274304/343145]\n",
      "train: 0.22511838782411903 [342912/343145]\n",
      "train: 0.21013565361499786 test: 0.24256348978567052 [343040/343145]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22436265825004328 [68480/343145]\n",
      "train: 0.22455858903478332 [137088/343145]\n",
      "train: 0.22316130459197422 [205696/343145]\n",
      "train: 0.22484805290378743 [274304/343145]\n",
      "train: 0.22596306136962194 [342912/343145]\n",
      "train: 0.23603996634483337 test: 0.24305933565123425 [343040/343145]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22352828498881178 [68480/343145]\n",
      "train: 0.22437276154645344 [137088/343145]\n",
      "train: 0.22359521089316303 [205696/343145]\n",
      "train: 0.2243837683892517 [274304/343145]\n",
      "train: 0.22532344200829071 [342912/343145]\n",
      "train: 0.2437404841184616 test: 0.24302631074732 [343040/343145]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22322982003013958 [68480/343145]\n",
      "train: 0.22399712790415358 [137088/343145]\n",
      "train: 0.2251128864321691 [205696/343145]\n",
      "train: 0.2250624546475375 [274304/343145]\n",
      "train: 0.22454110385655468 [342912/343145]\n",
      "train: 0.23914960026741028 test: 0.24299715970116828 [343040/343145]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22257134787308216 [68480/343145]\n",
      "train: 0.22454878493253863 [137088/343145]\n",
      "train: 0.22391925349053163 [205696/343145]\n",
      "train: 0.22445955030175288 [274304/343145]\n",
      "train: 0.22400179519248542 [342912/343145]\n",
      "train: 0.2511157989501953 test: 0.24312630282429043 [343040/343145]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22267894843659145 [68480/343145]\n",
      "train: 0.22372118328044663 [137088/343145]\n",
      "train: 0.22389888899651036 [205696/343145]\n",
      "train: 0.2248871311712176 [274304/343145]\n",
      "train: 0.2253342288087553 [342912/343145]\n",
      "train: 0.21249686181545258 test: 0.24356609300867102 [343040/343145]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2229838762258906 [68480/343145]\n",
      "train: 0.22399756170586863 [137088/343145]\n",
      "train: 0.2236984615950887 [205696/343145]\n",
      "train: 0.2239955408748851 [274304/343145]\n",
      "train: 0.22434650878630466 [342912/343145]\n",
      "train: 0.25308698415756226 test: 0.2427331309338085 [343040/343145]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2233035097963539 [68480/343145]\n",
      "train: 0.22444902607865297 [137088/343145]\n",
      "train: 0.22343643268208896 [205696/343145]\n",
      "train: 0.22382807723288214 [274304/343145]\n",
      "train: 0.22401219386774213 [342912/343145]\n",
      "train: 0.23430323600769043 test: 0.24341893480360596 [343040/343145]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22360271864763184 [68480/343145]\n",
      "train: 0.22338360422916376 [137088/343145]\n",
      "train: 0.22502320832503375 [205696/343145]\n",
      "train: 0.22293660503381224 [274304/343145]\n",
      "train: 0.22389999109862455 [342912/343145]\n",
      "train: 0.23565733432769775 test: 0.2430274295114014 [343040/343145]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2244970218262859 [68480/343145]\n",
      "train: 0.2232809652810666 [137088/343145]\n",
      "train: 0.22296571625924821 [205696/343145]\n",
      "train: 0.22335057255269877 [274304/343145]\n",
      "train: 0.22313221863735078 [342912/343145]\n",
      "train: 0.2373199760913849 test: 0.24343777815471285 [343040/343145]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22273585405651639 [68480/343145]\n",
      "train: 0.22269451607074311 [137088/343145]\n",
      "train: 0.22270445091955698 [205696/343145]\n",
      "train: 0.22497696246006596 [274304/343145]\n",
      "train: 0.22407103824748922 [342912/343145]\n",
      "train: 0.2209988683462143 test: 0.2428160610923824 [343040/343145]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22245891358932304 [68480/343145]\n",
      "train: 0.2219016545021267 [137088/343145]\n",
      "train: 0.2234797597821079 [205696/343145]\n",
      "train: 0.2232781300849434 [274304/343145]\n",
      "train: 0.22408547611045304 [342912/343145]\n",
      "train: 0.23568479716777802 test: 0.2438742613028485 [343040/343145]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22292778378758352 [68480/343145]\n",
      "train: 0.22284771535378783 [137088/343145]\n",
      "train: 0.22270726662740778 [205696/343145]\n",
      "train: 0.22301583125520108 [274304/343145]\n",
      "train: 0.2232765247906322 [342912/343145]\n",
      "train: 0.24209734797477722 test: 0.24343266203755237 [343040/343145]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22233214158585618 [68480/343145]\n",
      "train: 0.22275044529962895 [137088/343145]\n",
      "train: 0.2233626748254495 [205696/343145]\n",
      "train: 0.22301249019801617 [274304/343145]\n",
      "train: 0.22334362010457623 [342912/343145]\n",
      "train: 0.26133790612220764 test: 0.2446145374444487 [343040/343145]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22223586917922483 [68480/343145]\n",
      "train: 0.22265431418347714 [137088/343145]\n",
      "train: 0.22281158684905786 [205696/343145]\n",
      "train: 0.22324374846335668 [274304/343145]\n",
      "train: 0.22366350630659665 [342912/343145]\n",
      "train: 0.2252529114484787 test: 0.2433898948388377 [343040/343145]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22166471727178527 [68480/343145]\n",
      "train: 0.22164762678987054 [137088/343145]\n",
      "train: 0.2233586503720995 [205696/343145]\n",
      "train: 0.22366188096799958 [274304/343145]\n",
      "train: 0.22308878531095697 [342912/343145]\n",
      "train: 0.21061119437217712 test: 0.24362349781123074 [343040/343145]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2215036932705057 [68480/343145]\n",
      "train: 0.22207640531236555 [137088/343145]\n",
      "train: 0.22277326403713937 [205696/343145]\n",
      "train: 0.22261031961707928 [274304/343145]\n",
      "train: 0.2237411676280534 [342912/343145]\n",
      "train: 0.202126607298851 test: 0.24343412488299226 [343040/343145]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22220286624280655 [68480/343145]\n",
      "train: 0.22260237421228815 [137088/343145]\n",
      "train: 0.22271831742307144 [205696/343145]\n",
      "train: 0.2224185516251557 [274304/343145]\n",
      "train: 0.22301348835341075 [342912/343145]\n",
      "train: 0.20761437714099884 test: 0.24363519126985184 [343040/343145]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22170889333195748 [68480/343145]\n",
      "train: 0.22032902720592804 [137088/343145]\n",
      "train: 0.22129828552367972 [205696/343145]\n",
      "train: 0.2232345261180134 [274304/343145]\n",
      "train: 0.22385062385739676 [342912/343145]\n",
      "train: 0.24226407706737518 test: 0.243420522476806 [343040/343145]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22224667640593687 [68480/343145]\n",
      "train: 0.22239199030532766 [137088/343145]\n",
      "train: 0.22254576764778414 [205696/343145]\n",
      "train: 0.22244971214946527 [274304/343145]\n",
      "train: 0.22114942503620438 [342912/343145]\n",
      "train: 0.2248767465353012 test: 0.2445608144501105 [343040/343145]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2211864846489727 [68480/343145]\n",
      "train: 0.2218784701857549 [137088/343145]\n",
      "train: 0.22255528798855062 [205696/343145]\n",
      "train: 0.22147876599720165 [274304/343145]\n",
      "train: 0.22249135525146527 [342912/343145]\n",
      "train: 0.2107490599155426 test: 0.2439719085899444 [343040/343145]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22069256493277167 [68480/343145]\n",
      "train: 0.22130510333313871 [137088/343145]\n",
      "train: 0.2221692973720049 [205696/343145]\n",
      "train: 0.22255926573676849 [274304/343145]\n",
      "train: 0.22290819196669914 [342912/343145]\n",
      "train: 0.20817381143569946 test: 0.2435122165612421 [343040/343145]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2219833330402161 [68480/343145]\n",
      "train: 0.22169782707829083 [137088/343145]\n",
      "train: 0.22197920815157357 [205696/343145]\n",
      "train: 0.22279474698007107 [274304/343145]\n",
      "train: 0.22081288080940495 [342912/343145]\n",
      "train: 0.2565392255783081 test: 0.24421794363887406 [343040/343145]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2212760483419429 [68480/343145]\n",
      "train: 0.22148296937568865 [137088/343145]\n",
      "train: 0.22277414340025453 [205696/343145]\n",
      "train: 0.22201771959106423 [274304/343145]\n",
      "train: 0.2217582164804882 [342912/343145]\n",
      "train: 0.24561408162117004 test: 0.24404428581722448 [343040/343145]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22037077005571049 [68480/343145]\n",
      "train: 0.2218243614561967 [137088/343145]\n",
      "train: 0.22205038193557688 [205696/343145]\n",
      "train: 0.22149934258256385 [274304/343145]\n",
      "train: 0.2204931736715249 [342912/343145]\n",
      "train: 0.2119707465171814 test: 0.24401782184350687 [343040/343145]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22096580194805365 [68480/343145]\n",
      "train: 0.22217903177796014 [137088/343145]\n",
      "train: 0.2219674536096516 [205696/343145]\n",
      "train: 0.22133712214765264 [274304/343145]\n",
      "train: 0.22185947064921926 [342912/343145]\n",
      "train: 0.2195240557193756 test: 0.24374644536019793 [343040/343145]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22076861052539762 [68480/343145]\n",
      "train: 0.22191268572611594 [137088/343145]\n",
      "train: 0.2212634122471756 [205696/343145]\n",
      "train: 0.22104665106023424 [274304/343145]\n",
      "train: 0.2211799000514977 [342912/343145]\n",
      "train: 0.2283175140619278 test: 0.24398602050036503 [343040/343145]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22204387027014122 [68480/343145]\n",
      "train: 0.22107291502405457 [137088/343145]\n",
      "train: 0.22062090962235606 [205696/343145]\n",
      "train: 0.21945087533833377 [274304/343145]\n",
      "train: 0.2223170885343605 [342912/343145]\n",
      "train: 0.23982855677604675 test: 0.2443129967248564 [343040/343145]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22098264253561278 [68480/343145]\n",
      "train: 0.2201286155396878 [137088/343145]\n",
      "train: 0.22134019328809496 [205696/343145]\n",
      "train: 0.22052683325400993 [274304/343145]\n",
      "train: 0.22215488986737691 [342912/343145]\n",
      "train: 0.2126907855272293 test: 0.24417432243262602 [343040/343145]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.22090827306000657 [68480/343145]\n",
      "train: 0.22027288680312349 [137088/343145]\n",
      "train: 0.22028028809312564 [205696/343145]\n",
      "train: 0.22085835192519337 [274304/343145]\n",
      "train: 0.22217456009516964 [342912/343145]\n",
      "train: 0.20808172225952148 test: 0.24452632836631086 [343040/343145]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.2198969717076815 [68480/343145]\n",
      "train: 0.22125182906860735 [137088/343145]\n",
      "train: 0.22060338268751528 [205696/343145]\n",
      "train: 0.2208968366204358 [274304/343145]\n",
      "train: 0.22015014482634282 [342912/343145]\n",
      "train: 0.21419183909893036 test: 0.2439895331992833 [343040/343145]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.21909256479260641 [68480/343145]\n",
      "train: 0.22031055905147276 [137088/343145]\n",
      "train: 0.22100235635776128 [205696/343145]\n",
      "train: 0.221766412786361 [274304/343145]\n",
      "train: 0.22246024012565613 [342912/343145]\n",
      "train: 0.23881453275680542 test: 0.24487917158536157 [343040/343145]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.21883958691880245 [68480/343145]\n",
      "train: 0.22075310363364753 [137088/343145]\n",
      "train: 0.21996408573059895 [205696/343145]\n",
      "train: 0.22169166603195134 [274304/343145]\n",
      "train: 0.22042748243061464 [342912/343145]\n",
      "train: 0.20527975261211395 test: 0.24433394382678628 [343040/343145]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.21949053662560283 [68480/343145]\n",
      "train: 0.2198351082016728 [137088/343145]\n",
      "train: 0.22046242857268497 [205696/343145]\n",
      "train: 0.2215236756505806 [274304/343145]\n",
      "train: 0.22043068954415285 [342912/343145]\n",
      "train: 0.22621361911296844 test: 0.24443410072703298 [343040/343145]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "---------- ret1_ret2_2chan_cnn_scaleIn1000Out10000_0.0001_128 ----------\n",
      "train: 0.21912819707637837 [68480/343145]\n",
      "train: 0.22007368571722685 [137088/343145]\n",
      "train: 0.22004060797504524 [205696/343145]\n",
      "train: 0.22049391155701076 [274304/343145]\n",
      "train: 0.22060660962293396 [342912/343145]\n",
      "train: 0.1946072280406952 test: 0.24501902999803313 [343040/343145]\n"
     ]
    }
   ],
   "source": [
    "strategyname = \"ret1_ret2_2chan_cnn\"\n",
    "\n",
    "training_configs = []\n",
    "learning_rates_to_try = [1e-4]\n",
    "batch_sizes_to_try = [4096, 10000, 128]\n",
    "input_scalings_to_try = [1000]\n",
    "output_scalings_to_try = [10000]\n",
    "for learning_rate in learning_rates_to_try:\n",
    "    for batch_size in batch_sizes_to_try:\n",
    "        for input_scaling in input_scalings_to_try:\n",
    "            for output_scaling in output_scalings_to_try:\n",
    "                    training_configs.append({\n",
    "                        'learning_rate':learning_rate,\n",
    "                        'batch_size':batch_size,\n",
    "                        'input_scaling':input_scaling,\n",
    "                        'output_scaling':output_scaling,\n",
    "                    })\n",
    "\n",
    "epochs = 150\n",
    "for training_config in training_configs:\n",
    "    \n",
    "    learning_rate = training_config['learning_rate']\n",
    "    batch_size = training_config['batch_size']\n",
    "    input_scaling = training_config['input_scaling']\n",
    "    output_scaling = training_config['output_scaling']\n",
    "    # TRAINING SETUP\n",
    "    \n",
    "    #refresh the model\n",
    "    model = NeuralNetwork()\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    STRATEGY_NAME_WITH_ATTRS = f\"{strategyname}_scaleIn{input_scaling}Out{output_scaling}_{learning_rate}_{batch_size}\"\n",
    "    summary_writer = SummaryWriter(f'../output/training_tensorboard/{STRATEGY_NAME_WITH_ATTRS}')\n",
    "    \n",
    "    # TRAINING SETUP DONE\n",
    "    \n",
    "    print(\"DEVICE:\", device)\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    test_size = dataset_size - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    data_interval_len = int(600/1)\n",
    "    data_ohlc_sample_len = 1 # 1 for each of open high low close\n",
    "    losses_train = []\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        print(\"----------\", STRATEGY_NAME_WITH_ATTRS, \"----------\")\n",
    "\n",
    "        dataloader_train = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=0, pin_memory=True)\n",
    "        model.train()\n",
    "        \n",
    "        for train_batch_idx, (Feature_X, feature_y) in enumerate(dataloader_train):\n",
    "\n",
    "            X = Feature_X['log_return1_1s'] * input_scaling\n",
    "            X = torch.cat([X, Feature_X['log_return2_1s']*input_scaling], 1)\n",
    "\n",
    "            X = X.reshape(-1,2,data_interval_len*data_ohlc_sample_len*1)\n",
    "\n",
    "            y = feature_y * output_scaling\n",
    "\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            feature_y = feature_y.to(device)\n",
    "            pred = model(X)\n",
    "            pred.to(device)\n",
    "\n",
    "            loss_orig = loss_fn_orig(y, pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_orig.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            losses_train.append(loss_orig.item())\n",
    "            # we want 5 spread out output per epoch\n",
    "            if (t*int(train_size/batch_size) + train_batch_idx + 1) % int(train_size/5/batch_size) == 0:\n",
    "                \n",
    "                # NOTE: real loss is same as upscaled normalized loss as it's percentage loss (rmspe)\n",
    "                prediction_variety = np.std((pred/output_scaling).reshape(-1).tolist()) * 100\n",
    "                #NOTE: prediction variety is important as model sometimes predits a constant value! regardless of the input, then per batch variety is lowest(0 std dev)\n",
    "#                 print(\"prediction variety\",)\n",
    "#                 print(pred.reshape(-1).tolist()[:7])\n",
    "                \n",
    "                summary_writer.add_scalar(\"Prediction Variety\", prediction_variety, t*(train_size) + (train_batch_idx*batch_size))\n",
    "                summary_writer.add_scalar(\"Training Loss\", np.mean(losses_train), t*(train_size) + (train_batch_idx*batch_size))\n",
    "\n",
    "                print(\"train:\", np.mean(losses_train), f\"[{train_batch_idx*batch_size:>5d}/{train_size:>5d}]\")\n",
    "                losses_train = []\n",
    "                \n",
    "        dataloader_test = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0, pin_memory=True)\n",
    "        dataset_size = len(dataloader_test.dataset)\n",
    "        model.eval()\n",
    "\n",
    "        losses_test = []\n",
    "        for _, (Feature_X, feature_y) in enumerate(dataloader_test):\n",
    "            with torch.no_grad():\n",
    "\n",
    "                X = Feature_X['log_return1_1s'] * input_scaling\n",
    "                X = torch.cat([X, Feature_X['log_return2_1s']*input_scaling], 1)\n",
    "                X = X.reshape(-1,2,data_interval_len*data_ohlc_sample_len*1)\n",
    "\n",
    "                y = feature_y * output_scaling\n",
    "\n",
    "                X = X.type(torch.cuda.FloatTensor)\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                pred = model(X)\n",
    "                loss = loss_fn_orig(y, pred)\n",
    "                losses_test.append(loss.item())\n",
    "\n",
    "\n",
    "#                 summary_writer.add_scalar(\"Epoch Training Loss\", np.mean(losses_train), (t+1)*train_size)\n",
    "        summary_writer.add_scalar(\"Test Loss\", np.mean(losses_test), t*(train_size) + (train_batch_idx*batch_size))\n",
    "        print(\"train:\", np.mean(losses_train), \"test:\", np.mean(losses_test), f\"[{train_batch_idx*batch_size:>5d}/{train_size:>5d}]\")\n",
    "        losses_test = []\n",
    "        if (t+1)%50==0:\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_OUTPUT_DIRECTORY,f\"{STRATEGY_NAME_WITH_ATTRS}_epoch_{t}_tloss_{loss:.4f}.pth\"))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cea68b-9cf2-4a6c-8fab-d0e6b8f7654d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce561c-5b64-44bf-882b-41f6250b1084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
