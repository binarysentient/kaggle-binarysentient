{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2f18e2-9894-4f0c-bd57-8b37afc02309",
   "metadata": {},
   "source": [
    "### Can our model predict current volatility?  (forget future; first it should be capable of predicting current one with given features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c4e895-fd66-490d-a8b8-d28b324d3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from optiver_features_handler import get_features_map_for_stock, get_row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad9958-4061-4195-b9d8-77f142bc7fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750eb0e3-2860-490b-bc3c-2a512485a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join(\"..\",\"input\",\"optiver-realized-volatility-prediction\")\n",
    "OUTPUT_DIRECTORY = os.path.join(\"..\",\"output\")\n",
    "os.makedirs(OUTPUT_DIRECTORY,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02947ab-aa1d-4af0-9d6e-7a51cff159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptiverRealizedVolatilityDataset(Dataset):\n",
    "    def __init__(self, data_directory, mode=\"train\", lazy_load=True):\n",
    "        \"\"\"initializes Optiver Competition dataset\n",
    "        `mode`: train|test\n",
    "        `data_directory`: the datadirectory of the input data, where there are test.csv, train.csv, and parquet folders for trade_train.parquet and other relevant folders\n",
    "        \"\"\"\n",
    "        print(\"INIT: OptiverRealizedVolatilityDataset\")\n",
    "        if mode.lower() not in ['train','test']:\n",
    "            raise Exception(\"Invalid mode passed for Optiver dataset. Valid values:train|test\")\n",
    "        self.data_directory = data_directory\n",
    "        self.mode = mode.lower()\n",
    "        self.main_df = pd.read_csv(os.path.join(self.data_directory,f'{self.mode}.csv'))\n",
    "#         if self.mode == 'train':\n",
    "#             self.main_df['row_id'] = self.main_df.apply(lambda x: f\"{x['stock_id']:.0f}-{x['time_id']:.0f}\", axis=1)\n",
    "        if self.mode == 'test':\n",
    "            self.main_df['target'] = 0\n",
    "        \n",
    "        self.cache_stocks_done_set = set()\n",
    "        # this is our final features lookup where we park all our features which can be addressed by row_id\n",
    "        # which is individual train/test.csv row id using 'stock_id`-`time_id`\n",
    "        self.cache_rowid_feature_map = {}\n",
    "        row_id_series = self.main_df['stock_id'].astype(str) + \"-\" +self.main_df['time_id'].astype(str)\n",
    "        targets = self.main_df['target'].tolist()\n",
    "        self.stock_possible_timeids_list = {}\n",
    "        for idx, row_id in enumerate(row_id_series.tolist()):\n",
    "            stock_id = int(row_id.split('-')[0])\n",
    "            time_id = int(row_id.split('-')[1])\n",
    "            self.cache_rowid_feature_map[row_id] = {'target':targets[idx], 'stock_id':stock_id,'time_id':time_id,'row_id':row_id}\n",
    "            \n",
    "            # below code is to make sure what timeids we expect from stock data extractor\n",
    "            # in case of missing parquet files we'll have to know the keys to fill default values into\n",
    "            if stock_id not in self.stock_possible_timeids_list:\n",
    "                self.stock_possible_timeids_list[stock_id] = []\n",
    "            self.stock_possible_timeids_list[stock_id].append(time_id)\n",
    "            \n",
    "        \n",
    "        if lazy_load == False:\n",
    "            worker_data = []\n",
    "            for gkey, gdf in self.main_df.groupby(['stock_id']):\n",
    "                worker_data.append((self.data_directory, self.mode, gkey))\n",
    "#             print(\"---------- CPU COUNG:\", multiprocessing.cpu_count())\n",
    "            # NOTE: this was hell of a hunt; this windows and pytorch and jupyter combination is too tedious\n",
    "            #       make sure the function that we distribute don't call pytorch\n",
    "            with Pool(multiprocessing.cpu_count()) as p:\n",
    "                feature_set_list = p.starmap(get_features_map_for_stock, worker_data)\n",
    "                for feature_map in feature_set_list:\n",
    "                    for rowid, features_dict in feature_map.items():\n",
    "                        for fkey,fval in features_dict.items():\n",
    "                            self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                        self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                    # udpate the indications that we've already fetched this stock and the lazy loader code won't fetch this again\n",
    "                    self.cache_stocks_done_set.add(int(rowid.split('-')[0]))\n",
    "    \n",
    "    def __cache_generate_features(self, main_stock_id, main_time_id):\n",
    "            \n",
    "            \n",
    "            main_row_id = get_row_id(main_stock_id, main_time_id)\n",
    "            if main_stock_id not in self.cache_stocks_done_set:\n",
    "#                 trade_df = pd.read_parquet(os.path.join(self.data_directory, f\"trade_{self.mode}.parquet\", f\"stock_id={stock_id}\"))   \n",
    "                # we'll combine the featureset with the bigger feature set of all stocks\n",
    "                feature_map = get_features_map_for_stock(self.data_directory, self.mode, main_stock_id)\n",
    "                # NOTE: sometime we might now have parquet files in that case we'll have 3 entried in .csv while only 1 gets returned in feature map\n",
    "                # we need to cover for that disparity\n",
    "                for time_id in self.stock_possible_timeids_list[main_stock_id]:\n",
    "                    expected_row_id = get_row_id(main_stock_id, time_id)\n",
    "                    if expected_row_id not in feature_map:\n",
    "                        feature_map[expected_row_id] = {}\n",
    "                for rowid, features_dict in feature_map.items():\n",
    "                    for fkey,fval in features_dict.items():\n",
    "                        self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                    self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                self.cache_stocks_done_set.add(main_stock_id)\n",
    "#             print(self.cache_rowid_feature_map[main_row_id])\n",
    "#             print(torch.tensor([self.cache_rowid_feature_map[main_row_id].get('book_realized_volatility',0)]))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map[main_row_id].get('log_return1_2s', [0]*(int(600/2)))))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map.get('book_directional_volume1_2s', [0]*(int(600/2)))))\n",
    "            return self.cache_rowid_feature_map[main_row_id]\n",
    "        \n",
    "    @staticmethod\n",
    "    def transform_to_01_realized_volatility_linear_data(features_dict):\n",
    "        return (\n",
    "                {\n",
    "                    'row_id':features_dict['row_id'],\n",
    "                    'book_realized_volatility':torch.tensor([features_dict.get('book_realized_volatility',0)]),\n",
    "                    'log_return1_2s':torch.tensor(features_dict.get('log_return1_2s', [0]*(int(600/2)))),\n",
    "                    'book_directional_volume1_2s':torch.tensor(features_dict.get('book_directional_volume1_2s', [0]*(int(600/2)))) \n",
    "                },\n",
    "                torch.tensor([features_dict['target']])\n",
    "#                 [features_dict['target']]\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.main_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: handle for num_workers more than 0\n",
    "        #      using https://pytorch.org/docs/stable/data.html\n",
    "        #      using torch.util.data.get_worker_info()\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        stock_id = self.main_df.at[idx, 'stock_id']\n",
    "        time_id = self.main_df.at[idx, 'time_id']\n",
    "        x,y = self.__cache_generate_features(stock_id,time_id)\n",
    "#         x, y = self.__transform_to_01_realized_volatility_linear_data(features_dict)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcee691-c9ce-481f-a4e8-dbf97b66b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT: OptiverRealizedVolatilityDataset\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    dataset = OptiverRealizedVolatilityDataset(DATA_DIRECTORY, mode=\"train\", lazy_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202d58ff-26aa-4b02-b2ac-991ccb366c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'row_id': '2-19309',\n",
       "  'book_realized_volatility': tensor([0.0022], dtype=torch.float64),\n",
       "  'log_return1_2s': tensor([ 6.0413e-05,  6.0413e-05,  4.8357e-05, -1.2085e-04, -5.1354e-05,\n",
       "          -3.7564e-05,  1.0946e-04,  3.5530e-05,  4.3171e-05,  3.3897e-07,\n",
       "          -1.2371e-04, -3.6098e-05, -9.8656e-05,  1.0582e-04,  1.0305e-04,\n",
       "          -1.9261e-05, -3.5741e-05,  1.8883e-05, -2.5424e-05, -8.3551e-05,\n",
       "          -7.4092e-05,  2.4368e-04, -1.4165e-04,  3.5744e-05,  3.1450e-05,\n",
       "           1.2085e-04, -1.2451e-04, -3.2420e-05, -3.4293e-05,  1.7588e-05,\n",
       "          -5.4811e-06, -1.3497e-04, -1.7910e-04,  2.8383e-05, -2.4535e-05,\n",
       "           5.5848e-05, -4.6457e-05,  7.8601e-06,  1.3846e-04,  1.1608e-04,\n",
       "          -2.7190e-05, -5.9829e-05,  4.1800e-05, -4.7252e-05, -1.7348e-04,\n",
       "          -4.8430e-06, -1.1340e-04,  5.7795e-05,  0.0000e+00,  8.4624e-05,\n",
       "          -1.1776e-04, -2.5630e-05,  1.3132e-04,  1.6596e-05,  1.1527e-04,\n",
       "           5.3982e-05,  8.1596e-06, -1.5717e-05,  5.7415e-05,  1.0878e-04,\n",
       "          -5.4391e-05,  2.4172e-05,  8.7612e-05, -1.5103e-05, -1.6920e-04,\n",
       "           8.4594e-05, -3.0200e-05, -1.8126e-05, -1.9585e-04,  1.5354e-04,\n",
       "           6.0374e-06,  1.0456e-04,  4.5308e-05,  7.2497e-06,  3.8664e-05,\n",
       "          -1.9332e-05, -8.4634e-07, -2.2935e-07, -2.5396e-04,  3.0238e-05,\n",
       "          -2.4488e-04, -1.5188e-04,  8.2102e-05,  5.5938e-05, -3.2042e-05,\n",
       "           5.5744e-05, -3.0610e-05, -7.0336e-05,  6.1843e-05,  2.8888e-05,\n",
       "           1.1095e-04,  1.2996e-06,  9.7946e-05, -1.8090e-04,  1.1038e-05,\n",
       "          -1.4842e-05, -4.2883e-05, -3.9618e-05,  6.6502e-05,  6.6487e-05,\n",
       "           7.2551e-05,  5.0786e-05, -7.2547e-05, -6.1671e-05,  6.9340e-05,\n",
       "          -3.0217e-05,  2.7309e-05,  6.8266e-05, -3.1322e-05, -1.9486e-06,\n",
       "          -3.1771e-07,  2.4260e-06,  0.0000e+00, -2.6559e-05,  1.0488e-04,\n",
       "           2.4605e-04,  5.4394e-05,  1.0468e-04,  7.6547e-05,  4.3485e-05,\n",
       "          -6.1619e-05, -1.3774e-04,  1.0871e-05,  3.6238e-05, -2.4607e-04,\n",
       "          -1.0382e-04,  1.6355e-05, -3.1512e-04,  1.2109e-04, -4.9127e-05,\n",
       "           5.6097e-06, -7.2333e-05,  1.1229e-04, -1.2156e-04, -1.2094e-05,\n",
       "          -4.8381e-05,  3.5641e-05,  6.7920e-05, -7.5089e-05, -9.3705e-05,\n",
       "          -1.5484e-04,  3.0193e-05, -3.1242e-05, -9.7209e-05,  1.4868e-04,\n",
       "           1.4391e-04,  1.5876e-04, -1.2100e-05,  1.1396e-05, -4.5583e-04,\n",
       "           1.0132e-04,  3.0857e-04,  1.6239e-04, -1.1574e-04,  7.4354e-05,\n",
       "          -7.4354e-05,  1.5716e-04,  2.9613e-04, -3.7475e-05, -1.4351e-04,\n",
       "          -1.5730e-04,  3.3099e-05, -2.1158e-05, -1.2692e-04,  1.5956e-04,\n",
       "           1.2449e-04,  5.1072e-05,  4.0448e-04,  3.6336e-06,  2.3800e-04,\n",
       "           2.8663e-04, -9.7013e-05,  2.8229e-04, -8.7258e-06, -1.5458e-06,\n",
       "          -9.7019e-06, -1.1017e-04, -3.0477e-06,  7.1860e-05,  2.1372e-04,\n",
       "          -3.1032e-04, -1.3159e-04,  8.3305e-05,  7.2434e-05,  9.4186e-05,\n",
       "           6.0401e-05, -1.8718e-04,  9.6613e-05,  2.2940e-05, -2.9015e-05,\n",
       "          -4.5268e-05,  6.3404e-05, -1.9785e-04,  2.6556e-05,  3.7388e-05,\n",
       "           1.6009e-04,  1.3161e-04,  5.9531e-05, -4.2257e-05, -1.2079e-05,\n",
       "          -1.6660e-04, -1.0867e-04,  4.5923e-05, -1.2102e-05,  4.8286e-05,\n",
       "          -8.7540e-05,  1.8432e-05, -9.0404e-06,  1.6473e-04,  1.1383e-04,\n",
       "          -5.5553e-05, -2.3848e-05,  5.8894e-06,  1.2210e-05,  3.9687e-05,\n",
       "           4.0064e-05,  1.1596e-06, -3.3227e-05, -1.5103e-05, -5.0571e-05,\n",
       "           1.0055e-05,  2.1193e-05,  1.9725e-07,  3.1784e-05,  4.8784e-05,\n",
       "          -5.7646e-05, -1.8048e-05,  9.6571e-06,  0.0000e+00,  2.2048e-05,\n",
       "           2.1034e-04,  1.3213e-04, -3.0400e-05, -6.3265e-06, -3.7403e-05,\n",
       "          -3.0165e-05,  3.4512e-04,  1.0858e-04, -6.5153e-05, -5.0683e-05,\n",
       "          -2.7130e-04, -1.5430e-04, -3.6098e-05,  5.3272e-05,  2.2978e-04,\n",
       "          -2.3103e-06, -1.0852e-05,  8.5286e-05,  3.1884e-04, -1.0372e-04,\n",
       "          -6.5130e-05,  1.7252e-04, -1.7673e-04, -6.2764e-05,  6.6967e-05,\n",
       "           1.5679e-04,  0.0000e+00, -3.0150e-05, -7.5981e-05,  2.1709e-05,\n",
       "          -4.2154e-06, -1.6680e-04, -1.1855e-04, -2.1403e-06, -5.3240e-05,\n",
       "           1.2005e-05,  6.9124e-05,  2.7028e-05,  6.2354e-05,  1.1039e-04,\n",
       "          -1.5314e-04, -7.7507e-06,  2.5875e-05,  2.7156e-05, -6.9427e-05,\n",
       "          -6.0219e-06, -8.0879e-05,  4.2270e-05,  5.7930e-05,  6.3961e-05,\n",
       "           9.1049e-05, -1.0070e-04,  3.1798e-05, -1.5198e-05, -2.2525e-06,\n",
       "          -4.4534e-05,  1.9706e-05,  1.3250e-04, -1.2451e-04,  3.8701e-05,\n",
       "           7.2374e-06,  8.8050e-05, -6.6339e-05,  7.9606e-05,  3.0755e-05,\n",
       "          -9.0455e-06,  9.1657e-05,  9.1746e-05,  8.4650e-05,  3.5568e-05]),\n",
       "  'book_directional_volume1_2s': tensor([ 100.0000,   50.0000,    0.0000,  -50.0000, -100.0000,   50.0000,\n",
       "            98.5000,  147.0000,  147.0000,  149.5000,  -99.5000, -198.0000,\n",
       "           -92.0000, -140.0000,  -90.0000,   52.0000,  -48.0000,  -43.0000,\n",
       "            52.0000,  -95.5000,    0.0000,  106.0000, -189.0000,  150.0000,\n",
       "          -100.0000,  100.0000,  116.0000,   83.0000,  -67.0000,  -17.0000,\n",
       "          -184.0000,  -99.5000, -100.0000,   33.0000,  -84.0000,   16.0000,\n",
       "           -34.0000,  -84.0000,   83.0000,  200.0000,  200.0000,  100.0000,\n",
       "            95.0000,  150.0000,  100.0000,    0.0000, -268.5000,    0.0000,\n",
       "             0.0000, -100.0000,  -58.5000,  -58.5000,    0.0000, -118.5000,\n",
       "            10.0000, -100.0000,  -50.0000,   50.0000,   50.0000,    0.0000,\n",
       "             0.0000,  100.0000,  150.0000,  100.0000,    0.0000,   50.0000,\n",
       "             0.0000,    0.0000,  -50.0000,   50.0000,    0.0000,  194.0000,\n",
       "             0.0000,   50.0000,  100.0000,    0.0000,  -34.0000,  -35.5000,\n",
       "            50.0000,  -50.0000, -137.0000,   56.5000,    5.0000,  -81.0000,\n",
       "          -115.5000, -137.0000,  -18.5000,  144.5000,   57.5000,  173.0000,\n",
       "            50.0000,  100.0000,  -50.0000,  191.5000,  141.5000,   83.0000,\n",
       "           -35.5000,    0.0000,  -50.0000,    0.0000,    0.0000, -100.0000,\n",
       "          -100.0000,  -50.0000, -160.0000, -210.0000, -109.0000,  195.5000,\n",
       "           250.0000,  199.0000,  206.5000,  214.0000,  214.0000,   53.0000,\n",
       "           -50.0000,    0.0000,  100.0000,  194.0000,  200.0000,   50.0000,\n",
       "             0.0000,  -50.0000, -100.0000, -100.0000,   16.0000,   11.0000,\n",
       "            50.0000,  -58.5000,  150.0000, -300.0000, -100.0000,  -64.0000,\n",
       "            46.0000,    0.0000,  -50.0000,   50.0000, -134.0000,   33.0000,\n",
       "          -358.5000, -417.0000, -134.0000,   16.0000,   50.5000,  -82.0000,\n",
       "          -142.0000, -246.5000,  100.0000,  -50.0000,   49.0000,   50.0000,\n",
       "           -32.5000,    9.5000,   33.0000,   50.0000,  150.0000,   50.0000,\n",
       "           -50.0000, -100.0000, -200.0000,    1.0000,  -49.5000, -350.0000,\n",
       "          -100.0000,    0.0000,   50.0000,   50.0000,  -18.0000,  200.0000,\n",
       "          -100.0000, -200.0000,   72.5000, -150.0000,  -68.5000,  -16.0000,\n",
       "            71.0000,   82.0000,    0.0000,  -50.0000,   50.0000,   50.0000,\n",
       "           -50.0000,  -50.0000,   50.0000,  100.0000,    0.0000,  100.0000,\n",
       "            50.0000,  100.0000,  150.0000,    0.0000,  100.0000,    0.0000,\n",
       "           111.0000,  168.5000,  -99.0000,  -50.0000, -150.0000,  100.0000,\n",
       "          -150.0000,   50.0000,   50.0000,   50.0000,  -50.0000,  -50.0000,\n",
       "           -50.0000, -100.0000, -199.0000, -267.5000, -200.0000, -150.0000,\n",
       "          -100.0000,    1.0000,  -49.5000,   51.0000,    0.5000,   83.0000,\n",
       "           -35.0000, -133.0000, -199.5000, -149.0000, -218.5000, -318.5000,\n",
       "          -366.5000, -333.0000, -166.5000, -249.0000, -333.0000,  -84.0000,\n",
       "           -84.0000,  -84.0000,  133.0000, -187.5000, -337.5000, -100.0000,\n",
       "           -50.0000,    0.0000,  100.0000,  200.0000,  100.0000,  100.0000,\n",
       "            51.0000, -148.0000, -198.0000,  -98.0000, -399.0000,    0.0000,\n",
       "            50.0000, -150.0000,  100.0000,   50.0000,    0.0000,  205.0000,\n",
       "          -237.0000,  -50.0000,  -50.0000,   50.0000,   50.0000, -100.0000,\n",
       "          -150.0000,    0.0000,   97.0000,   -1.5000,    0.0000,   -3.0000,\n",
       "          -201.5000,   50.5000,   97.0000,   47.0000,   -1.5000, -168.5000,\n",
       "             0.0000,   50.0000,  200.0000,  100.0000, -100.0000,  -50.0000,\n",
       "             0.0000,  150.0000,   50.0000,  100.0000, -250.0000,   50.0000,\n",
       "           182.0000,   32.0000,   14.0000,  -86.0000,  -69.0000, -100.0000,\n",
       "          -149.5000, -150.0000, -100.0000,   50.0000,    0.0000,  -50.0000,\n",
       "           150.0000,  100.0000,  150.0000,  300.5000,  150.0000,  200.0000])},\n",
       " tensor([0.0020]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for x in range(0,9):\n",
    "#     print(dataset[x])\n",
    "dataset[10000] #[0]['book_wap1_1s'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01a7450-a6f4-49ac-861b-81912176aed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for key, val in dataset.cache_rowid_feature_map.items():\n",
    "#     dataset.main_df.at[0,'time_id']\n",
    "#     dataset.main_df.at[0,'stock_id']\n",
    "tradevola = []\n",
    "for idx in range(0, len(dataset)):\n",
    "    X, y = dataset[idx]\n",
    "    tradevola.append(X['book_realized_volatility'].item())\n",
    "#     print('book',X['book_realized_volatility'].item(),'trade', X['trade_realized_volatility'].item(),'traget', y.item())\n",
    "#     print('bookdiff', abs(X['book_realized_volatility'].item()-y.item()), 'tradediff', abs(X['trade_realized_volatility'].item()-y.item()))\n",
    "#     break\n",
    "#     input()\n",
    "#     except:\n",
    "#         print(\"ERRR\")\n",
    "#         print(idx)\n",
    "#         print(dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a690b3b2-6d81-4ce0-b7eb-a82d78183697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    428932.000000\n",
       "mean          0.004233\n",
       "std           0.003586\n",
       "min           0.000081\n",
       "25%           0.002065\n",
       "50%           0.003159\n",
       "75%           0.005108\n",
       "max           0.086421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(tradevola).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "15e35973-37f1-408a-b47f-3a8fa6c9879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.cnn_stack = nn.Sequential(\n",
    "#             nn.Conv1d(1, 10, kernel_size=8, stride=2, padding=0),\n",
    "# #             nn.Linear(input_size, 1024),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Conv1d(10, 10, kernel_size=2, stride=2, padding=0),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Conv1d(10, 10, kernel_size=4, stride=1, padding=0), \n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(0.1),\n",
    "#         )\n",
    "#         self.linear_stack = nn.Sequential(\n",
    "#             nn.LazyLinear(128),\n",
    "# #             nn.Hardswish(),\n",
    "# #             nn.Linear(2048, 1024),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(64, 1),\n",
    "#         )\n",
    "        self.basic_stack = nn.Sequential(\n",
    "            nn.Linear(int(600/2),512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.basic_stack(x)\n",
    "#         x = self.flatten(x)\n",
    "#         logits = self.cnn_stack(x)\n",
    "#         logits = self.flatten(logits)\n",
    "#         logits = self.linear_stack(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn_mse(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)))\n",
    "\n",
    "def loss_fn_mspe(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)/y))\n",
    "\n",
    "def loss_fn_orig(y, pred):\n",
    "    return torch.sqrt(torch.mean(torch.square((y-pred)/y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d4954eef-824e-4676-b639-f443156a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7dc67ca2-9cf8-4035-a214-112214b37cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (basic_stack): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "    (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.1, inplace=False)\n",
       "    (15): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1f24f-c586-4e1b-aad6-fb4671c87232",
   "metadata": {},
   "source": [
    "#### analyze the initial weights (or change them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "931890cf-e329-4a15-b0d0-352dc27f985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @torch.no_grad()\n",
    "# def init_weights(m):\n",
    "# #     print(m)\n",
    "#     if type(m) == nn.Linear:\n",
    "# #         m.weight.fill_(1.0)\n",
    "#         torch.nn.init.xavier_uniform_(m.weight,gain=10)\n",
    "#         m.bias.data.uniform_(-1,1)\n",
    "# #     elif type(m) == nn.ReLU:\n",
    "# #         print(m.data)\n",
    "#     else:\n",
    "#         print(type(m))\n",
    "# #         print(m.weight)\n",
    "# model.apply(init_weights)\n",
    "# # for param in model.parameters():\n",
    "# # #     print(param)\n",
    "# #       print(param.data.size(), param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c79a7d-9e08-4433-9c77-1af049f349d6",
   "metadata": {},
   "source": [
    "### LEarning rate: our base line is 0.34 loss as that's what the optiver guys have when they use current 10 min realize vol and use it as target (copy to prediction). We create simplest neural network and work with learning rates to figure out what's best and when we see something in range of 0.35 then we've found good Learning rate\n",
    "- #### SGD: 1e-7 works best\n",
    "- #### ADAM: 1e-3, 1e-4 works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5cb3871f-5215-4afb-92fc-47ae2d385fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "batch_size = 4096\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef34a31-7317-47c0-a94f-9bebe2fd2e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.878080  [    0/343145] real loss: 0.8780801892280579\n",
      "[0.03448563069105148, 0.039495863020420074, 0.02333875186741352, 0.034538667649030685, 0.046411752700805664, 0.025815727189183235, 0.03722376748919487]\n",
      "[0.20906119048595428, 0.1826799064874649, 0.16328570246696472, 0.4066798686981201, 0.8013405799865723, 0.4421999156475067, 0.5088809132575989]\n",
      "loss: 0.847465  [65536/343145] real loss: 0.8474645018577576\n",
      "[0.04636446014046669, 0.04427403584122658, 0.044182464480400085, 0.05121458321809769, 0.03596247732639313, 0.054810840636491776, 0.03703754395246506]\n",
      "[0.4231337010860443, 0.13289479911327362, 0.8553152680397034, 0.5112099647521973, 0.15840519964694977, 1.3889795541763306, 0.08450010418891907]\n",
      "loss: 0.816014  [131072/343145] real loss: 0.8160144090652466\n",
      "[0.048889804631471634, 0.055429767817258835, 0.05332763493061066, 0.04161607846617699, 0.04115968570113182, 0.04331577569246292, 0.054540541023015976]\n",
      "[0.1263555884361267, 0.5198436975479126, 0.4305543005466461, 0.158605694770813, 0.13341650366783142, 0.16302409768104553, 0.27986907958984375]\n",
      "loss: 0.778193  [196608/343145] real loss: 0.7781932950019836\n",
      "[0.1362987756729126, 0.04836105927824974, 0.06097526475787163, 0.0655735433101654, 0.0639810562133789, 0.0557447224855423, 0.055294957011938095]\n",
      "[1.2557175159454346, 0.1737084984779358, 0.2859717905521393, 0.44380807876586914, 0.4845665693283081, 0.26813840866088867, 0.34132909774780273]\n",
      "loss: 0.731973  [262144/343145] real loss: 0.7319734692573547\n",
      "[0.048485301434993744, 0.06599641591310501, 0.07038736343383789, 0.08739914000034332, 0.08063315600156784, 0.07319028675556183, 0.09590918570756912]\n",
      "[0.16340109705924988, 0.17110459506511688, 0.14264599978923798, 0.3625698983669281, 0.24656400084495544, 0.13180069625377655, 0.6180728077888489]\n",
      "loss: 0.677251  [327680/343145] real loss: 0.6772512197494507\n",
      "[0.07417255640029907, 0.18164098262786865, 0.06973301619291306, 0.07131080329418182, 0.10380269587039948, 0.10260633379220963, 0.0761677473783493]\n",
      "[0.1310351938009262, 0.7734367847442627, 0.16045409440994263, 0.2351303994655609, 0.33149638772010803, 0.6228920221328735, 0.1613236963748932]\n",
      "LOSSES TRAIN: 0.7868336126917884 LOSSES TEST: 0.680204553263528\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.659839  [    0/343145] real loss: 0.6598391532897949\n",
      "[0.10763825476169586, 0.09441281855106354, 0.1790926456451416, 0.1556224226951599, 0.12160299718379974, 0.10136742889881134, 0.09663574397563934]\n",
      "[0.27502939105033875, 0.20262889564037323, 1.5186073780059814, 0.6017810106277466, 0.4413628876209259, 0.23290559649467468, 0.37441620230674744]\n",
      "loss: 0.584557  [65536/343145] real loss: 0.5845567584037781\n",
      "[0.4208106994628906, 0.10174170136451721, 0.1318817287683487, 0.09420784562826157, 0.14504660665988922, 0.1585560142993927, 0.1336282342672348]\n",
      "[1.1371510028839111, 0.23199310898780823, 0.37080249190330505, 0.1193832978606224, 0.498106986284256, 0.27191901206970215, 0.5763674378395081]\n",
      "loss: 0.485190  [131072/343145] real loss: 0.48518967628479004\n",
      "[0.1386733055114746, 0.11380648612976074, 0.16049206256866455, 0.19761613011360168, 0.08928744494915009, 0.2815840542316437, 0.23860511183738708]\n",
      "[0.18467310070991516, 0.16034451127052307, 0.2596248984336853, 0.6595870852470398, 0.09654419869184494, 0.6530091166496277, 0.51175856590271]\n",
      "loss: 0.399498  [196608/343145] real loss: 0.3994978070259094\n",
      "[0.19300034642219543, 0.1478157490491867, 0.309344619512558, 0.22158551216125488, 0.1660555899143219, 0.3234502971172333, 0.19977203011512756]\n",
      "[0.2765918970108032, 0.15393678843975067, 0.8204484581947327, 0.4779442250728607, 0.17681720852851868, 0.5118956565856934, 0.213870108127594]\n",
      "loss: 0.369052  [262144/343145] real loss: 0.36905232071876526\n",
      "[0.17675505578517914, 0.14866891503334045, 0.2019405961036682, 0.33609986305236816, 0.3066716194152832, 0.2654064893722534, 0.2552202045917511]\n",
      "[0.1184173971414566, 0.1119651049375534, 0.3009265959262848, 0.6148262619972229, 0.4663834869861603, 0.3339930772781372, 0.26037830114364624]\n",
      "loss: 0.364291  [327680/343145] real loss: 0.36429139971733093\n",
      "[0.5597861409187317, 0.46316564083099365, 0.23610691726207733, 0.24988599121570587, 0.22918492555618286, 0.2746604382991791, 0.5507967472076416]\n",
      "[0.7853683233261108, 0.4386376142501831, 0.2622216045856476, 0.33647620677948, 0.29287928342819214, 0.3344672918319702, 0.6304599046707153]\n",
      "LOSSES TRAIN: 0.4654699769758043 LOSSES TEST: 0.35637830410684856\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.346992  [    0/343145] real loss: 0.34699156880378723\n",
      "[0.23076361417770386, 0.25021854043006897, 0.5819728970527649, 0.5861697196960449, 0.20802414417266846, 0.1902788281440735, 0.6569629311561584]\n",
      "[0.21210329234600067, 0.34201520681381226, 0.7110594511032104, 0.6395133137702942, 0.2686558961868286, 0.16586700081825256, 0.9597212076187134]\n",
      "loss: 0.348116  [65536/343145] real loss: 0.34811580181121826\n",
      "[0.20987088978290558, 0.15477493405342102, 0.42472660541534424, 0.32706958055496216, 0.455360472202301, 0.2287978082895279, 0.16658787429332733]\n",
      "[0.35599470138549805, 0.1495736986398697, 0.6887562274932861, 0.378606915473938, 0.47439658641815186, 0.4020819067955017, 0.21128970384597778]\n",
      "loss: 0.345010  [131072/343145] real loss: 0.34500980377197266\n",
      "[0.2223503738641739, 0.12346742302179337, 0.18343903124332428, 0.2827690839767456, 0.2823254466056824, 0.2636520266532898, 0.35460832715034485]\n",
      "[0.2931413948535919, 0.1340080052614212, 0.18680889904499054, 0.24549351632595062, 0.35077640414237976, 0.31236690282821655, 0.5583317875862122]\n",
      "loss: 0.321431  [196608/343145] real loss: 0.321431040763855\n",
      "[0.12569662928581238, 0.15209868550300598, 0.3448728024959564, 0.11082956939935684, 0.39637497067451477, 0.419864296913147, 0.17699703574180603]\n",
      "[0.09891119599342346, 0.19401399791240692, 0.4127618968486786, 0.14868159592151642, 0.4840220808982849, 0.3971334993839264, 0.21998940408229828]\n",
      "loss: 0.309291  [262144/343145] real loss: 0.3092910051345825\n",
      "[0.22309647500514984, 0.7180682420730591, 0.29835838079452515, 0.11102992296218872, 0.3515646755695343, 0.25215137004852295, 0.3914908766746521]\n",
      "[0.43646442890167236, 0.6646474003791809, 0.3065587878227234, 0.09872269630432129, 0.5996045470237732, 0.24370770156383514, 0.4603995084762573]\n",
      "loss: 0.305772  [327680/343145] real loss: 0.3057718575000763\n",
      "[0.18254339694976807, 0.6766500473022461, 0.18503808975219727, 0.32528629899024963, 0.3763395845890045, 0.29131191968917847, 0.12942932546138763]\n",
      "[0.18032479286193848, 0.7657675743103027, 0.14720220863819122, 0.26880979537963867, 0.3795973062515259, 0.3613620102405548, 0.07070309668779373]\n",
      "LOSSES TRAIN: 0.33477929128067835 LOSSES TEST: 0.32418687854494366\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.330616  [    0/343145] real loss: 0.3306159973144531\n",
      "[0.3315587341785431, 0.5223730206489563, 0.12202855944633484, 0.14674171805381775, 0.21530833840370178, 0.36786264181137085, 0.14839714765548706]\n",
      "[0.35562869906425476, 0.6038160920143127, 0.1267869919538498, 0.16047799587249756, 0.3453274071216583, 0.32002291083335876, 0.24245260655879974]\n",
      "loss: 0.336004  [65536/343145] real loss: 0.3360036313533783\n",
      "[0.3806976079940796, 0.20692399144172668, 0.18189279735088348, 0.18579471111297607, 0.35488855838775635, 0.19518397748470306, 0.14843659102916718]\n",
      "[0.55663001537323, 0.24663540720939636, 0.29356348514556885, 0.18611060082912445, 0.9291662573814392, 0.22528520226478577, 0.22361940145492554]\n",
      "loss: 0.313978  [131072/343145] real loss: 0.3139781057834625\n",
      "[0.31389346718788147, 0.37966620922088623, 0.16934242844581604, 0.17554521560668945, 0.2598194181919098, 0.2557297348976135, 1.1320586204528809]\n",
      "[0.5009660720825195, 0.4038991928100586, 0.17215219140052795, 0.13818460702896118, 0.35270851850509644, 0.3765183985233307, 1.0835306644439697]\n",
      "loss: 0.318244  [196608/343145] real loss: 0.3182438015937805\n",
      "[2.738598108291626, 0.2152983546257019, 0.4499834477901459, 0.11984561383724213, 0.40918147563934326, 0.4709356725215912, 0.15940701961517334]\n",
      "[1.154144048690796, 0.27826789021492004, 0.7603169083595276, 0.1282913088798523, 0.6386004686355591, 0.49574339389801025, 0.18067529797554016]\n",
      "loss: 0.299112  [262144/343145] real loss: 0.2991116940975189\n",
      "[0.17244192957878113, 0.15843141078948975, 0.30573171377182007, 0.2781510651111603, 0.43113088607788086, 0.17822137475013733, 0.13365495204925537]\n",
      "[0.22517161071300507, 0.16103500127792358, 0.3064112067222595, 0.30591830611228943, 0.5137469172477722, 0.18539530038833618, 0.16326670348644257]\n",
      "loss: 0.327092  [327680/343145] real loss: 0.3270920217037201\n",
      "[0.23262318968772888, 0.19353464245796204, 0.23313423991203308, 0.20043963193893433, 0.30578604340553284, 0.12980511784553528, 0.43250250816345215]\n",
      "[0.3009108006954193, 0.3448094129562378, 0.243340402841568, 0.2890293002128601, 0.3477660119533539, 0.15062110126018524, 0.5505639314651489]\n",
      "LOSSES TRAIN: 0.3165312785477865 LOSSES TEST: 0.3173308556988126\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.306293  [    0/343145] real loss: 0.3062933683395386\n",
      "[0.1563478708267212, 0.17247247695922852, 0.18687859177589417, 0.20138797163963318, 0.24366837739944458, 0.40097400546073914, 0.18648485839366913]\n",
      "[0.1401648074388504, 0.14851289987564087, 0.17623840272426605, 0.12846960127353668, 0.25363489985466003, 0.39770448207855225, 0.1315837949514389]\n",
      "loss: 0.316793  [65536/343145] real loss: 0.3167926073074341\n",
      "[0.22348612546920776, 0.10666980594396591, 0.13563138246536255, 0.45635366439819336, 0.1489700973033905, 0.16416621208190918, 0.1644590198993683]\n",
      "[0.33324238657951355, 0.15443100035190582, 0.12348759919404984, 0.5979505181312561, 0.2031611055135727, 0.14941920340061188, 0.13240940868854523]\n",
      "loss: 0.303471  [131072/343145] real loss: 0.30347132682800293\n",
      "[0.10613696277141571, 0.21082672476768494, 0.22433415055274963, 0.6712603569030762, 0.6647355556488037, 1.4178227186203003, 0.356723427772522]\n",
      "[0.20961950719356537, 0.24718479812145233, 0.226889505982399, 0.6661139726638794, 0.45892709493637085, 0.9385855793952942, 0.40970760583877563]\n",
      "loss: 0.315449  [196608/343145] real loss: 0.31544873118400574\n",
      "[0.2991020381450653, 0.3827427923679352, 0.1731923371553421, 0.25111153721809387, 0.14460331201553345, 0.19429601728916168, 0.4091063439846039]\n",
      "[0.38703131675720215, 0.29630911350250244, 0.29759520292282104, 0.25289681553840637, 0.22743749618530273, 0.2933169901371002, 0.3820466101169586]\n",
      "loss: 0.324162  [262144/343145] real loss: 0.32416173815727234\n",
      "[0.22613026201725006, 0.17831145226955414, 0.17526282370090485, 0.3550110459327698, 0.22716473042964935, 0.18486787378787994, 0.1789085417985916]\n",
      "[0.3369485139846802, 0.1947527974843979, 0.3159971833229065, 0.4204331040382385, 0.309286504983902, 0.24445569515228271, 0.13969889283180237]\n",
      "loss: 0.298129  [327680/343145] real loss: 0.2981286942958832\n",
      "[1.0097949504852295, 0.10463039577007294, 0.47399359941482544, 0.5738622546195984, 0.3430561423301697, 0.3997679352760315, 0.2381606101989746]\n",
      "[1.1022562980651855, 0.09399940073490143, 0.5375795364379883, 0.5343587398529053, 0.3323681056499481, 0.49100130796432495, 0.4003917872905731]\n",
      "LOSSES TRAIN: 0.31111979768389747 LOSSES TEST: 0.31475608547528583\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.301062  [    0/343145] real loss: 0.30106207728385925\n",
      "[0.7869368195533752, 0.2670184075832367, 0.18265245854854584, 0.41417670249938965, 0.14148883521556854, 0.5191203355789185, 0.651818573474884]\n",
      "[0.6935003995895386, 0.24015279114246368, 0.6039260625839233, 0.6311522722244263, 0.20898211002349854, 0.6159718036651611, 0.9060854315757751]\n",
      "loss: 0.295869  [65536/343145] real loss: 0.2958693504333496\n",
      "[0.6354116201400757, 0.17703624069690704, 0.5243216753005981, 0.3218340277671814, 0.353914737701416, 0.2037615329027176, 0.11616872251033783]\n",
      "[0.6757079362869263, 0.12292410433292389, 0.4431167244911194, 0.45427680015563965, 0.47757798433303833, 0.14108459651470184, 0.19357870519161224]\n",
      "loss: 0.307834  [131072/343145] real loss: 0.30783388018608093\n",
      "[0.3313877284526825, 0.21396349370479584, 0.15416979789733887, 0.4366678297519684, 0.2186346799135208, 0.2909778356552124, 0.26912227272987366]\n",
      "[0.4989311099052429, 0.29399368166923523, 0.2815288007259369, 0.7059305906295776, 0.23156970739364624, 0.30770552158355713, 0.15869510173797607]\n",
      "loss: 0.318788  [196608/343145] real loss: 0.31878840923309326\n",
      "[0.3678071200847626, 0.14895612001419067, 0.0890379399061203, 0.7945947051048279, 0.16603346168994904, 0.19278590381145477, 0.20881056785583496]\n",
      "[0.602408230304718, 0.32056841254234314, 0.12962239980697632, 0.814162015914917, 0.20150591433048248, 0.31699201464653015, 0.19449220597743988]\n",
      "loss: 0.303438  [262144/343145] real loss: 0.30343836545944214\n",
      "[0.19119791686534882, 0.23683099448680878, 0.23447243869304657, 0.14093449711799622, 0.41725918650627136, 0.3074973523616791, 0.13969555497169495]\n",
      "[0.13986900448799133, 0.32980260252952576, 0.23714040219783783, 0.19246789813041687, 0.31307539343833923, 0.2442164123058319, 0.16357989609241486]\n",
      "loss: 0.298969  [327680/343145] real loss: 0.29896900057792664\n",
      "[0.0985625833272934, 0.19309139251708984, 0.1617152988910675, 0.12835878133773804, 0.21865811944007874, 0.31101617217063904, 0.18033525347709656]\n",
      "[0.14522850513458252, 0.417074978351593, 0.2423262894153595, 0.14888310432434082, 0.1902748942375183, 0.3551439940929413, 0.23981718719005585]\n",
      "LOSSES TRAIN: 0.30706787818954107 LOSSES TEST: 0.30839246369543527\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.293915  [    0/343145] real loss: 0.2939148545265198\n",
      "[0.24658402800559998, 0.18760567903518677, 0.3360198140144348, 2.463421106338501, 0.26460492610931396, 0.10772477835416794, 0.6128903031349182]\n",
      "[0.27600201964378357, 0.22224730253219604, 0.5088196396827698, 1.9669177532196045, 0.2473324090242386, 0.12059620022773743, 1.0465381145477295]\n",
      "loss: 0.300908  [65536/343145] real loss: 0.30090779066085815\n",
      "[0.21900328993797302, 0.17548450827598572, 0.6848748326301575, 0.1834058314561844, 0.25311437249183655, 0.10770320892333984, 0.139802023768425]\n",
      "[0.3201698064804077, 0.1974886953830719, 0.9358717799186707, 0.17147471010684967, 0.46252650022506714, 0.06198129802942276, 0.11582300066947937]\n",
      "loss: 0.296992  [131072/343145] real loss: 0.2969922423362732\n",
      "[0.2605917751789093, 0.2958407700061798, 0.306753009557724, 1.3650835752487183, 0.14714688062667847, 0.2776663899421692, 0.3781169354915619]\n",
      "[0.3193312883377075, 0.3391498923301697, 0.474787175655365, 1.4217110872268677, 0.10906299948692322, 0.28107360005378723, 0.4301582872867584]\n",
      "loss: 0.313260  [196608/343145] real loss: 0.31326043605804443\n",
      "[0.15758055448532104, 0.728324830532074, 0.20143650472164154, 0.12358686327934265, 0.10875256359577179, 0.1480478048324585, 0.4236808121204376]\n",
      "[0.1659892052412033, 0.4985409677028656, 0.23167088627815247, 0.18883560597896576, 0.08646909892559052, 0.24376139044761658, 0.5176287889480591]\n",
      "loss: 0.308943  [262144/343145] real loss: 0.30894315242767334\n",
      "[0.24938911199569702, 0.18558651208877563, 0.7251325249671936, 0.1709558069705963, 0.12422722578048706, 0.24924755096435547, 0.25756338238716125]\n",
      "[0.2646852135658264, 0.26270291209220886, 0.8089411854743958, 0.21499069035053253, 0.10802240669727325, 0.4689100980758667, 0.34048980474472046]\n",
      "loss: 0.295886  [327680/343145] real loss: 0.2958860397338867\n",
      "[0.21037760376930237, 0.13981656730175018, 0.289061576128006, 0.11784446239471436, 0.11545337736606598, 0.21188275516033173, 0.40154892206192017]\n",
      "[0.3582916855812073, 0.18016919493675232, 0.41926610469818115, 0.14776550233364105, 0.11756869405508041, 0.2380490005016327, 0.5872595906257629]\n",
      "LOSSES TRAIN: 0.3035785069777852 LOSSES TEST: 0.3059429540520623\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.356569  [    0/343145] real loss: 0.3565690815448761\n",
      "[0.6956927180290222, 0.493971049785614, 0.2113526165485382, 0.15997648239135742, 0.3959901034832001, 0.09944722056388855, 0.7568237781524658]\n",
      "[1.0025110244750977, 0.5084690451622009, 0.16643820703029633, 0.17941780388355255, 0.3674691915512085, 0.06490619480609894, 0.9292218685150146]\n",
      "loss: 0.297462  [65536/343145] real loss: 0.2974618375301361\n",
      "[0.22560635209083557, 0.32298579812049866, 0.43700897693634033, 0.16347549855709076, 0.3165338635444641, 0.2377106100320816, 0.11590442061424255]\n",
      "[0.2638508081436157, 0.26781919598579407, 0.6542710065841675, 0.21393738687038422, 0.232424795627594, 0.26160481572151184, 0.10636630654335022]\n",
      "loss: 0.296980  [131072/343145] real loss: 0.2969798445701599\n",
      "[0.13188713788986206, 0.23816432058811188, 0.27569854259490967, 0.6872320175170898, 0.544962465763092, 0.18972797691822052, 0.15984132885932922]\n",
      "[0.37850791215896606, 0.18056049942970276, 0.5478901863098145, 0.5984703302383423, 0.3960708975791931, 0.2935996949672699, 0.1601646989583969]\n",
      "loss: 0.285743  [196608/343145] real loss: 0.2857432961463928\n",
      "[0.2653573155403137, 0.31700846552848816, 0.4576098918914795, 0.4615170359611511, 0.2890688478946686, 0.2826997637748718, 0.19880080223083496]\n",
      "[0.25778570771217346, 0.36619579792022705, 0.4343930184841156, 0.8338602185249329, 0.27311971783638, 0.29254209995269775, 0.28283581137657166]\n",
      "loss: 0.294983  [262144/343145] real loss: 0.29498302936553955\n",
      "[0.9021203517913818, 0.35201168060302734, 0.6504082083702087, 0.2776908874511719, 0.18763583898544312, 0.19417831301689148, 0.2268061637878418]\n",
      "[0.7707827091217041, 0.31259438395500183, 0.9273552298545837, 0.3864631950855255, 0.2198667973279953, 0.2817925214767456, 0.22189749777317047]\n",
      "loss: 0.290347  [327680/343145] real loss: 0.2903468608856201\n",
      "[0.13924914598464966, 0.3320325016975403, 0.861225962638855, 0.16330057382583618, 0.19343110918998718, 0.47485995292663574, 0.5852411389350891]\n",
      "[0.13628080487251282, 0.35927870869636536, 2.009979724884033, 0.19470739364624023, 0.21583770215511322, 0.28878968954086304, 1.0452512502670288]\n",
      "LOSSES TRAIN: 0.30115331815821783 LOSSES TEST: 0.3051245226746514\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.287685  [    0/343145] real loss: 0.28768450021743774\n",
      "[0.5504305362701416, 1.27945077419281, 0.25505155324935913, 0.09861373901367188, 0.22617584466934204, 0.2271556854248047, 0.21379327774047852]\n",
      "[0.8853319883346558, 1.334434986114502, 0.2915979027748108, 0.0699274018406868, 0.13498170673847198, 0.4646523892879486, 0.3012988865375519]\n",
      "loss: 0.293528  [65536/343145] real loss: 0.2935282588005066\n",
      "[0.07255791127681732, 0.37497377395629883, 0.26339468359947205, 0.16641058027744293, 0.12997496128082275, 0.5207911729812622, 0.1564629226922989]\n",
      "[0.03340449929237366, 0.5321013927459717, 0.16390760242938995, 0.24438409507274628, 0.15909579396247864, 0.6496222019195557, 0.26691848039627075]\n",
      "loss: 0.299217  [131072/343145] real loss: 0.29921698570251465\n",
      "[0.5497748851776123, 0.29435300827026367, 0.3583677113056183, 0.33886224031448364, 0.1999148279428482, 0.6696237325668335, 0.5886470079421997]\n",
      "[0.49950918555259705, 0.34293779730796814, 0.4009684920310974, 0.5185064673423767, 0.3749566972255707, 0.9012283086776733, 0.8092984557151794]\n",
      "loss: 0.289068  [196608/343145] real loss: 0.2890678346157074\n",
      "[0.3531152606010437, 0.24817585945129395, 0.16974857449531555, 0.1938265860080719, 0.31286588311195374, 0.44215506315231323, 0.10997471958398819]\n",
      "[0.42513948678970337, 0.33405131101608276, 0.31512290239334106, 0.22611229121685028, 0.9427686333656311, 0.6658452749252319, 0.12378060817718506]\n",
      "loss: 0.293221  [262144/343145] real loss: 0.2932208180427551\n",
      "[0.1852026730775833, 0.3643690347671509, 0.2339635044336319, 1.5315401554107666, 1.1855707168579102, 0.3406253457069397, 0.10743740200996399]\n",
      "[0.19801750779151917, 0.44476819038391113, 0.36457547545433044, 1.7508162260055542, 0.581345796585083, 0.5622379779815674, 0.17336060106754303]\n",
      "loss: 0.295211  [327680/343145] real loss: 0.2952105700969696\n",
      "[0.5010553598403931, 0.20266565680503845, 0.3457881808280945, 0.1187303215265274, 0.326945960521698, 0.3121189475059509, 0.274834007024765]\n",
      "[0.5914310812950134, 0.2471725046634674, 0.5187153816223145, 0.12324430048465729, 0.363234281539917, 0.3658778965473175, 0.3360382914543152]\n",
      "LOSSES TRAIN: 0.29867496093114215 LOSSES TEST: 0.30575857985587346\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.294870  [    0/343145] real loss: 0.29487037658691406\n",
      "[0.2644557058811188, 0.3180848956108093, 0.17660164833068848, 0.2633289098739624, 1.0758693218231201, 0.09819011390209198, 0.536219596862793]\n",
      "[0.2811487019062042, 0.5504937171936035, 0.2331223040819168, 0.3280313014984131, 0.7040178179740906, 0.18676000833511353, 0.5594005584716797]\n",
      "loss: 0.358906  [65536/343145] real loss: 0.35890594124794006\n",
      "[0.17156115174293518, 0.3601088523864746, 0.3002167344093323, 0.12433084845542908, 0.24336019158363342, 0.16261449456214905, 0.1740855872631073]\n",
      "[0.1623000055551529, 0.5502846240997314, 0.4472893178462982, 0.1665189117193222, 0.32083660364151, 0.20603801310062408, 0.2226240038871765]\n",
      "loss: 0.290525  [131072/343145] real loss: 0.2905252277851105\n",
      "[0.20467178523540497, 0.5177684426307678, 0.22602005302906036, 0.4548805058002472, 0.18950402736663818, 0.3560188114643097, 0.45378348231315613]\n",
      "[0.19566871225833893, 0.7612146735191345, 0.2516227066516876, 0.6937080025672913, 0.2068839967250824, 0.6938339471817017, 0.3735857903957367]\n",
      "loss: 0.308907  [196608/343145] real loss: 0.30890700221061707\n",
      "[0.46661922335624695, 0.29769188165664673, 0.47502514719963074, 0.2619251608848572, 0.16099804639816284, 0.21240995824337006, 0.2730180025100708]\n",
      "[1.025317668914795, 0.4334867000579834, 0.8498148322105408, 0.20857051014900208, 0.141361802816391, 0.24744971096515656, 0.6183518171310425]\n",
      "loss: 0.290318  [262144/343145] real loss: 0.2903181314468384\n",
      "[0.6796910166740417, 0.21618697047233582, 0.3084239065647125, 0.19581961631774902, 0.6535550951957703, 0.2327018678188324, 0.24959656596183777]\n",
      "[0.7276893854141235, 0.18039719760417938, 0.3141120970249176, 0.19918091595172882, 0.5839587450027466, 0.3943929970264435, 0.27062660455703735]\n",
      "loss: 0.304347  [327680/343145] real loss: 0.3043470084667206\n",
      "[0.1518479436635971, 0.2324202060699463, 0.22525639832019806, 0.16824251413345337, 0.3224025070667267, 0.2291957288980484, 0.3845936954021454]\n",
      "[0.2524121105670929, 0.20488488674163818, 0.2820602059364319, 0.1377301961183548, 0.30930349230766296, 0.22796979546546936, 0.46114382147789]\n",
      "LOSSES TRAIN: 0.29655441287018003 LOSSES TEST: 0.30491094078336445\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.306532  [    0/343145] real loss: 0.30653175711631775\n",
      "[0.8259766697883606, 0.2421475648880005, 0.07377518713474274, 0.24557965993881226, 0.5400447845458984, 0.25678667426109314, 1.2737711668014526]\n",
      "[0.5174778699874878, 0.21485430002212524, 0.057097502052783966, 0.32811129093170166, 0.5298603773117065, 0.3525483012199402, 0.8935415148735046]\n",
      "loss: 0.279651  [65536/343145] real loss: 0.2796505391597748\n",
      "[0.34225767850875854, 0.2523079812526703, 0.11984947323799133, 0.12879560887813568, 0.19865165650844574, 0.15395987033843994, 0.17744100093841553]\n",
      "[0.406100869178772, 0.28130578994750977, 0.1029563918709755, 0.13281939923763275, 0.255998820066452, 0.20091210305690765, 0.27552610635757446]\n",
      "loss: 0.287157  [131072/343145] real loss: 0.2871566414833069\n",
      "[0.10959197580814362, 0.2611277997493744, 0.1818605214357376, 0.10441412031650543, 0.15364132821559906, 0.2452058643102646, 0.09434742480516434]\n",
      "[0.10856559872627258, 0.38608571887016296, 0.20036961138248444, 0.13376690447330475, 0.1368349939584732, 0.3425549864768982, 0.14692839980125427]\n",
      "loss: 0.293905  [196608/343145] real loss: 0.2939053773880005\n",
      "[0.4257228970527649, 0.14691181480884552, 0.141580268740654, 0.38602757453918457, 0.32534152269363403, 0.5225839614868164, 0.332296222448349]\n",
      "[0.5480290055274963, 0.17684710025787354, 0.1738865077495575, 0.44353991746902466, 0.33027198910713196, 0.6695154309272766, 0.38251280784606934]\n",
      "loss: 0.289482  [262144/343145] real loss: 0.2894820272922516\n",
      "[0.45964446663856506, 0.25728997588157654, 0.1086587905883789, 1.9362540245056152, 0.44882452487945557, 0.15157809853553772, 0.6848695874214172]\n",
      "[0.6381387114524841, 0.24012430012226105, 0.20106570422649384, 2.0467100143432617, 0.5544435977935791, 0.17645978927612305, 0.5680046081542969]\n",
      "loss: 0.331514  [327680/343145] real loss: 0.3315139412879944\n",
      "[0.12499058991670609, 0.250069260597229, 0.31090247631073, 0.4560391306877136, 0.7843575477600098, 0.219356507062912, 0.1698835790157318]\n",
      "[0.21635659039020538, 0.2105589061975479, 0.5568141937255859, 0.369721919298172, 0.4289657771587372, 0.2548152208328247, 0.16591839492321014]\n",
      "LOSSES TRAIN: 0.29589038838942844 LOSSES TEST: 0.30734844009081524\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.313722  [    0/343145] real loss: 0.3137218654155731\n",
      "[0.2342166304588318, 0.12958672642707825, 0.403962105512619, 0.14989584684371948, 0.3204306662082672, 0.47039422392845154, 0.48997846245765686]\n",
      "[0.2996114194393158, 0.18004749715328217, 0.5499234199523926, 0.20488570630550385, 0.20620939135551453, 0.6340449452400208, 0.5167551040649414]\n",
      "loss: 0.285322  [65536/343145] real loss: 0.2853218913078308\n",
      "[0.49562352895736694, 0.6863768100738525, 0.579181969165802, 0.27447181940078735, 0.208502858877182, 0.12404510378837585, 0.3491455018520355]\n",
      "[1.2655107975006104, 0.4571591913700104, 0.9553139209747314, 0.29217439889907837, 0.1697693020105362, 0.09952069818973541, 0.3714631199836731]\n",
      "loss: 0.293610  [131072/343145] real loss: 0.2936101257801056\n",
      "[0.39531809091567993, 0.11355310678482056, 0.1717342883348465, 0.2413647323846817, 0.32794860005378723, 0.4172949194908142, 0.08305630087852478]\n",
      "[0.5973038077354431, 0.13171400129795074, 0.2565630078315735, 0.3954392969608307, 0.4724780023097992, 0.5629056096076965, 0.08593149483203888]\n",
      "loss: 0.299137  [196608/343145] real loss: 0.29913660883903503\n",
      "[0.29913538694381714, 0.2014537751674652, 0.368643581867218, 0.4498600661754608, 0.19424796104431152, 0.2946013808250427, 0.08490931242704391]\n",
      "[0.31833311915397644, 0.2282795011997223, 0.43093058466911316, 0.34065020084381104, 0.3751696050167084, 0.23514461517333984, 0.09562169760465622]\n",
      "loss: 0.291698  [262144/343145] real loss: 0.2916983962059021\n",
      "[0.23319879174232483, 0.18214088678359985, 0.399183452129364, 0.1767648458480835, 0.4111834466457367, 0.21241620182991028, 1.1540553569793701]\n",
      "[0.23640428483486176, 0.20171669125556946, 0.6496232748031616, 0.32463499903678894, 0.42434418201446533, 0.23001879453659058, 1.5124740600585938]\n",
      "loss: 0.321164  [327680/343145] real loss: 0.3211642801761627\n",
      "[0.36613091826438904, 0.2948291301727295, 0.25062185525894165, 0.10135427117347717, 0.5718233585357666, 0.09659544378519058, 0.29453593492507935]\n",
      "[0.42970579862594604, 0.4117986261844635, 0.29751309752464294, 0.14655590057373047, 0.8441605567932129, 0.12099039554595947, 0.4733503758907318]\n",
      "LOSSES TRAIN: 0.29411869815417696 LOSSES TEST: 0.3064899558112735\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.291261  [    0/343145] real loss: 0.29126057028770447\n",
      "[0.18971702456474304, 0.282316654920578, 0.6299899220466614, 0.2716556489467621, 0.27224114537239075, 0.22336159646511078, 0.3284156024456024]\n",
      "[0.33351069688796997, 0.23490619659423828, 0.45755597949028015, 0.29026439785957336, 0.37402668595314026, 0.21744610369205475, 1.057432770729065]\n",
      "loss: 0.283738  [65536/343145] real loss: 0.2837381064891815\n",
      "[0.6049628257751465, 0.4453246295452118, 0.14638540148735046, 0.27727729082107544, 1.0635145902633667, 0.26700931787490845, 0.2088707685470581]\n",
      "[0.8284329175949097, 0.5400435328483582, 0.24083811044692993, 0.3282434046268463, 0.8776596784591675, 0.20142020285129547, 0.2973766028881073]\n",
      "loss: 0.288454  [131072/343145] real loss: 0.28845444321632385\n",
      "[0.1588437855243683, 0.33999329805374146, 0.11026760935783386, 0.45170727372169495, 0.2179492861032486, 0.2190488576889038, 0.21941633522510529]\n",
      "[0.2619253098964691, 0.34579211473464966, 0.19091080129146576, 0.45026907324790955, 0.1925531029701233, 0.18948790431022644, 0.17612290382385254]\n",
      "loss: 0.304624  [196608/343145] real loss: 0.3046239912509918\n",
      "[0.14666730165481567, 0.18508049845695496, 0.18025511503219604, 1.5758464336395264, 0.4335011839866638, 0.14288675785064697, 0.14819258451461792]\n",
      "[0.16843530535697937, 0.16268399357795715, 0.2147206962108612, 1.4673835039138794, 0.5508626103401184, 0.0922825038433075, 0.16057419776916504]\n",
      "loss: 0.285079  [262144/343145] real loss: 0.28507930040359497\n",
      "[0.35279741883277893, 0.2731473743915558, 0.15474006533622742, 0.8536456823348999, 0.294882595539093, 0.7934585809707642, 0.36704355478286743]\n",
      "[0.4487200081348419, 0.1292375922203064, 0.15970809757709503, 0.82635897397995, 0.3299171030521393, 0.5826382637023926, 0.44522619247436523]\n",
      "loss: 0.285762  [327680/343145] real loss: 0.2857617139816284\n",
      "[0.34534764289855957, 0.11297760903835297, 0.3818569779396057, 0.10798336565494537, 0.0970345139503479, 0.39650803804397583, 0.34685689210891724]\n",
      "[0.33849048614501953, 0.10902970284223557, 0.5527499914169312, 0.0639382004737854, 0.09793039411306381, 0.3672989010810852, 0.44132861495018005]\n",
      "LOSSES TRAIN: 0.29338243426311583 LOSSES TEST: 0.30667569807597567\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.281776  [    0/343145] real loss: 0.28177645802497864\n",
      "[0.3915857672691345, 0.5351181030273438, 0.34292712807655334, 0.34746167063713074, 0.13532185554504395, 0.3386632204055786, 0.3786728084087372]\n",
      "[0.43168720602989197, 0.25747230648994446, 0.35753220319747925, 0.26497259736061096, 0.13477149605751038, 0.47921222448349, 0.5196151733398438]\n",
      "loss: 0.283774  [65536/343145] real loss: 0.28377437591552734\n",
      "[0.20794156193733215, 0.3006962239742279, 0.25831884145736694, 0.35645222663879395, 0.6696206331253052, 0.23662470281124115, 0.10711471736431122]\n",
      "[0.2561427056789398, 0.24331559240818024, 0.290411114692688, 0.2755129933357239, 1.7222214937210083, 0.24683649837970734, 0.08229070156812668]\n",
      "loss: 0.293829  [131072/343145] real loss: 0.29382914304733276\n",
      "[0.2648669481277466, 0.1477455496788025, 0.09268395602703094, 0.7027693390846252, 0.22608083486557007, 0.19525954127311707, 0.41009819507598877]\n",
      "[0.2683972120285034, 0.23075619339942932, 0.09247750043869019, 0.7547345757484436, 0.3102652132511139, 0.30631890892982483, 0.34255051612854004]\n",
      "loss: 0.286314  [196608/343145] real loss: 0.28631359338760376\n",
      "[0.13423073291778564, 0.10765251517295837, 0.6899898052215576, 0.3183731436729431, 0.23307359218597412, 0.2884206175804138, 0.2609673738479614]\n",
      "[0.21173420548439026, 0.226016104221344, 0.9503334760665894, 0.5283352732658386, 0.3215648829936981, 0.32717740535736084, 0.3155350089073181]\n",
      "loss: 0.286926  [262144/343145] real loss: 0.2869260609149933\n",
      "[0.1427580714225769, 0.2640804946422577, 0.14908814430236816, 0.1956850290298462, 0.24747979640960693, 0.10264980792999268, 0.2285136878490448]\n",
      "[0.15800368785858154, 0.2526930868625641, 0.10902859270572662, 0.18108029663562775, 0.24252869188785553, 0.09091710299253464, 0.26254770159721375]\n",
      "loss: 0.286565  [327680/343145] real loss: 0.28656479716300964\n",
      "[0.1806316077709198, 0.2180565595626831, 0.2532705068588257, 0.24814370274543762, 0.09457340836524963, 0.19250896573066711, 0.2602460980415344]\n",
      "[0.2289113998413086, 0.19140300154685974, 0.3098334074020386, 0.2709216773509979, 0.09302239865064621, 0.2541288137435913, 0.2454896867275238]\n",
      "LOSSES TRAIN: 0.29262398254303706 LOSSES TEST: 0.3093097366037823\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.295883  [    0/343145] real loss: 0.29588282108306885\n",
      "[0.3803693950176239, 0.20407427847385406, 0.1286708265542984, 0.2676624655723572, 0.1926354616880417, 0.13542979955673218, 0.3440603017807007]\n",
      "[0.6563854217529297, 0.22706419229507446, 0.13455580174922943, 0.39523690938949585, 0.24213150143623352, 0.24741101264953613, 0.3976616859436035]\n",
      "loss: 0.276412  [65536/343145] real loss: 0.27641168236732483\n",
      "[0.33426976203918457, 0.27956631779670715, 0.2858735918998718, 0.45025843381881714, 0.2463635504245758, 0.2193828523159027, 0.3211307227611542]\n",
      "[0.2733367085456848, 0.24500709772109985, 0.6127845048904419, 0.44123268127441406, 0.2753724157810211, 0.29268679022789, 0.4904830753803253]\n",
      "loss: 0.282300  [131072/343145] real loss: 0.28230008482933044\n",
      "[1.0577824115753174, 0.24679496884346008, 0.4777749478816986, 0.19843612611293793, 0.7368524074554443, 0.21194759011268616, 0.07881079614162445]\n",
      "[0.6126458048820496, 0.27232471108436584, 0.8364770412445068, 0.3250848948955536, 0.6419268846511841, 0.22654540836811066, 0.09049870073795319]\n",
      "loss: 0.279658  [196608/343145] real loss: 0.27965763211250305\n",
      "[0.24644845724105835, 0.18999342620372772, 0.23089434206485748, 0.22793219983577728, 0.2688998878002167, 0.1806589663028717, 0.8595533967018127]\n",
      "[0.4348229169845581, 0.24760501086711884, 0.20694389939308167, 0.21826298534870148, 0.262635201215744, 0.1792849898338318, 1.0631258487701416]\n",
      "loss: 0.318461  [262144/343145] real loss: 0.3184608221054077\n",
      "[0.20610445737838745, 0.09089180082082748, 0.7241629362106323, 0.2616751194000244, 0.22528651356697083, 0.43219029903411865, 0.10441796481609344]\n",
      "[0.21592089533805847, 0.30401599407196045, 1.0823862552642822, 0.5372806787490845, 0.3074356019496918, 0.6989037394523621, 0.11820419132709503]\n",
      "loss: 0.286494  [327680/343145] real loss: 0.28649359941482544\n",
      "[0.1955539435148239, 0.16974037885665894, 0.18863637745380402, 0.18610483407974243, 0.1689908355474472, 0.2804184556007385, 0.5030599236488342]\n",
      "[0.16233579814434052, 0.13274450600147247, 0.17491589486598969, 0.2499966025352478, 0.12014319747686386, 0.28890660405158997, 0.6156156659126282]\n",
      "LOSSES TRAIN: 0.29175821585314615 LOSSES TEST: 0.3081746640659514\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.294608  [    0/343145] real loss: 0.294607549905777\n",
      "[0.38983607292175293, 0.10027411580085754, 0.3315616548061371, 0.23607328534126282, 0.2275514155626297, 0.320696622133255, 0.18069905042648315]\n",
      "[0.4644725024700165, 0.1389216035604477, 0.2500216066837311, 0.3261435031890869, 0.32631781697273254, 0.5526714324951172, 0.1506388932466507]\n",
      "loss: 0.307534  [65536/343145] real loss: 0.30753350257873535\n",
      "[0.36943212151527405, 0.29129230976104736, 0.3243691027164459, 0.128826305270195, 0.20082564651966095, 0.3276503384113312, 0.575482964515686]\n",
      "[0.5002087950706482, 0.25179779529571533, 0.4187467098236084, 0.1630133092403412, 0.19882409274578094, 0.3964676856994629, 0.63026362657547]\n",
      "loss: 0.290300  [131072/343145] real loss: 0.2903001010417938\n",
      "[0.28519976139068604, 0.13777750730514526, 0.5888628959655762, 0.22945761680603027, 0.20912891626358032, 0.2494838833808899, 0.17915505170822144]\n",
      "[0.43848928809165955, 0.16617639362812042, 0.912369430065155, 0.20128969848155975, 0.1626763939857483, 0.21915119886398315, 0.23787620663642883]\n",
      "loss: 0.318519  [196608/343145] real loss: 0.3185189962387085\n",
      "[0.3874088227748871, 0.21184340119361877, 0.49503934383392334, 0.1673753559589386, 0.16826480627059937, 0.21565331518650055, 0.056664057075977325]\n",
      "[0.31409579515457153, 0.19528929889202118, 0.7858556509017944, 0.11083680391311646, 0.19016459584236145, 0.22310809791088104, 0.06417270004749298]\n",
      "loss: 0.291644  [262144/343145] real loss: 0.2916441857814789\n",
      "[0.14799705147743225, 0.4829599857330322, 0.08841145038604736, 0.18620479106903076, 0.24271124601364136, 0.3885490596294403, 0.3435593545436859]\n",
      "[0.23628130555152893, 0.3550392985343933, 0.1053433045744896, 0.14666900038719177, 0.3285568058490753, 0.5896592736244202, 0.28337129950523376]\n",
      "loss: 0.288150  [327680/343145] real loss: 0.28814977407455444\n",
      "[0.2294132113456726, 0.28223565220832825, 0.2556332051753998, 0.12114298343658447, 0.23471947014331818, 0.276212215423584, 0.2547193765640259]\n",
      "[0.28973349928855896, 0.5181835889816284, 0.24789629876613617, 0.10465499758720398, 0.3306369185447693, 0.3277581036090851, 0.43663060665130615]\n",
      "LOSSES TRAIN: 0.2907339944725945 LOSSES TEST: 0.3087487362679981\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.329448  [    0/343145] real loss: 0.3294476568698883\n",
      "[0.2643968164920807, 0.7394750118255615, 0.6059980392456055, 0.42503657937049866, 1.122947096824646, 0.16561095416545868, 0.28395360708236694]\n",
      "[0.29484081268310547, 1.1031825542449951, 0.5924739837646484, 0.4223781228065491, 1.4956012964248657, 0.15378209948539734, 0.29503750801086426]\n",
      "loss: 0.288859  [65536/343145] real loss: 0.28885871171951294\n",
      "[0.33535006642341614, 0.3704507350921631, 0.2343401163816452, 0.16582931578159332, 0.2987799346446991, 0.3384562134742737, 0.25494518876075745]\n",
      "[0.48603707551956177, 0.6323652863502502, 0.24887800216674805, 0.19918091595172882, 0.41049307584762573, 0.3059268891811371, 0.2933700978755951]\n",
      "loss: 0.290137  [131072/343145] real loss: 0.29013699293136597\n",
      "[0.1870078295469284, 0.16915878653526306, 0.1647048145532608, 0.6417017579078674, 0.27355968952178955, 1.301845669746399, 0.2042638510465622]\n",
      "[0.1700393110513687, 0.1304105967283249, 0.11057340353727341, 0.7427657842636108, 0.44814738631248474, 2.8761701583862305, 0.21405290067195892]\n",
      "loss: 0.284864  [196608/343145] real loss: 0.28486350178718567\n",
      "[0.1783522218465805, 0.31800782680511475, 0.43344491720199585, 0.1728309541940689, 0.3008352220058441, 0.1566120833158493, 0.6213733553886414]\n",
      "[0.21441060304641724, 0.2797917127609253, 0.6477218866348267, 0.21911069750785828, 0.2658087909221649, 0.13352730870246887, 0.8293334245681763]\n",
      "loss: 0.282817  [262144/343145] real loss: 0.2828170657157898\n",
      "[0.2233944684267044, 0.3239935636520386, 0.3393574357032776, 0.12725740671157837, 0.1556338220834732, 0.22564609348773956, 0.28854694962501526]\n",
      "[0.3634980022907257, 0.736871063709259, 0.36957690119743347, 0.11339590698480606, 0.17236210405826569, 0.22414140403270721, 0.3262799084186554]\n",
      "loss: 0.290720  [327680/343145] real loss: 0.29071950912475586\n",
      "[0.5444390773773193, 0.1899084597826004, 0.12229684740304947, 0.4344543218612671, 0.2382241189479828, 0.1595183163881302, 0.27027463912963867]\n",
      "[0.7956557869911194, 0.17678751051425934, 0.14110170304775238, 0.27388468384742737, 0.30458760261535645, 0.2101738005876541, 0.3427557051181793]\n",
      "LOSSES TRAIN: 0.2906293524872689 LOSSES TEST: 0.3101039613996233\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.306644  [    0/343145] real loss: 0.30664411187171936\n",
      "[0.18936187028884888, 0.16474810242652893, 0.2689706087112427, 0.5619308948516846, 0.2336691915988922, 0.3035508990287781, 0.17302218079566956]\n",
      "[0.12774311006069183, 0.25616079568862915, 0.3415148854255676, 0.800667405128479, 0.2839033901691437, 0.3636789917945862, 0.1672039031982422]\n",
      "loss: 0.282256  [65536/343145] real loss: 0.28225579857826233\n",
      "[0.19573722779750824, 0.10781288146972656, 0.13774226605892181, 0.9454084038734436, 0.6610429883003235, 0.23401369154453278, 0.31179434061050415]\n",
      "[0.23196779191493988, 0.10312510281801224, 0.18644899129867554, 0.8995271921157837, 0.9531019330024719, 0.23309339582920074, 0.4427812099456787]\n",
      "loss: 0.286002  [131072/343145] real loss: 0.2860015034675598\n",
      "[0.2673247158527374, 0.25876161456108093, 0.24117830395698547, 0.5030343532562256, 0.32694491744041443, 0.3196210265159607, 0.1443166434764862]\n",
      "[0.2462632954120636, 0.2700355052947998, 0.2885355055332184, 0.5119205117225647, 0.4558919072151184, 0.3836608827114105, 0.17659731209278107]\n",
      "loss: 0.429566  [196608/343145] real loss: 0.4295657277107239\n",
      "[0.31796377897262573, 0.20341046154499054, 0.13533318042755127, 1.3484388589859009, 0.31925085186958313, 0.4745413064956665, 0.22880415618419647]\n",
      "[0.5149664878845215, 0.2346293032169342, 0.1752208024263382, 2.241520404815674, 0.303376704454422, 0.28530529141426086, 0.22614100575447083]\n",
      "loss: 0.281140  [262144/343145] real loss: 0.28114011883735657\n",
      "[0.3017284572124481, 0.32225537300109863, 0.26221638917922974, 0.6365911960601807, 0.1755433976650238, 0.26074665784835815, 0.7811304926872253]\n",
      "[0.3214569091796875, 0.30282771587371826, 0.26279929280281067, 0.6718525886535645, 0.2197778970003128, 0.19410470128059387, 0.6229788064956665]\n",
      "loss: 0.283929  [327680/343145] real loss: 0.28392913937568665\n",
      "[0.05677665024995804, 0.25043776631355286, 0.16706760227680206, 0.36802151799201965, 0.24538208544254303, 0.1597173511981964, 0.2362954318523407]\n",
      "[0.05486229807138443, 0.32965749502182007, 0.2301889955997467, 0.40904000401496887, 0.1694377064704895, 0.14229010045528412, 0.20868650078773499]\n",
      "LOSSES TRAIN: 0.2909802787360691 LOSSES TEST: 0.309434650909333\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.285290  [    0/343145] real loss: 0.28529009222984314\n",
      "[0.3853931427001953, 0.17727099359035492, 0.29091817140579224, 0.16596925258636475, 0.12019246071577072, 0.7562947273254395, 0.21124017238616943]\n",
      "[0.27261120080947876, 0.22960929572582245, 0.41856831312179565, 0.2565039098262787, 0.1014975979924202, 0.6031386256217957, 0.24060529470443726]\n",
      "loss: 0.286026  [65536/343145] real loss: 0.2860260009765625\n",
      "[0.2405340075492859, 0.4140193462371826, 0.41296422481536865, 0.29758912324905396, 0.358417272567749, 0.208000048995018, 0.46402573585510254]\n",
      "[0.2428814023733139, 0.5034146904945374, 0.43866682052612305, 0.3352818191051483, 0.29344069957733154, 0.15662869811058044, 0.6589831113815308]\n",
      "loss: 0.306969  [131072/343145] real loss: 0.3069693446159363\n",
      "[0.20870806276798248, 0.248398557305336, 0.5481973886489868, 0.20740610361099243, 0.154722198843956, 0.15119579434394836, 0.2140548676252365]\n",
      "[0.2234521061182022, 0.27671560645103455, 0.7268167734146118, 0.1548108011484146, 0.1432034969329834, 0.1587764024734497, 0.25478920340538025]\n",
      "loss: 0.279747  [196608/343145] real loss: 0.27974656224250793\n",
      "[0.7288377285003662, 0.24322353303432465, 0.3414522111415863, 0.18202893435955048, 0.46531224250793457, 0.3140449821949005, 0.3183958828449249]\n",
      "[0.5925104022026062, 0.2022021859884262, 0.8327982425689697, 0.23181170225143433, 0.8139832615852356, 0.3455837070941925, 0.4829240143299103]\n",
      "loss: 0.284502  [262144/343145] real loss: 0.28450214862823486\n",
      "[0.2256399393081665, 0.21622006595134735, 0.18320225179195404, 0.24859321117401123, 0.4790431261062622, 0.2035636305809021, 0.15648451447486877]\n",
      "[0.1994355171918869, 0.20158688724040985, 0.24157670140266418, 0.2985784113407135, 0.7312154769897461, 0.35776689648628235, 0.35896480083465576]\n",
      "loss: 0.276100  [327680/343145] real loss: 0.27610042691230774\n",
      "[0.6412950158119202, 0.16155801713466644, 0.17611271142959595, 0.31361159682273865, 0.27859124541282654, 0.17471180856227875, 0.1907927393913269]\n",
      "[1.1054726839065552, 0.27552109956741333, 0.180185005068779, 0.3263646066188812, 0.3889468014240265, 0.20041689276695251, 0.3211773931980133]\n",
      "LOSSES TRAIN: 0.2888171172567776 LOSSES TEST: 0.31057827955200557\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.281449  [    0/343145] real loss: 0.2814493477344513\n",
      "[0.1916085183620453, 0.7183626294136047, 0.4313305616378784, 0.929161787033081, 0.1081324890255928, 0.4521641433238983, 0.2023952156305313]\n",
      "[0.20171380043029785, 1.210615634918213, 0.6091514825820923, 1.449454426765442, 0.14217950403690338, 0.46925443410873413, 0.45106297731399536]\n",
      "loss: 0.285486  [65536/343145] real loss: 0.2854860723018646\n",
      "[0.2823309898376465, 0.250144898891449, 0.2877529561519623, 0.29563093185424805, 0.2173643261194229, 0.48288828134536743, 0.453308641910553]\n",
      "[0.3729606866836548, 0.2949317991733551, 0.3465636074542999, 0.31752729415893555, 0.28948861360549927, 0.9498965740203857, 0.3428477942943573]\n",
      "loss: 0.291401  [131072/343145] real loss: 0.29140111804008484\n",
      "[0.36239904165267944, 0.41286760568618774, 0.38129666447639465, 0.4569418132305145, 0.34755951166152954, 0.2153913527727127, 0.283134400844574]\n",
      "[0.3435424864292145, 0.45926788449287415, 0.36119940876960754, 0.33970990777015686, 0.3676024079322815, 0.5540527701377869, 0.42086997628211975]\n",
      "loss: 0.285780  [196608/343145] real loss: 0.28577980399131775\n",
      "[0.44394242763519287, 0.3429481089115143, 0.16105039417743683, 0.37859517335891724, 0.8148218989372253, 0.41787511110305786, 0.3653488755226135]\n",
      "[0.7806808948516846, 0.3097813129425049, 0.18533669412136078, 0.23291561007499695, 1.0046089887619019, 0.8297879099845886, 0.2698573172092438]\n",
      "loss: 0.283548  [262144/343145] real loss: 0.2835477292537689\n",
      "[0.08598284423351288, 0.29232123494148254, 1.1580082178115845, 0.15059036016464233, 0.15938784182071686, 0.49795758724212646, 0.5075593590736389]\n",
      "[0.15503180027008057, 0.3747148811817169, 1.6973999738693237, 0.24579760432243347, 0.19203290343284607, 0.5718464255332947, 0.4204554855823517]\n",
      "loss: 0.279078  [327680/343145] real loss: 0.2790781259536743\n",
      "[0.31568413972854614, 0.367502897977829, 0.13943056762218475, 0.8926337361335754, 0.9143087267875671, 0.6700842976570129, 0.32318124175071716]\n",
      "[0.2679154872894287, 0.477226585149765, 0.20906750857830048, 1.0514367818832397, 1.1927591562271118, 0.7181856036186218, 0.40493038296699524]\n",
      "LOSSES TRAIN: 0.2889471153418223 LOSSES TEST: 0.30991951198804946\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.325131  [    0/343145] real loss: 0.3251311182975769\n",
      "[0.20059534907341003, 0.15048998594284058, 0.2347068190574646, 0.5180032253265381, 0.24628931283950806, 0.3412100672721863, 0.1429367959499359]\n",
      "[0.20637430250644684, 0.15980879962444305, 0.26690179109573364, 0.4342428743839264, 0.30651479959487915, 0.38187310099601746, 0.12316469848155975]\n",
      "loss: 0.291653  [65536/343145] real loss: 0.2916531562805176\n",
      "[0.3092312812805176, 0.25757724046707153, 0.6736832857131958, 0.42910337448120117, 0.6036457419395447, 0.21902479231357574, 0.18490540981292725]\n",
      "[0.2576732039451599, 0.273808091878891, 0.8765388131141663, 0.5565673112869263, 0.7585760951042175, 0.20464390516281128, 0.31736260652542114]\n",
      "loss: 0.283445  [131072/343145] real loss: 0.28344547748565674\n",
      "[0.314676433801651, 0.28573065996170044, 0.2772302031517029, 0.31819769740104675, 0.404928982257843, 1.355648398399353, 0.4760969281196594]\n",
      "[0.40313011407852173, 0.3618099093437195, 0.24782828986644745, 0.331423282623291, 0.4694894850254059, 1.4107061624526978, 0.6023797988891602]\n",
      "loss: 0.301189  [196608/343145] real loss: 0.30118903517723083\n",
      "[0.26192784309387207, 0.8701748251914978, 0.33099374175071716, 0.13749784231185913, 0.15533480048179626, 0.2353956550359726, 0.419903427362442]\n",
      "[0.3090015947818756, 0.5067821145057678, 0.5100567936897278, 0.17403210699558258, 0.17170248925685883, 0.35961008071899414, 0.45804497599601746]\n",
      "loss: 0.287225  [262144/343145] real loss: 0.287224680185318\n",
      "[0.4901510775089264, 0.20432907342910767, 0.4379892945289612, 0.14423052966594696, 0.14188429713249207, 0.16961181163787842, 0.18665802478790283]\n",
      "[0.7025963068008423, 0.6166427731513977, 0.6871920824050903, 0.15442679822444916, 0.2090442031621933, 0.09551230072975159, 0.2307775914669037]\n",
      "loss: 0.283369  [327680/343145] real loss: 0.2833684980869293\n",
      "[0.2581401467323303, 0.5391255021095276, 0.18444380164146423, 0.2323118895292282, 0.4673709571361542, 0.08603961020708084, 0.198736771941185]\n",
      "[0.25778812170028687, 0.45103979110717773, 0.33357807993888855, 0.4200599193572998, 0.6170418858528137, 0.11900439858436584, 0.21198830008506775]\n",
      "LOSSES TRAIN: 0.28796498832248507 LOSSES TEST: 0.31284294383866446\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.277845  [    0/343145] real loss: 0.2778445780277252\n",
      "[0.12600699067115784, 0.336577445268631, 0.3748309910297394, 0.1958335041999817, 0.17701950669288635, 0.48577889800071716, 1.1481268405914307]\n",
      "[0.150580495595932, 0.45662960410118103, 0.34591570496559143, 0.1833030879497528, 0.3050203025341034, 0.4051970839500427, 1.3367774486541748]\n",
      "loss: 0.284023  [65536/343145] real loss: 0.2840227484703064\n",
      "[0.3262479901313782, 0.2306402623653412, 0.29585862159729004, 0.24107125401496887, 0.7718143463134766, 0.21412506699562073, 0.3240073323249817]\n",
      "[0.2961502969264984, 0.18807470798492432, 0.3350645899772644, 0.35672810673713684, 1.0986101627349854, 0.18736900389194489, 0.3809994161128998]\n",
      "loss: 0.280362  [131072/343145] real loss: 0.28036174178123474\n",
      "[0.3622347116470337, 0.4664122462272644, 0.24020901322364807, 0.7634971141815186, 0.19003121554851532, 0.23820112645626068, 0.4291270971298218]\n",
      "[0.3462322950363159, 0.6575855612754822, 0.25360578298568726, 0.5107980966567993, 0.3100152015686035, 0.22717760503292084, 0.6939219832420349]\n",
      "loss: 0.282328  [196608/343145] real loss: 0.2823280394077301\n",
      "[0.43394386768341064, 0.2865374684333801, 0.32836607098579407, 0.2650706470012665, 0.14288656413555145, 0.32921597361564636, 0.3541785478591919]\n",
      "[0.452239990234375, 0.2847287952899933, 0.3044689893722534, 0.29020601511001587, 0.1354397088289261, 0.3702414929866791, 0.42133262753486633]\n",
      "loss: 0.279465  [262144/343145] real loss: 0.27946460247039795\n",
      "[0.3581862151622772, 0.23710408806800842, 0.2947639226913452, 0.1727774441242218, 0.2852916419506073, 1.3562521934509277, 0.22385601699352264]\n",
      "[0.7249937057495117, 0.352306604385376, 0.5200097560882568, 0.25362229347229004, 0.3096452057361603, 0.8653082847595215, 0.3129400908946991]\n",
      "loss: 0.285587  [327680/343145] real loss: 0.2855866551399231\n",
      "[0.12184048444032669, 0.23965829610824585, 0.2146422117948532, 0.0890314131975174, 0.5131275653839111, 0.11872012913227081, 0.19004638493061066]\n",
      "[0.13085269927978516, 0.22488680481910706, 0.20135851204395294, 0.12233379483222961, 0.5204474329948425, 0.09823340177536011, 0.19496160745620728]\n",
      "LOSSES TRAIN: 0.287876087640013 LOSSES TEST: 0.3138698126588549\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.282817  [    0/343145] real loss: 0.2828170657157898\n",
      "[0.42534804344177246, 0.11673418432474136, 0.5378487706184387, 0.09571990370750427, 0.30281007289886475, 0.36675119400024414, 0.2036350965499878]\n",
      "[0.7464931607246399, 0.13774900138378143, 0.6550922989845276, 0.08143190294504166, 0.24284480512142181, 0.555548906326294, 0.2538749873638153]\n",
      "loss: 0.287014  [65536/343145] real loss: 0.2870142459869385\n",
      "[0.38011598587036133, 0.22974812984466553, 0.336203932762146, 0.2304423600435257, 1.1968404054641724, 0.25926846265792847, 0.19875618815422058]\n",
      "[0.5722711086273193, 0.1646972894668579, 0.29925888776779175, 0.23843219876289368, 1.376989722251892, 0.4263962209224701, 0.25848260521888733]\n",
      "loss: 0.276163  [131072/343145] real loss: 0.2761627733707428\n",
      "[0.10923101007938385, 0.3897389769554138, 0.2290925830602646, 0.5978098511695862, 0.7698670029640198, 0.0925561711192131, 0.4625266492366791]\n",
      "[0.17254769802093506, 0.47019222378730774, 0.1972390115261078, 0.6650906205177307, 0.8228404521942139, 0.09949200600385666, 0.6853166222572327]\n",
      "loss: 0.278942  [196608/343145] real loss: 0.27894169092178345\n",
      "[0.2602492570877075, 0.3398154675960541, 0.31666046380996704, 0.2845894396305084, 0.20706993341445923, 0.20912161469459534, 0.2774670422077179]\n",
      "[0.39756113290786743, 0.4137171804904938, 0.38497158885002136, 0.3090640902519226, 0.12376520037651062, 0.08776669949293137, 0.2313304990530014]\n",
      "loss: 0.285678  [262144/343145] real loss: 0.28567779064178467\n",
      "[0.17399799823760986, 0.2716042399406433, 0.35672062635421753, 0.2903098464012146, 0.4290647506713867, 0.9401648640632629, 0.3107966482639313]\n",
      "[0.2961735129356384, 0.3684263825416565, 0.3886236250400543, 0.25479060411453247, 1.5907353162765503, 1.0108340978622437, 0.35133299231529236]\n",
      "loss: 0.284602  [327680/343145] real loss: 0.2846018970012665\n",
      "[0.285942941904068, 0.2617919147014618, 0.37795761227607727, 0.44885432720184326, 0.0934959426522255, 0.5056596994400024, 0.4564113914966583]\n",
      "[0.32443779706954956, 0.4493682086467743, 0.6283071041107178, 0.8037899732589722, 0.10144290328025818, 0.3469706177711487, 0.47792670130729675]\n",
      "LOSSES TRAIN: 0.2867235779052689 LOSSES TEST: 0.3133100186075483\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.278392  [    0/343145] real loss: 0.2783924341201782\n",
      "[0.21491877734661102, 0.29796314239501953, 0.35196754336357117, 0.09630253911018372, 0.17646607756614685, 0.5717863440513611, 0.11777892708778381]\n",
      "[0.2313764989376068, 0.3178406059741974, 0.33522120118141174, 0.09580859541893005, 0.1675007939338684, 0.6064164638519287, 0.14795149862766266]\n",
      "loss: 0.281558  [65536/343145] real loss: 0.2815583646297455\n",
      "[0.3652442395687103, 0.20040163397789001, 0.08196273446083069, 0.11797218024730682, 0.3128485083580017, 0.17896220088005066, 0.6424002051353455]\n",
      "[0.7759339809417725, 0.22050200402736664, 0.0797078013420105, 0.1899774968624115, 0.32004329562187195, 0.2686839997768402, 0.7305359840393066]\n",
      "loss: 0.287476  [131072/343145] real loss: 0.2874758541584015\n",
      "[0.1978401243686676, 0.115245521068573, 0.2019995003938675, 1.0465455055236816, 0.12699802219867706, 0.25917962193489075, 0.12687315046787262]\n",
      "[0.15200559794902802, 0.11550040543079376, 0.28709420561790466, 1.157594084739685, 0.1235015019774437, 0.38160020112991333, 0.2328953891992569]\n",
      "loss: 0.277842  [196608/343145] real loss: 0.2778416872024536\n",
      "[0.5824522972106934, 0.28648197650909424, 0.13633398711681366, 0.6810490489006042, 0.20456919074058533, 0.2158517837524414, 0.3198908269405365]\n",
      "[0.9145365953445435, 0.2433972954750061, 0.17490170896053314, 0.7405527830123901, 0.2812332808971405, 0.3472664952278137, 0.40742531418800354]\n",
      "loss: 0.282440  [262144/343145] real loss: 0.282439649105072\n",
      "[0.3006276488304138, 0.2106843888759613, 0.173450767993927, 0.39074236154556274, 0.6024101972579956, 0.24676579236984253, 0.14036016166210175]\n",
      "[0.29291781783103943, 0.14292789995670319, 0.2887252867221832, 0.34234619140625, 0.7908559441566467, 0.3021179139614105, 0.1370597928762436]\n",
      "loss: 0.275367  [327680/343145] real loss: 0.27536681294441223\n",
      "[0.3034093379974365, 0.4183288514614105, 0.2624829411506653, 0.20004864037036896, 0.13648295402526855, 0.11271258443593979, 0.3602052628993988]\n",
      "[0.36163920164108276, 0.5225191116333008, 0.2943001985549927, 0.18971969187259674, 0.1099579930305481, 0.11507159471511841, 0.5993289947509766]\n",
      "LOSSES TRAIN: 0.2865928943668093 LOSSES TEST: 0.31766400592667715\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.279482  [    0/343145] real loss: 0.2794819474220276\n",
      "[0.27071383595466614, 0.4119415581226349, 0.1457916498184204, 0.27868226170539856, 0.23501631617546082, 0.6370394825935364, 0.277877539396286]\n",
      "[0.21399979293346405, 0.22321011126041412, 0.27211111783981323, 0.2301023155450821, 0.276819109916687, 0.3910648226737976, 0.43600037693977356]\n",
      "loss: 0.283939  [65536/343145] real loss: 0.28393930196762085\n",
      "[0.30950936675071716, 0.5039560198783875, 0.2704167068004608, 0.2884591221809387, 0.3636801540851593, 0.2206547111272812, 0.21419109404087067]\n",
      "[0.38731610774993896, 0.5293859839439392, 0.2297740876674652, 0.28883180022239685, 0.8067541122436523, 0.3048616945743561, 0.2314985990524292]\n",
      "loss: 0.282734  [131072/343145] real loss: 0.2827339172363281\n",
      "[0.10801228135824203, 0.15894997119903564, 0.3355525732040405, 0.25852441787719727, 0.23563143610954285, 0.4057113826274872, 0.23110170662403107]\n",
      "[0.14157749712467194, 0.23679789900779724, 0.30021220445632935, 0.2505643963813782, 0.26477718353271484, 0.6435791850090027, 0.17766080796718597]\n",
      "loss: 0.293838  [196608/343145] real loss: 0.29383838176727295\n",
      "[0.16100719571113586, 2.9130616188049316, 0.16042575240135193, 0.20160067081451416, 0.23144756257534027, 0.2546941637992859, 0.10564474761486053]\n",
      "[0.1807287037372589, 3.842848062515259, 0.2148502916097641, 0.16978169977664948, 0.24273169040679932, 0.3220489025115967, 0.14944760501384735]\n",
      "loss: 0.281973  [262144/343145] real loss: 0.28197333216667175\n",
      "[0.18170265853405, 0.9723258018493652, 0.30349138379096985, 0.1541152447462082, 0.4258207678794861, 0.3018026351928711, 0.29513514041900635]\n",
      "[0.21580860018730164, 1.5343682765960693, 0.2138873040676117, 0.21716319024562836, 0.3168731927871704, 0.30716949701309204, 0.2598420977592468]\n",
      "loss: 0.287735  [327680/343145] real loss: 0.2877351939678192\n",
      "[0.1151493638753891, 0.36011260747909546, 0.28765052556991577, 0.4681755304336548, 1.8220653533935547, 2.1604976654052734, 0.5195266604423523]\n",
      "[0.1483384072780609, 0.38018229603767395, 0.28741949796676636, 0.45325690507888794, 1.6849889755249023, 1.6930577754974365, 0.5580165982246399]\n",
      "LOSSES TRAIN: 0.2862157661999975 LOSSES TEST: 0.31621773753847393\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.289473  [    0/343145] real loss: 0.28947293758392334\n",
      "[0.545954704284668, 0.377612829208374, 0.20292659103870392, 0.2698577642440796, 0.25181546807289124, 0.40576374530792236, 0.23593947291374207]\n",
      "[0.6063449382781982, 0.446405827999115, 0.25220221281051636, 0.33285290002822876, 0.19851380586624146, 0.5295249819755554, 0.2329079955816269]\n",
      "loss: 0.291609  [65536/343145] real loss: 0.2916085124015808\n",
      "[0.08907252550125122, 0.4286709725856781, 0.22581395506858826, 0.3143501877784729, 0.4453073740005493, 0.37807726860046387, 0.18390756845474243]\n",
      "[0.07173480093479156, 0.366884708404541, 0.3934495151042938, 0.35172930359840393, 0.4271292984485626, 0.4315090775489807, 0.3207317888736725]\n",
      "loss: 0.281766  [131072/343145] real loss: 0.2817663848400116\n",
      "[0.23508904874324799, 0.25222399830818176, 0.780695378780365, 0.23280587792396545, 0.15301494300365448, 0.5796231627464294, 0.3345252573490143]\n",
      "[0.24435681104660034, 0.23418599367141724, 0.5978596806526184, 0.1858624964952469, 0.1134968027472496, 0.690640389919281, 0.3502911925315857]\n",
      "loss: 0.277023  [196608/343145] real loss: 0.27702265977859497\n",
      "[0.3625503182411194, 0.3156152069568634, 0.32633325457572937, 0.2771138548851013, 0.3611351549625397, 0.32089245319366455, 0.3331882953643799]\n",
      "[0.3884580135345459, 0.3417527973651886, 0.4091135263442993, 0.30951622128486633, 0.44627660512924194, 0.3230811059474945, 0.35829490423202515]\n",
      "loss: 0.282643  [262144/343145] real loss: 0.28264299035072327\n",
      "[0.1372489333152771, 0.3308190405368805, 0.7203609943389893, 0.3427732288837433, 0.526447057723999, 0.10986587405204773, 0.24292337894439697]\n",
      "[0.1688368022441864, 0.42429500818252563, 0.536086916923523, 0.3409123122692108, 0.8369588255882263, 0.07134170085191727, 0.29729029536247253]\n",
      "loss: 0.379151  [327680/343145] real loss: 0.3791506290435791\n",
      "[0.3169940710067749, 0.2962595522403717, 0.3744772970676422, 0.18311837315559387, 0.22014859318733215, 0.6268383264541626, 1.5509995222091675]\n",
      "[0.38646450638771057, 0.25956517457962036, 0.4175226092338562, 0.13181059062480927, 0.14439180493354797, 0.8535999655723572, 1.504454255104065]\n",
      "LOSSES TRAIN: 0.28625532062280745 LOSSES TEST: 0.31754845806530546\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.281972  [    0/343145] real loss: 0.2819717228412628\n",
      "[0.18830278515815735, 0.2835662066936493, 1.0215767621994019, 0.26198911666870117, 0.6249070167541504, 0.2233903706073761, 0.45125019550323486]\n",
      "[0.22089770436286926, 0.3632063865661621, 1.1080751419067383, 0.2626557946205139, 0.6583778858184814, 0.185856893658638, 0.5760713219642639]\n",
      "loss: 0.291950  [65536/343145] real loss: 0.2919498383998871\n",
      "[0.2573213279247284, 0.2015218287706375, 0.10372231900691986, 0.4275539815425873, 0.3066594898700714, 0.2824493646621704, 0.24591125547885895]\n",
      "[0.30161041021347046, 0.19788530468940735, 0.14749759435653687, 0.31122779846191406, 0.4828953146934509, 0.4862731695175171, 0.20391671359539032]\n",
      "loss: 0.296337  [131072/343145] real loss: 0.29633742570877075\n",
      "[0.41477638483047485, 0.6559712886810303, 0.11734577268362045, 0.34722328186035156, 0.7663961052894592, 0.5039129257202148, 0.18252946436405182]\n",
      "[0.31809481978416443, 0.6047228574752808, 0.13656049966812134, 0.3591175973415375, 1.1675952672958374, 0.7991706728935242, 0.17896109819412231]\n",
      "loss: 0.280045  [196608/343145] real loss: 0.280044823884964\n",
      "[1.0330713987350464, 0.24997371435165405, 0.1609887331724167, 0.14084428548812866, 0.21043597161769867, 0.42719393968582153, 0.16429278254508972]\n",
      "[1.445513129234314, 0.3815414011478424, 0.1682446002960205, 0.13290199637413025, 0.21237340569496155, 0.42947497963905334, 0.14386829733848572]\n",
      "loss: 0.285604  [262144/343145] real loss: 0.2856036424636841\n",
      "[0.5645018815994263, 0.6656808853149414, 0.7217642664909363, 0.12863969802856445, 0.20776912569999695, 0.2542019486427307, 0.8546231985092163]\n",
      "[0.47573322057724, 0.9695290327072144, 0.9444392919540405, 0.13616050779819489, 0.24440321326255798, 0.2514526844024658, 1.2704665660858154]\n",
      "loss: 0.277228  [327680/343145] real loss: 0.27722814679145813\n",
      "[0.2792971432209015, 0.1871972382068634, 0.23908834159374237, 0.5681577324867249, 0.33903825283050537, 0.30487918853759766, 0.18284882605075836]\n",
      "[0.28007400035858154, 0.3026183843612671, 0.5351650714874268, 0.629912793636322, 0.3745644986629486, 0.33179140090942383, 0.2256564050912857]\n",
      "LOSSES TRAIN: 0.2857954878182638 LOSSES TEST: 0.3190168397767203\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.293050  [    0/343145] real loss: 0.2930501699447632\n",
      "[0.16713976860046387, 0.18547099828720093, 0.25862011313438416, 0.778473436832428, 0.3609265387058258, 0.2297959327697754, 0.18010783195495605]\n",
      "[0.17184440791606903, 0.1601289063692093, 0.43492159247398376, 1.0346391201019287, 0.3599643111228943, 0.2389557957649231, 0.23495738208293915]\n",
      "loss: 0.283283  [65536/343145] real loss: 0.2832832634449005\n",
      "[0.15963329374790192, 0.4441604018211365, 0.1342589557170868, 0.18187673389911652, 0.6321154832839966, 0.3283904194831848, 0.2201652228832245]\n",
      "[0.17053909599781036, 0.34761250019073486, 0.14490219950675964, 0.2876392900943756, 1.4296159744262695, 0.324299693107605, 0.2850170135498047]\n",
      "loss: 0.279372  [131072/343145] real loss: 0.27937155961990356\n",
      "[0.2985609173774719, 0.3404228091239929, 0.5953840017318726, 0.24147258698940277, 0.19392907619476318, 0.24839632213115692, 0.10129404067993164]\n",
      "[0.32891789078712463, 0.3050698935985565, 0.8369050025939941, 0.2746117115020752, 0.24927730858325958, 0.23795630037784576, 0.10247780382633209]\n",
      "loss: 0.278611  [196608/343145] real loss: 0.2786113917827606\n",
      "[0.12689775228500366, 0.1122346967458725, 1.0187915563583374, 0.12484611570835114, 0.5907241702079773, 0.3604634404182434, 0.3922125995159149]\n",
      "[0.1087610051035881, 0.13214340806007385, 1.0907166004180908, 0.08566650003194809, 0.7640460133552551, 0.26445430517196655, 0.28083372116088867]\n",
      "loss: 0.332303  [262144/343145] real loss: 0.3323034644126892\n",
      "[0.3005744516849518, 0.19922560453414917, 0.30741578340530396, 1.0681579113006592, 0.3249558210372925, 0.5567012429237366, 0.1925809383392334]\n",
      "[0.3742372989654541, 0.2091854065656662, 0.28441479802131653, 1.4819117784500122, 0.4742673933506012, 0.8418035507202148, 0.28604158759117126]\n",
      "loss: 0.279987  [327680/343145] real loss: 0.27998706698417664\n",
      "[0.206459641456604, 0.39668160676956177, 0.3626810312271118, 0.6183613538742065, 0.13752195239067078, 0.821199893951416, 0.2931348383426666]\n",
      "[0.20580720901489258, 0.42480918765068054, 0.35769960284233093, 0.7771809101104736, 0.18904191255569458, 1.0328712463378906, 0.19740469753742218]\n",
      "LOSSES TRAIN: 0.2850153155270077 LOSSES TEST: 0.3158621106828962\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.281174  [    0/343145] real loss: 0.2811739444732666\n",
      "[0.18582358956336975, 0.16127313673496246, 0.29005032777786255, 0.14900119602680206, 0.5919827222824097, 0.12982790172100067, 0.49967247247695923]\n",
      "[0.14171549677848816, 0.1499280035495758, 0.28457319736480713, 0.17514410614967346, 0.3801427185535431, 0.20704948902130127, 0.9875673651695251]\n",
      "loss: 0.276102  [65536/343145] real loss: 0.27610233426094055\n",
      "[0.32437485456466675, 0.18744319677352905, 0.16372977197170258, 0.3400324285030365, 0.3927678167819977, 0.3134894371032715, 0.3069780766963959]\n",
      "[0.36981001496315, 0.1738068014383316, 0.18451440334320068, 0.6077681183815002, 0.41261929273605347, 0.5798362493515015, 0.4072878062725067]\n",
      "loss: 0.280479  [131072/343145] real loss: 0.28047850728034973\n",
      "[0.22334732115268707, 0.40279579162597656, 0.3988763391971588, 0.28507405519485474, 0.18689081072807312, 0.39606741070747375, 0.3589059114456177]\n",
      "[0.30215898156166077, 0.4203339219093323, 0.7184892892837524, 0.6483936905860901, 0.15108169615268707, 0.4944179058074951, 0.6180726885795593]\n",
      "loss: 0.281822  [196608/343145] real loss: 0.2818220853805542\n",
      "[0.3108622133731842, 0.17664669454097748, 0.43979179859161377, 0.2057899534702301, 0.19261322915554047, 0.41601577401161194, 0.17005017399787903]\n",
      "[0.4069291949272156, 0.43382787704467773, 0.4808785915374756, 0.19644400477409363, 0.29581019282341003, 0.40643778443336487, 0.1268962025642395]\n",
      "loss: 0.282661  [262144/343145] real loss: 0.2826608121395111\n",
      "[0.4520852863788605, 0.09918893873691559, 0.27505218982696533, 0.21303001046180725, 0.27052971720695496, 0.34049004316329956, 0.511474072933197]\n",
      "[0.4592057764530182, 0.1973215937614441, 0.37047070264816284, 0.23166120052337646, 0.3662321865558624, 0.4634166955947876, 0.6117792725563049]\n",
      "loss: 0.282700  [327680/343145] real loss: 0.28269970417022705\n",
      "[0.16151174902915955, 0.25723522901535034, 0.18595115840435028, 0.22575527429580688, 0.13342446088790894, 0.4011446237564087, 0.5438252687454224]\n",
      "[0.2056645005941391, 0.24576041102409363, 0.24665549397468567, 0.48240089416503906, 0.11750790476799011, 0.41768550872802734, 1.0316684246063232]\n",
      "LOSSES TRAIN: 0.2844838723540306 LOSSES TEST: 0.3159257698626745\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.284326  [    0/343145] real loss: 0.2843264937400818\n",
      "[0.2688511610031128, 0.16547605395317078, 0.44146034121513367, 0.2485399693250656, 0.09950298070907593, 0.17833086848258972, 0.24502867460250854]\n",
      "[0.23630279302597046, 0.14627480506896973, 0.3616706132888794, 0.340972900390625, 0.10892769694328308, 0.21858611702919006, 0.22922269999980927]\n",
      "loss: 0.271654  [65536/343145] real loss: 0.2716538608074188\n",
      "[0.6673942804336548, 0.15167009830474854, 0.28071779012680054, 0.28869712352752686, 0.29512473940849304, 0.09217158704996109, 0.1261824667453766]\n",
      "[0.7671666741371155, 0.2232905924320221, 0.2604404091835022, 0.28890660405158997, 0.2779579162597656, 0.14596210420131683, 0.11822380125522614]\n",
      "loss: 0.312619  [131072/343145] real loss: 0.31261855363845825\n",
      "[0.33252978324890137, 0.35838785767555237, 0.1897786408662796, 0.15630093216896057, 0.26668938994407654, 0.3882344365119934, 0.5209424495697021]\n",
      "[0.43060439825057983, 0.3983081877231598, 0.2284059077501297, 0.18184219300746918, 0.33150529861450195, 0.4132661819458008, 0.5712466835975647]\n",
      "loss: 0.270064  [196608/343145] real loss: 0.2700642943382263\n",
      "[0.46152257919311523, 0.1551712453365326, 0.23084348440170288, 0.1698768436908722, 0.11141642928123474, 0.15030889213085175, 0.21278055012226105]\n",
      "[0.4320727288722992, 0.1626524031162262, 0.30661579966545105, 0.37371060252189636, 0.31534940004348755, 0.1300627887248993, 0.2585940957069397]\n",
      "loss: 0.277484  [262144/343145] real loss: 0.27748391032218933\n",
      "[0.23785006999969482, 0.18099667131900787, 0.8159621357917786, 0.6179012060165405, 0.4105082154273987, 0.26307639479637146, 0.20304907858371735]\n",
      "[0.18804869055747986, 0.27788278460502625, 0.8318793773651123, 0.4570982754230499, 0.47647711634635925, 0.22822630405426025, 0.19556619226932526]\n",
      "loss: 0.279230  [327680/343145] real loss: 0.2792298197746277\n",
      "[0.14017993211746216, 0.3383793532848358, 0.23843857645988464, 0.39618754386901855, 0.20710629224777222, 0.2906869947910309, 0.28159797191619873]\n",
      "[0.22694659233093262, 0.31545019149780273, 0.17340239882469177, 0.41801100969314575, 0.2548801004886627, 0.14285090565681458, 0.2638697028160095]\n",
      "LOSSES TRAIN: 0.2850397321439925 LOSSES TEST: 0.3197729218573797\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.298079  [    0/343145] real loss: 0.29807865619659424\n",
      "[0.2220565229654312, 0.27729862928390503, 0.0949772372841835, 0.5482611656188965, 0.3656555712223053, 0.5095939040184021, 0.5372709631919861]\n",
      "[0.20334920287132263, 0.5015395283699036, 0.13989590108394623, 0.7549620866775513, 0.29387331008911133, 0.47495222091674805, 0.6093850135803223]\n",
      "loss: 0.337306  [65536/343145] real loss: 0.33730626106262207\n",
      "[0.5927016735076904, 0.1387225240468979, 0.122606560587883, 0.9227219223976135, 0.373886376619339, 0.43406689167022705, 0.2221435159444809]\n",
      "[0.4591243863105774, 0.1772679090499878, 0.11801909655332565, 1.0834192037582397, 0.30813300609588623, 0.5880857110023499, 0.21462999284267426]\n",
      "loss: 0.278920  [131072/343145] real loss: 0.2789200246334076\n",
      "[0.39833512902259827, 0.08959034085273743, 0.21637287735939026, 0.09155288338661194, 0.24958965182304382, 0.16536347568035126, 0.3153079152107239]\n",
      "[0.5936746001243591, 0.08643289655447006, 0.2514415979385376, 0.1174372062087059, 0.4454573094844818, 0.1561158001422882, 0.33962899446487427]\n",
      "loss: 0.273538  [196608/343145] real loss: 0.2735375463962555\n",
      "[0.13044768571853638, 0.21314065158367157, 0.16017240285873413, 0.11862800270318985, 0.13969871401786804, 0.3820793628692627, 0.4970604181289673]\n",
      "[0.13451099395751953, 0.20517168939113617, 0.13991999626159668, 0.15139590203762054, 0.2633766829967499, 0.533776581287384, 0.7953670620918274]\n",
      "loss: 0.287040  [262144/343145] real loss: 0.28703972697257996\n",
      "[0.7149170637130737, 0.3559252917766571, 0.19272083044052124, 0.2741154730319977, 0.5222792029380798, 0.17181652784347534, 1.1561840772628784]\n",
      "[1.0696494579315186, 0.30855271220207214, 0.16524170339107513, 0.2378246933221817, 0.34947440028190613, 0.18558000028133392, 1.3189979791641235]\n",
      "loss: 0.286396  [327680/343145] real loss: 0.2863956093788147\n",
      "[0.1590375155210495, 0.21751205623149872, 0.1837117224931717, 0.2611231803894043, 0.41478410363197327, 0.15321654081344604, 0.3495788276195526]\n",
      "[0.24934451282024384, 0.1543014943599701, 0.21429860591888428, 0.3492394983768463, 0.500434398651123, 0.17621059715747833, 0.3585508167743683]\n",
      "LOSSES TRAIN: 0.28393119005929857 LOSSES TEST: 0.31717268767811\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.276553  [    0/343145] real loss: 0.27655288577079773\n",
      "[0.20413288474082947, 0.3021675646305084, 0.40251651406288147, 0.28359630703926086, 1.1446188688278198, 0.07712426781654358, 0.8727355599403381]\n",
      "[0.181518092751503, 0.45819032192230225, 0.31424421072006226, 0.33700740337371826, 1.0967282056808472, 0.1320524960756302, 0.47518932819366455]\n",
      "loss: 0.283824  [65536/343145] real loss: 0.28382381796836853\n",
      "[1.0230953693389893, 0.533736526966095, 0.5202877521514893, 0.31094107031822205, 0.6317062377929688, 0.16923996806144714, 0.5568505525588989]\n",
      "[1.225162148475647, 0.8219083547592163, 0.3628292977809906, 0.2314440906047821, 0.5056889057159424, 0.15384280681610107, 0.6653031706809998]\n",
      "loss: 0.279099  [131072/343145] real loss: 0.27909913659095764\n",
      "[0.30882883071899414, 0.11169330030679703, 0.09134160727262497, 0.7969539761543274, 0.562616765499115, 0.28282058238983154, 0.3674638271331787]\n",
      "[0.32420557737350464, 0.10431220382452011, 0.06921400129795074, 1.7590891122817993, 0.7112762928009033, 0.3116097152233124, 0.3428610861301422]\n",
      "loss: 0.286254  [196608/343145] real loss: 0.28625431656837463\n",
      "[0.837116539478302, 0.2130732238292694, 0.5315248370170593, 0.4847908616065979, 0.26368415355682373, 0.35927149653434753, 0.26540517807006836]\n",
      "[0.8135060667991638, 0.28358718752861023, 0.642754077911377, 1.4672393798828125, 0.2621029019355774, 0.35053950548171997, 0.30079078674316406]\n",
      "loss: 0.286249  [262144/343145] real loss: 0.28624850511550903\n",
      "[0.12221471220254898, 0.34226194024086, 0.3811355531215668, 0.336772084236145, 0.2892274558544159, 0.4991876780986786, 0.3180929124355316]\n",
      "[0.15381360054016113, 0.34395632147789, 0.4766833186149597, 0.3882353901863098, 0.440555214881897, 0.6332398056983948, 0.3452301025390625]\n",
      "loss: 0.286478  [327680/343145] real loss: 0.2864783704280853\n",
      "[0.39756184816360474, 0.18845877051353455, 0.4429466128349304, 0.40837475657463074, 0.41309091448783875, 0.29761356115341187, 0.4191233515739441]\n",
      "[0.4437275230884552, 0.28281688690185547, 0.516846239566803, 0.5029163956642151, 0.4603929817676544, 0.3647010922431946, 0.525116503238678]\n",
      "LOSSES TRAIN: 0.2838049910607792 LOSSES TEST: 0.3217217837061201\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.289244  [    0/343145] real loss: 0.2892439365386963\n",
      "[0.150997132062912, 0.29857414960861206, 0.5383545160293579, 0.1011972576379776, 0.16429801285266876, 0.5818347334861755, 0.5747641921043396]\n",
      "[0.1322139948606491, 0.31407469511032104, 0.6431633830070496, 0.09889879822731018, 0.21040849387645721, 0.6039522290229797, 0.4521542191505432]\n",
      "loss: 0.280494  [65536/343145] real loss: 0.28049448132514954\n",
      "[0.21046924591064453, 0.3371806740760803, 0.1711157113313675, 0.27340012788772583, 0.23443880677223206, 0.2669191360473633, 0.32776251435279846]\n",
      "[0.3014219105243683, 0.1573459953069687, 0.15699860453605652, 0.46078696846961975, 0.2929864823818207, 0.26107701659202576, 0.2965545058250427]\n",
      "loss: 0.272589  [131072/343145] real loss: 0.27258920669555664\n",
      "[0.21977046132087708, 0.22492477297782898, 0.2939916253089905, 0.4606485366821289, 0.3688025176525116, 0.20276261866092682, 0.2541132867336273]\n",
      "[0.29776230454444885, 0.3285458981990814, 0.2400641143321991, 0.8079829812049866, 0.4506952166557312, 0.20179979503154755, 0.20095200836658478]\n",
      "loss: 0.284576  [196608/343145] real loss: 0.28457584977149963\n",
      "[0.26409879326820374, 0.22366838157176971, 0.3438987731933594, 0.2795565128326416, 0.2612046003341675, 0.33935868740081787, 0.5537235736846924]\n",
      "[0.2866992950439453, 0.20270989835262299, 0.29619958996772766, 0.2376403957605362, 0.22858749330043793, 0.24974051117897034, 0.5325905084609985]\n",
      "loss: 0.279216  [262144/343145] real loss: 0.2792159616947174\n",
      "[0.6041732430458069, 1.772942066192627, 0.2264554500579834, 0.5348785519599915, 0.13071870803833008, 0.3242993950843811, 0.3000442683696747]\n",
      "[0.6474813222885132, 2.2153313159942627, 0.25612369179725647, 0.5506343245506287, 0.16498509049415588, 0.44353529810905457, 0.4211808145046234]\n",
      "loss: 0.276375  [327680/343145] real loss: 0.27637478709220886\n",
      "[0.22718200087547302, 0.220221608877182, 0.16238801181316376, 0.1525038778781891, 0.3417752683162689, 0.26401329040527344, 0.4661434292793274]\n",
      "[0.23563480377197266, 0.27308589220046997, 0.14739739894866943, 0.17290879786014557, 0.42229726910591125, 0.5125070810317993, 0.4108016788959503]\n",
      "LOSSES TRAIN: 0.2840390084754853 LOSSES TEST: 0.32167885700861615\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.273226  [    0/343145] real loss: 0.2732258439064026\n",
      "[0.3801293969154358, 0.5309557318687439, 0.2394433170557022, 0.4056364893913269, 0.18515107035636902, 0.2728544771671295, 0.40867850184440613]\n",
      "[0.36788681149482727, 0.6438011527061462, 0.22765639424324036, 0.4364098906517029, 0.1550751030445099, 0.285601407289505, 0.41857069730758667]\n",
      "loss: 0.284670  [65536/343145] real loss: 0.28467005491256714\n",
      "[0.23935715854167938, 0.2104588896036148, 0.14444410800933838, 0.26142609119415283, 0.20961105823516846, 0.15727488696575165, 0.13589419424533844]\n",
      "[0.4492368996143341, 0.23860479891300201, 0.14929009974002838, 0.3519223928451538, 0.17114019393920898, 0.19903869926929474, 0.18118959665298462]\n",
      "loss: 0.276163  [131072/343145] real loss: 0.2761634290218353\n",
      "[0.16390708088874817, 0.1772640347480774, 0.06847979128360748, 0.1698513925075531, 0.19666939973831177, 0.29532116651535034, 0.4015241265296936]\n",
      "[0.1861845999956131, 0.2022484987974167, 0.07771740108728409, 0.2075423002243042, 0.25184789299964905, 0.28671830892562866, 0.791225016117096]\n",
      "loss: 0.271819  [196608/343145] real loss: 0.27181872725486755\n",
      "[0.29668503999710083, 0.23934108018875122, 0.364285945892334, 0.20493754744529724, 0.5116264820098877, 0.5806914567947388, 0.3225739002227783]\n",
      "[0.40062791109085083, 0.3581649959087372, 0.5127044916152954, 0.19296689331531525, 0.5145717859268188, 0.8570720553398132, 0.42702388763427734]\n",
      "loss: 0.307427  [262144/343145] real loss: 0.3074268400669098\n",
      "[0.2610343098640442, 0.1667787730693817, 0.2811654508113861, 0.28598102927207947, 0.22929947078227997, 0.15106581151485443, 0.1272357851266861]\n",
      "[0.24490348994731903, 0.22238489985466003, 0.31478092074394226, 0.2052713930606842, 0.8088545799255371, 0.22171470522880554, 0.14417800307273865]\n",
      "loss: 0.282002  [327680/343145] real loss: 0.2820015251636505\n",
      "[0.14267902076244354, 0.0639229565858841, 0.26262032985687256, 0.6285163760185242, 0.1970602571964264, 0.166309654712677, 0.19770973920822144]\n",
      "[0.1681995987892151, 0.05011549964547157, 0.2829445004463196, 0.6072260737419128, 0.5006182193756104, 0.22901651263237, 0.1916109025478363]\n",
      "LOSSES TRAIN: 0.2833078716482435 LOSSES TEST: 0.3227052064169021\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.287112  [    0/343145] real loss: 0.2871116101741791\n",
      "[0.15860013663768768, 0.5807905197143555, 0.377388060092926, 0.11430911719799042, 0.19883252680301666, 0.18220995366573334, 0.18628016114234924]\n",
      "[0.2131723165512085, 0.48635968565940857, 0.5795304179191589, 0.17016610503196716, 0.31744900345802307, 0.10284320265054703, 0.10747859627008438]\n",
      "loss: 0.283576  [65536/343145] real loss: 0.2835761308670044\n",
      "[0.2213703691959381, 0.14566758275032043, 0.22471120953559875, 0.2816687822341919, 0.12310423702001572, 0.2828587293624878, 0.07687513530254364]\n",
      "[0.18521618843078613, 0.12682189047336578, 0.3190116882324219, 0.25552719831466675, 0.1896606981754303, 0.21068769693374634, 0.05863669887185097]\n",
      "loss: 0.282412  [131072/343145] real loss: 0.2824121117591858\n",
      "[0.20162847638130188, 0.24341079592704773, 0.32602086663246155, 0.2067340612411499, 0.2283661663532257, 0.3938603699207306, 0.24232807755470276]\n",
      "[0.3488413989543915, 0.2951239049434662, 0.43011027574539185, 0.2380087971687317, 0.234980508685112, 0.838866114616394, 0.28280481696128845]\n",
      "loss: 0.281508  [196608/343145] real loss: 0.28150808811187744\n",
      "[0.22912031412124634, 0.2557586133480072, 0.5479187965393066, 0.4155305325984955, 0.16229525208473206, 0.17376908659934998, 0.21562981605529785]\n",
      "[0.3107109069824219, 0.2801632881164551, 0.678581178188324, 0.5076984763145447, 0.1793888956308365, 0.2420336902141571, 0.23148120939731598]\n",
      "loss: 0.281611  [262144/343145] real loss: 0.2816111445426941\n",
      "[0.8708057999610901, 0.15282979607582092, 0.1417301893234253, 0.19849640130996704, 0.22751843929290771, 0.3721131682395935, 0.07859857380390167]\n",
      "[1.089438557624817, 0.12389259785413742, 0.16548529267311096, 0.26634329557418823, 0.20222650468349457, 0.6711074113845825, 0.0877075046300888]\n",
      "loss: 0.271882  [327680/343145] real loss: 0.2718823254108429\n",
      "[0.3111812174320221, 0.1433255523443222, 0.5678961873054504, 0.1218893975019455, 0.16589459776878357, 0.0882551521062851, 0.2027515023946762]\n",
      "[0.532550573348999, 0.14280110597610474, 0.3673270046710968, 0.10956190526485443, 0.20590411126613617, 0.07805360108613968, 0.26352059841156006]\n",
      "LOSSES TRAIN: 0.28291836345479604 LOSSES TEST: 0.32129725955781485\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.281390  [    0/343145] real loss: 0.2813904583454132\n",
      "[0.0717201977968216, 0.4921818673610687, 0.17311429977416992, 0.5452576279640198, 0.7323643565177917, 0.27830129861831665, 0.42726245522499084]\n",
      "[0.06603539735078812, 0.4396582841873169, 0.18297609686851501, 0.6283494830131531, 0.8805690407752991, 0.3641892075538635, 0.6083236336708069]\n",
      "loss: 0.281869  [65536/343145] real loss: 0.28186890482902527\n",
      "[0.2695196270942688, 0.26622700691223145, 0.3055272400379181, 0.2454846203327179, 0.1630484163761139, 0.2619727551937103, 0.213616281747818]\n",
      "[0.39706239104270935, 0.20316310226917267, 0.287603497505188, 0.2825916111469269, 0.23626741766929626, 0.34549829363822937, 0.2350122034549713]\n",
      "loss: 0.280930  [131072/343145] real loss: 0.2809300124645233\n",
      "[0.22997577488422394, 1.2325310707092285, 0.22788986563682556, 0.5995290875434875, 0.591920793056488, 0.11753484606742859, 0.1877322793006897]\n",
      "[0.16589489579200745, 1.5615874528884888, 0.20614399015903473, 0.570885181427002, 0.5954592823982239, 0.13106049597263336, 0.1879269927740097]\n",
      "loss: 0.274668  [196608/343145] real loss: 0.2746678292751312\n",
      "[0.15240557491779327, 0.4343137741088867, 0.5306926369667053, 0.7645311951637268, 0.3646855652332306, 0.22872713208198547, 0.5357875823974609]\n",
      "[0.16465720534324646, 0.6081092357635498, 0.4885323941707611, 0.8141087293624878, 0.4148105978965759, 0.27536019682884216, 0.36100029945373535]\n",
      "loss: 0.273096  [262144/343145] real loss: 0.2730959355831146\n",
      "[0.2200721800327301, 0.6475648880004883, 0.26373547315597534, 0.17798718810081482, 0.16301533579826355, 0.3772538900375366, 0.2557219862937927]\n",
      "[0.2551473081111908, 0.7097306251525879, 0.2194744050502777, 0.2004808932542801, 0.22892719507217407, 0.4317373037338257, 0.24929650127887726]\n",
      "loss: 0.295589  [327680/343145] real loss: 0.2955891489982605\n",
      "[0.20368273556232452, 0.26860061287879944, 0.47111019492149353, 0.14706425368785858, 0.40925493836402893, 0.20124715566635132, 0.23471416532993317]\n",
      "[0.31176260113716125, 0.22873398661613464, 0.7061858177185059, 0.11454910039901733, 0.4701808989048004, 0.20201140642166138, 0.27008721232414246]\n",
      "LOSSES TRAIN: 0.28286733017081306 LOSSES TEST: 0.32253578305244446\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.283649  [    0/343145] real loss: 0.2836487293243408\n",
      "[0.5231424570083618, 0.3463379442691803, 0.3448925316333771, 0.40194761753082275, 0.21119442582130432, 0.34437575936317444, 0.2846156060695648]\n",
      "[0.6567453742027283, 0.32956498861312866, 0.35415372252464294, 0.3353073000907898, 0.3283733129501343, 0.3145802915096283, 0.4300382137298584]\n",
      "loss: 0.281925  [65536/343145] real loss: 0.28192541003227234\n",
      "[0.18185162544250488, 0.3243456482887268, 0.12707459926605225, 0.13091835379600525, 0.419378399848938, 0.6673520803451538, 0.14316192269325256]\n",
      "[0.27401208877563477, 0.34571540355682373, 0.1350139081478119, 0.15713590383529663, 0.4326256811618805, 0.47166961431503296, 0.19825109839439392]\n",
      "loss: 0.277288  [131072/343145] real loss: 0.2772884964942932\n",
      "[0.2556678056716919, 0.3713950514793396, 0.2646419405937195, 0.27725645899772644, 0.2142409384250641, 0.222157821059227, 0.25885340571403503]\n",
      "[0.31563401222229004, 0.379386305809021, 0.39626169204711914, 0.23722660541534424, 0.22622008621692657, 0.3588186204433441, 0.2913605868816376]\n",
      "loss: 0.277251  [196608/343145] real loss: 0.27725136280059814\n",
      "[0.322759211063385, 0.5360659956932068, 0.3453129827976227, 0.2130434364080429, 1.3639670610427856, 0.3854181170463562, 0.1238081306219101]\n",
      "[0.4113936722278595, 0.8731583952903748, 0.4397839903831482, 0.23334550857543945, 1.411536693572998, 0.45270490646362305, 0.11250149458646774]\n",
      "loss: 0.278957  [262144/343145] real loss: 0.2789570391178131\n",
      "[0.1693679243326187, 0.45284005999565125, 0.2650531530380249, 0.38360777497291565, 0.1330438256263733, 0.14460113644599915, 0.31032320857048035]\n",
      "[0.2160985916852951, 0.6132503747940063, 0.2872036099433899, 0.42766430974006653, 0.1712237000465393, 0.22028200328350067, 0.3045090138912201]\n",
      "loss: 0.281697  [327680/343145] real loss: 0.2816971242427826\n",
      "[0.45751330256462097, 0.3385319113731384, 0.34966233372688293, 0.3872745633125305, 0.420769065618515, 0.4127367436885834, 0.29314562678337097]\n",
      "[0.8132098913192749, 0.3158591091632843, 0.27923959493637085, 0.713651180267334, 0.7225427031517029, 0.5455892086029053, 0.2290922850370407]\n",
      "LOSSES TRAIN: 0.2818722150155476 LOSSES TEST: 0.32181297881262644\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.284455  [    0/343145] real loss: 0.2844548523426056\n",
      "[0.3915826380252838, 0.5380326509475708, 0.259330689907074, 0.35275694727897644, 0.7781448364257812, 0.2385459542274475, 0.3269815742969513]\n",
      "[0.43678268790245056, 0.5769608020782471, 0.32539308071136475, 0.34076979756355286, 1.1876648664474487, 0.25102758407592773, 0.41917911171913147]\n",
      "loss: 0.272379  [65536/343145] real loss: 0.27237850427627563\n",
      "[0.17088103294372559, 0.10271382331848145, 0.3646347224712372, 0.3179551362991333, 0.09503726661205292, 0.14659900963306427, 0.2661551535129547]\n",
      "[0.12062890827655792, 0.09095840156078339, 0.3254448175430298, 0.37098032236099243, 0.12283989787101746, 0.2021268904209137, 0.21427099406719208]\n",
      "loss: 0.285070  [131072/343145] real loss: 0.28507038950920105\n",
      "[0.22488680481910706, 0.3565046191215515, 1.2194948196411133, 0.9006140828132629, 0.16816332936286926, 0.16307008266448975, 0.7305194139480591]\n",
      "[0.3396337032318115, 0.32440340518951416, 1.4063889980316162, 0.4911227226257324, 0.14739669859409332, 0.16824209690093994, 0.9445568323135376]\n",
      "loss: 0.273240  [196608/343145] real loss: 0.27324023842811584\n",
      "[0.4091425836086273, 0.13876394927501678, 0.5104159712791443, 0.23009216785430908, 0.3369767665863037, 0.4940418601036072, 0.1184474378824234]\n",
      "[0.3559073805809021, 0.11927729845046997, 1.0027687549591064, 0.3094804883003235, 0.5575379729270935, 0.6100738048553467, 0.19909068942070007]\n",
      "loss: 0.273480  [262144/343145] real loss: 0.2734801471233368\n",
      "[0.2936464846134186, 0.095341756939888, 0.9277147650718689, 0.29448074102401733, 0.18101871013641357, 0.6041176319122314, 0.7178288102149963]\n",
      "[0.5559967756271362, 0.10035990178585052, 0.7227479815483093, 0.2696135938167572, 0.15918339788913727, 1.1505359411239624, 1.11166512966156]\n",
      "loss: 0.287620  [327680/343145] real loss: 0.28761976957321167\n",
      "[0.22509385645389557, 0.4278300106525421, 0.1677749752998352, 0.46029481291770935, 0.47193238139152527, 0.14202673733234406, 0.27376553416252136]\n",
      "[0.19435030221939087, 0.5801495313644409, 0.23665478825569153, 0.634758472442627, 0.831757128238678, 0.18084339797496796, 0.38926202058792114]\n",
      "LOSSES TRAIN: 0.2817365296539806 LOSSES TEST: 0.3250361056554885\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.279402  [    0/343145] real loss: 0.2794021666049957\n",
      "[0.3327378034591675, 0.4045586884021759, 0.1766672134399414, 0.2650381624698639, 0.2366287112236023, 1.4328992366790771, 0.6007734537124634]\n",
      "[0.3551447093486786, 0.42846012115478516, 0.26989319920539856, 0.4710176885128021, 0.2246032953262329, 0.8932265639305115, 0.7078101634979248]\n",
      "loss: 0.276087  [65536/343145] real loss: 0.2760874629020691\n",
      "[0.34390369057655334, 0.18226663768291473, 0.1850535273551941, 0.6106081008911133, 0.2638980746269226, 0.23358571529388428, 0.3586226999759674]\n",
      "[0.20705710351467133, 0.10183999687433243, 0.26073870062828064, 0.719205379486084, 0.35920852422714233, 0.19948740303516388, 0.5214989185333252]\n",
      "loss: 0.282849  [131072/343145] real loss: 0.2828490138053894\n",
      "[0.18510885536670685, 0.17222093045711517, 0.14751094579696655, 0.4026218354701996, 0.20441429316997528, 0.4564272463321686, 0.39105650782585144]\n",
      "[0.2100640833377838, 0.3700363039970398, 0.21765559911727905, 0.44449129700660706, 0.24709580838680267, 0.26959991455078125, 0.4636085033416748]\n",
      "loss: 0.277157  [196608/343145] real loss: 0.27715685963630676\n",
      "[0.3162333369255066, 0.23197075724601746, 0.2667212188243866, 0.31831642985343933, 0.2025933861732483, 0.2146277129650116, 0.2578471899032593]\n",
      "[0.25951239466667175, 0.4260229766368866, 0.42211687564849854, 0.25687721371650696, 0.2001889944076538, 0.1969984918832779, 0.22039470076560974]\n",
      "loss: 0.278900  [262144/343145] real loss: 0.27890050411224365\n",
      "[0.14786222577095032, 0.789825975894928, 0.3291113078594208, 0.16109248995780945, 0.22416920959949493, 0.37380778789520264, 0.2199443280696869]\n",
      "[0.1374950110912323, 0.8709732294082642, 0.3039509057998657, 0.18359290063381195, 0.33828920125961304, 0.6754181981086731, 0.3029402196407318]\n",
      "loss: 0.266014  [327680/343145] real loss: 0.2660137116909027\n",
      "[0.17935897409915924, 0.4501602053642273, 0.8648872971534729, 2.163940906524658, 0.12512832880020142, 0.2551642656326294, 0.18918003141880035]\n",
      "[0.20788109302520752, 0.635036289691925, 1.3725029230117798, 2.3189857006073, 0.2225026935338974, 0.36190471053123474, 0.2243236005306244]\n",
      "LOSSES TRAIN: 0.28178607601495015 LOSSES TEST: 0.32360310355822247\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.273975  [    0/343145] real loss: 0.2739746868610382\n",
      "[0.5628184080123901, 0.323408842086792, 0.09398242831230164, 0.170248880982399, 0.1351684331893921, 0.20743535459041595, 0.19722019135951996]\n",
      "[0.8878176808357239, 0.2776610851287842, 0.1607188880443573, 0.3050547242164612, 0.1153528019785881, 0.230299711227417, 0.16847750544548035]\n",
      "loss: 0.275903  [65536/343145] real loss: 0.27590253949165344\n",
      "[0.25049832463264465, 0.5798275470733643, 0.1189572811126709, 0.15986371040344238, 0.36484819650650024, 0.19285553693771362, 0.24682128429412842]\n",
      "[0.26469340920448303, 1.208891749382019, 0.14935749769210815, 0.17603799700737, 0.3483630120754242, 0.19789429008960724, 0.20075030624866486]\n",
      "loss: 0.276603  [131072/343145] real loss: 0.27660349011421204\n",
      "[0.6396386623382568, 0.1476989984512329, 0.12914863228797913, 0.2511756718158722, 0.09830664098262787, 0.14816059172153473, 0.47185760736465454]\n",
      "[0.9563823938369751, 0.14537718892097473, 0.1350719928741455, 0.2248965948820114, 0.11019320040941238, 0.21566538512706757, 0.6750631928443909]\n",
      "loss: 0.282902  [196608/343145] real loss: 0.2829018235206604\n",
      "[0.237677201628685, 0.40284931659698486, 0.20308247208595276, 0.08973823487758636, 0.3172733783721924, 0.47013741731643677, 0.38482576608657837]\n",
      "[0.28662538528442383, 0.5526714324951172, 0.2130672037601471, 0.10465310513973236, 0.3471193015575409, 1.068362832069397, 0.5493931174278259]\n",
      "loss: 0.280889  [262144/343145] real loss: 0.2808888256549835\n",
      "[0.26603835821151733, 0.19090472161769867, 0.3967667818069458, 0.45544204115867615, 0.23133604228496552, 0.43066105246543884, 0.35919252038002014]\n",
      "[0.5059341788291931, 0.22954870760440826, 0.34007349610328674, 0.5274562239646912, 0.8993028402328491, 0.5119984149932861, 0.31925809383392334]\n",
      "loss: 0.296546  [327680/343145] real loss: 0.29654645919799805\n",
      "[0.3269321918487549, 0.1712357997894287, 0.31127703189849854, 0.43639931082725525, 0.3491699993610382, 0.2845936715602875, 0.23820218443870544]\n",
      "[0.2981278896331787, 0.1753174066543579, 0.2899287939071655, 0.3918280005455017, 0.3573299050331116, 0.24835848808288574, 0.31701982021331787]\n",
      "LOSSES TRAIN: 0.28142827181589036 LOSSES TEST: 0.32545617648533415\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.276994  [    0/343145] real loss: 0.2769938111305237\n",
      "[0.10224685072898865, 0.6714173555374146, 0.19829635322093964, 0.20463116466999054, 0.36537468433380127, 0.2939576804637909, 0.3037504255771637]\n",
      "[0.14323770999908447, 0.5628997087478638, 0.21627488732337952, 0.22602221369743347, 0.47417548298835754, 0.5552680492401123, 0.21302840113639832]\n",
      "loss: 0.276128  [65536/343145] real loss: 0.2761276662349701\n",
      "[0.07223508507013321, 0.23901815712451935, 0.30501025915145874, 0.3070298433303833, 0.16767698526382446, 0.3165113925933838, 0.18684935569763184]\n",
      "[0.0919509008526802, 0.31124868988990784, 0.300383597612381, 0.23656751215457916, 0.1581593006849289, 0.25875329971313477, 0.21720020473003387]\n",
      "loss: 0.282133  [131072/343145] real loss: 0.2821325957775116\n",
      "[0.2630958557128906, 0.34553226828575134, 0.5904189348220825, 0.39543822407722473, 0.2537563145160675, 0.5888636112213135, 0.23355183005332947]\n",
      "[0.24582171440124512, 0.4918866753578186, 0.6744654774665833, 0.6270686388015747, 0.4084438979625702, 1.1016876697540283, 0.4264684021472931]\n",
      "loss: 0.272486  [196608/343145] real loss: 0.27248579263687134\n",
      "[0.3613550066947937, 0.217675119638443, 0.4135300815105438, 0.23103398084640503, 0.11671417206525803, 0.2318817675113678, 0.6920599341392517]\n",
      "[0.32721859216690063, 0.3535943031311035, 0.4077340066432953, 0.26615628600120544, 0.18760991096496582, 0.16025370359420776, 0.6429260969161987]\n",
      "loss: 0.288656  [262144/343145] real loss: 0.28865593671798706\n",
      "[0.5033349394798279, 0.2917573153972626, 0.11869611591100693, 0.0918164849281311, 0.1907324343919754, 0.25557300448417664, 0.19744105637073517]\n",
      "[0.6641433835029602, 0.2705957889556885, 0.08282479643821716, 0.13211430609226227, 0.2332874983549118, 0.3860712945461273, 0.22876770794391632]\n",
      "loss: 0.276499  [327680/343145] real loss: 0.276498943567276\n",
      "[0.12466605007648468, 0.5001083016395569, 0.13746029138565063, 0.08813796937465668, 0.10351882129907608, 0.41263753175735474, 0.28152182698249817]\n",
      "[0.13463670015335083, 0.6254400014877319, 0.2103663980960846, 0.10992749780416489, 0.09527300298213959, 0.6221106052398682, 0.33479902148246765]\n",
      "LOSSES TRAIN: 0.2815630120180902 LOSSES TEST: 0.3249776079541161\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.286610  [    0/343145] real loss: 0.28661036491394043\n",
      "[0.3223482072353363, 0.22377069294452667, 0.26194682717323303, 0.28783437609672546, 0.169867604970932, 0.10885794460773468, 0.22163125872612]\n",
      "[0.4442161023616791, 0.3633562922477722, 0.37872979044914246, 0.23947861790657043, 0.09988150745630264, 0.18270990252494812, 0.1789814978837967]\n",
      "loss: 0.274568  [65536/343145] real loss: 0.2745678424835205\n",
      "[0.5551203489303589, 0.2053539752960205, 0.19907590746879578, 0.38848865032196045, 0.1512989103794098, 0.405717134475708, 0.13280609250068665]\n",
      "[0.5296816229820251, 0.2848159968852997, 0.17836369574069977, 0.6192389130592346, 0.20124900341033936, 0.5751214027404785, 0.17805589735507965]\n",
      "loss: 0.275332  [131072/343145] real loss: 0.2753320038318634\n",
      "[0.6706371307373047, 0.33124828338623047, 0.2918001115322113, 0.1961635947227478, 0.1480541229248047, 0.18702974915504456, 0.3143133819103241]\n",
      "[0.9472193121910095, 0.39381730556488037, 0.4319843053817749, 0.14261089265346527, 0.13154810667037964, 0.15302839875221252, 0.28748178482055664]\n",
      "loss: 0.275413  [196608/343145] real loss: 0.27541273832321167\n",
      "[0.46861496567726135, 0.4068642854690552, 0.20934632420539856, 0.8850170969963074, 0.36168810725212097, 0.2322702407836914, 0.32679784297943115]\n",
      "[0.6316620707511902, 0.6243414878845215, 0.14279800653457642, 0.6339181065559387, 0.5029696822166443, 0.3316687047481537, 0.3701907992362976]\n",
      "loss: 0.278598  [262144/343145] real loss: 0.2785979211330414\n",
      "[0.23545193672180176, 0.18047887086868286, 0.10626983642578125, 0.5667856931686401, 0.7069776058197021, 0.7793788313865662, 0.18206195533275604]\n",
      "[0.25588059425354004, 0.1719990074634552, 0.10126390308141708, 0.5280359983444214, 1.0291855335235596, 0.5721774697303772, 0.20222850143909454]\n",
      "loss: 0.274622  [327680/343145] real loss: 0.274621844291687\n",
      "[0.21044041216373444, 0.1311856508255005, 0.1665927618741989, 0.6000928282737732, 0.23825614154338837, 0.31848621368408203, 0.4614182114601135]\n",
      "[0.22192899882793427, 0.12169269472360611, 0.21135839819908142, 1.1475048065185547, 0.22764909267425537, 0.2853595018386841, 0.6761325001716614]\n",
      "LOSSES TRAIN: 0.28132714827855426 LOSSES TEST: 0.32374595744269236\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.345942  [    0/343145] real loss: 0.34594234824180603\n",
      "[0.31108587980270386, 0.47639161348342896, 0.46050387620925903, 0.10980847477912903, 0.2092074751853943, 0.244523823261261, 0.8399827480316162]\n",
      "[0.19802649319171906, 0.3356564939022064, 0.37784960865974426, 0.11350850015878677, 0.30730220675468445, 0.3356848955154419, 1.34950852394104]\n",
      "loss: 0.272208  [65536/343145] real loss: 0.2722083628177643\n",
      "[0.4808499217033386, 0.25446435809135437, 0.08154640346765518, 0.37254029512405396, 0.19852915406227112, 0.21148467063903809, 0.1825096160173416]\n",
      "[0.7475185394287109, 0.23616759479045868, 0.1359896957874298, 0.388685017824173, 0.1832711100578308, 0.26130950450897217, 0.20429711043834686]\n",
      "loss: 0.274701  [131072/343145] real loss: 0.2747010290622711\n",
      "[0.27299243211746216, 0.2523486018180847, 0.4868789315223694, 0.2393733263015747, 0.34183457493782043, 0.3654937148094177, 0.4254990518093109]\n",
      "[0.4355471134185791, 0.23580549657344818, 0.580207884311676, 0.3281054198741913, 0.3696227967739105, 0.3663586974143982, 0.7207316160202026]\n",
      "loss: 0.271407  [196608/343145] real loss: 0.2714066803455353\n",
      "[0.6387212872505188, 0.22158464789390564, 0.5602457523345947, 0.16738247871398926, 0.2929745018482208, 0.22005131840705872, 0.35512134432792664]\n",
      "[0.9828243255615234, 0.4079369902610779, 0.5451754331588745, 0.2551470994949341, 0.2016007900238037, 0.22150738537311554, 0.36489561200141907]\n",
      "loss: 0.280045  [262144/343145] real loss: 0.28004512190818787\n",
      "[0.06369835138320923, 0.4362383484840393, 0.2603839933872223, 0.17822939157485962, 0.42941731214523315, 0.21891537308692932, 0.25502023100852966]\n",
      "[0.053044501692056656, 0.3390393853187561, 0.20437738299369812, 0.2431565821170807, 0.5643023252487183, 0.22972889244556427, 0.4444314241409302]\n",
      "loss: 0.267828  [327680/343145] real loss: 0.2678282856941223\n",
      "[0.24423760175704956, 0.33535000681877136, 0.1424637734889984, 0.09348610043525696, 0.6866522431373596, 0.17521050572395325, 0.23554342985153198]\n",
      "[0.277948796749115, 0.3126088082790375, 0.21453139185905457, 0.11047810316085815, 0.8101396560668945, 0.26435020565986633, 0.32594621181488037]\n",
      "LOSSES TRAIN: 0.28060072837840944 LOSSES TEST: 0.32447894130434307\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.281951  [    0/343145] real loss: 0.28195059299468994\n",
      "[0.253054141998291, 0.22438053786754608, 0.2521766126155853, 0.14072412252426147, 0.7475746870040894, 0.5130545496940613, 0.5656975507736206]\n",
      "[0.2687835991382599, 0.2892273962497711, 0.3045646846294403, 0.10995069891214371, 0.7622347474098206, 0.6232641339302063, 0.9201712012290955]\n",
      "loss: 0.272324  [65536/343145] real loss: 0.2723243534564972\n",
      "[0.3085843324661255, 0.2595866322517395, 0.5264546275138855, 0.3052726984024048, 0.3165305554866791, 0.5951389074325562, 0.2792414128780365]\n",
      "[0.5888322591781616, 0.5055462121963501, 0.5488224625587463, 0.4607976973056793, 0.5097550749778748, 0.7745593786239624, 0.20341719686985016]\n",
      "loss: 0.275780  [131072/343145] real loss: 0.2757801115512848\n",
      "[0.4695051610469818, 0.5607953667640686, 0.3865012526512146, 0.1816834807395935, 0.13023138046264648, 0.5994781255722046, 0.3906574547290802]\n",
      "[0.5368350744247437, 0.3771734833717346, 1.1920135021209717, 0.2514631152153015, 0.18901999294757843, 0.7316595911979675, 0.5088943243026733]\n",
      "loss: 0.273957  [196608/343145] real loss: 0.2739574611186981\n",
      "[0.30360686779022217, 0.2558881640434265, 0.15602514147758484, 0.4784584045410156, 0.13891904056072235, 0.3877218961715698, 0.17214584350585938]\n",
      "[0.3862452805042267, 0.2879835069179535, 0.1566808968782425, 0.45391198992729187, 0.1801030933856964, 0.6671661734580994, 0.2326958179473877]\n",
      "loss: 0.270196  [262144/343145] real loss: 0.2701962888240814\n",
      "[0.22929319739341736, 0.09291064739227295, 0.4280869662761688, 0.14946042001247406, 0.8437143564224243, 0.4507652819156647, 1.0033715963363647]\n",
      "[0.20778138935565948, 0.14639249444007874, 0.4665488004684448, 0.18263690173625946, 1.5459531545639038, 0.9086724519729614, 0.7957344055175781]\n",
      "loss: 0.284157  [327680/343145] real loss: 0.28415724635124207\n",
      "[0.13132523000240326, 0.10197512805461884, 0.20374852418899536, 0.14782288670539856, 0.14327780902385712, 0.23581364750862122, 0.20109011232852936]\n",
      "[0.08239729702472687, 0.10316290706396103, 0.3053651750087738, 0.13349610567092896, 0.13635119795799255, 0.24791590869426727, 0.2251282036304474]\n",
      "LOSSES TRAIN: 0.28098750540188383 LOSSES TEST: 0.3247791769958678\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.281161  [    0/343145] real loss: 0.28116095066070557\n",
      "[0.20200340449810028, 0.2058904618024826, 0.34276166558265686, 0.3239938020706177, 0.1740054339170456, 0.2592138648033142, 0.09717004001140594]\n",
      "[0.3170152008533478, 0.28092238306999207, 0.303376704454422, 0.39488327503204346, 0.21154500544071198, 0.2409810870885849, 0.10881220549345016]\n",
      "loss: 0.268655  [65536/343145] real loss: 0.2686552405357361\n",
      "[0.11276165395975113, 0.20823954045772552, 0.1831386685371399, 0.20649173855781555, 0.2888055741786957, 0.5226451754570007, 0.33021318912506104]\n",
      "[0.1484559029340744, 0.1922598034143448, 0.2001314014196396, 0.20028609037399292, 0.3359327018260956, 0.7388927936553955, 0.40485039353370667]\n",
      "loss: 0.276696  [131072/343145] real loss: 0.2766962945461273\n",
      "[0.19992360472679138, 0.3208378255367279, 0.3307890295982361, 0.17039978504180908, 0.10625249147415161, 0.35363301634788513, 0.21012312173843384]\n",
      "[0.24983389675617218, 0.3795816898345947, 0.3625894784927368, 0.18898530304431915, 0.1378054916858673, 0.42658060789108276, 0.21023380756378174]\n",
      "loss: 0.271483  [196608/343145] real loss: 0.27148330211639404\n",
      "[0.3391687572002411, 0.06389553844928741, 0.5003501176834106, 0.18303313851356506, 0.2521723210811615, 0.2457513064146042, 0.312744140625]\n",
      "[0.3757097125053406, 0.055086299777030945, 0.4559861123561859, 0.19676850736141205, 0.34691122174263, 0.200730100274086, 0.458159476518631]\n",
      "loss: 0.282821  [262144/343145] real loss: 0.2828212380409241\n",
      "[0.5098695755004883, 0.2587127983570099, 0.4233376979827881, 0.2770960032939911, 0.05948727950453758, 0.1742972582578659, 0.4853532016277313]\n",
      "[0.5576601028442383, 0.23525629937648773, 0.3508794903755188, 0.30006200075149536, 0.0806197002530098, 0.23147881031036377, 0.5878140926361084]\n",
      "loss: 0.268630  [327680/343145] real loss: 0.2686302959918976\n",
      "[0.1764771044254303, 0.2164987176656723, 0.0841190442442894, 0.1442807912826538, 0.48046278953552246, 0.1813855916261673, 0.22551879286766052]\n",
      "[0.209466814994812, 0.19013170897960663, 0.1584504097700119, 0.0891358032822609, 0.6596059203147888, 0.14894750714302063, 0.3065012991428375]\n",
      "LOSSES TRAIN: 0.2803139626270249 LOSSES TEST: 0.3240078389644623\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.274901  [    0/343145] real loss: 0.27490076422691345\n",
      "[0.3541208505630493, 0.13119079172611237, 1.4190698862075806, 0.2816529870033264, 0.3208416700363159, 2.5047905445098877, 0.21022051572799683]\n",
      "[0.4608227014541626, 0.179967001080513, 1.2249053716659546, 0.1830907016992569, 0.35865089297294617, 3.0617053508758545, 0.2144984006881714]\n",
      "loss: 0.274228  [65536/343145] real loss: 0.2742278277873993\n",
      "[0.30204543471336365, 0.28424620628356934, 0.45873087644577026, 0.5298770666122437, 0.32861316204071045, 0.43892762064933777, 0.43169915676116943]\n",
      "[0.3710397183895111, 0.34835588932037354, 0.4637809097766876, 0.33861780166625977, 0.3307654857635498, 0.3989483118057251, 0.4634755253791809]\n",
      "loss: 0.280109  [131072/343145] real loss: 0.28010910749435425\n",
      "[0.3991430997848511, 1.6153208017349243, 0.26877361536026, 0.3166346549987793, 0.17558293044567108, 0.18147701025009155, 0.1813374161720276]\n",
      "[0.405979722738266, 1.504454255104065, 0.24286890029907227, 0.3040879964828491, 0.18200699985027313, 0.2417108118534088, 0.23329490423202515]\n",
      "loss: 0.270195  [196608/343145] real loss: 0.27019524574279785\n",
      "[0.3529511094093323, 0.16668415069580078, 0.08607089519500732, 0.1852024495601654, 0.18005774915218353, 0.15504509210586548, 1.0384129285812378]\n",
      "[0.4291782081127167, 0.25659218430519104, 0.09120579808950424, 0.18413610756397247, 0.20869478583335876, 0.1662037968635559, 2.4043257236480713]\n",
      "loss: 0.277697  [262144/343145] real loss: 0.27769678831100464\n",
      "[0.569486677646637, 0.2684982419013977, 0.17255812883377075, 0.13603487610816956, 0.37046030163764954, 0.22928911447525024, 0.9318462610244751]\n",
      "[0.6319181323051453, 0.33043211698532104, 0.28119128942489624, 0.132430300116539, 0.36081570386886597, 0.2913600206375122, 0.8148390054702759]\n",
      "loss: 0.278196  [327680/343145] real loss: 0.2781960368156433\n",
      "[0.24962879717350006, 0.15298743546009064, 0.17460307478904724, 0.1813201606273651, 0.1408611387014389, 0.08916213363409042, 0.2694454789161682]\n",
      "[0.29300108551979065, 0.10184240341186523, 0.19189488887786865, 0.24078230559825897, 0.19558589160442352, 0.09758950024843216, 0.29130271077156067]\n",
      "LOSSES TRAIN: 0.27962642233996166 LOSSES TEST: 0.32963634246871587\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.281656  [    0/343145] real loss: 0.28165608644485474\n",
      "[0.5257012844085693, 0.13076815009117126, 0.25134095549583435, 0.1186431497335434, 0.2169235348701477, 0.4450748860836029, 0.11080551147460938]\n",
      "[0.35688289999961853, 0.12758569419384003, 0.23558959364891052, 0.10741239786148071, 0.19949521124362946, 0.4801408052444458, 0.113401398062706]\n",
      "loss: 0.268270  [65536/343145] real loss: 0.26827049255371094\n",
      "[0.23584352433681488, 0.20843496918678284, 0.5574465394020081, 0.7117932438850403, 0.0577077716588974, 0.4046299159526825, 0.24281123280525208]\n",
      "[0.24768880009651184, 0.14766010642051697, 0.3567728102207184, 1.131445050239563, 0.0680525004863739, 0.5180603861808777, 0.24912360310554504]\n",
      "loss: 0.291536  [131072/343145] real loss: 0.29153579473495483\n",
      "[0.6618500351905823, 0.5555457472801208, 0.26916739344596863, 0.5890509486198425, 0.2108646035194397, 0.4081054925918579, 0.47523894906044006]\n",
      "[0.8145331144332886, 0.6928406357765198, 0.17397060990333557, 0.5182101130485535, 0.3004647195339203, 0.7220445871353149, 0.4800090193748474]\n",
      "loss: 0.272048  [196608/343145] real loss: 0.27204763889312744\n",
      "[0.214532271027565, 0.15078553557395935, 0.23987707495689392, 0.539925754070282, 0.24442599713802338, 0.5008257627487183, 0.3771088123321533]\n",
      "[0.2122509926557541, 0.376475989818573, 0.34430670738220215, 0.6009303331375122, 0.2545573115348816, 0.49804720282554626, 0.47635188698768616]\n",
      "loss: 0.272891  [262144/343145] real loss: 0.272891104221344\n",
      "[0.11666055023670197, 0.1641814261674881, 0.3720623850822449, 0.488169401884079, 0.22724857926368713, 0.4976353049278259, 0.21731431782245636]\n",
      "[0.14395371079444885, 0.17295439541339874, 0.5309474468231201, 0.7597411274909973, 0.2930225133895874, 0.4345669746398926, 0.3620957136154175]\n",
      "loss: 0.279075  [327680/343145] real loss: 0.27907535433769226\n",
      "[0.11728110909461975, 0.1623205840587616, 0.44140613079071045, 0.2066512554883957, 1.0487035512924194, 0.2630094587802887, 0.2965209186077118]\n",
      "[0.2539394795894623, 0.14759330451488495, 0.3954254984855652, 0.19537359476089478, 1.229623556137085, 0.39804062247276306, 0.2869633138179779]\n",
      "LOSSES TRAIN: 0.27979557783830733 LOSSES TEST: 0.3292814606711978\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.272998  [    0/343145] real loss: 0.2729983627796173\n",
      "[0.2039959579706192, 0.2871120572090149, 0.19640594720840454, 0.9340197443962097, 0.12414327263832092, 0.2628544569015503, 0.2948917746543884]\n",
      "[0.3261207938194275, 0.1831091046333313, 0.15136529505252838, 0.8981473445892334, 0.1611545979976654, 0.21657289564609528, 0.42523229122161865]\n",
      "loss: 0.295728  [65536/343145] real loss: 0.2957283854484558\n",
      "[0.908011794090271, 0.49570611119270325, 0.13239622116088867, 0.16282843053340912, 0.17172206938266754, 0.30964383482933044, 0.34140586853027344]\n",
      "[0.5370066165924072, 0.49104249477386475, 0.09238779544830322, 0.18231700360774994, 0.2150598019361496, 0.24000580608844757, 0.3615380823612213]\n",
      "loss: 0.282291  [131072/343145] real loss: 0.2822912931442261\n",
      "[0.22976145148277283, 0.3456389605998993, 0.20930060744285583, 0.29851779341697693, 0.33102691173553467, 0.5259687304496765, 0.23892377316951752]\n",
      "[0.19729049503803253, 0.5836156010627747, 0.22986571490764618, 0.35938337445259094, 0.45107439160346985, 0.8349196910858154, 0.20981279015541077]\n",
      "loss: 0.277320  [196608/343145] real loss: 0.27731969952583313\n",
      "[0.06530437618494034, 0.0844908058643341, 0.1359158307313919, 0.09023986756801605, 0.49326109886169434, 0.3696523904800415, 0.1743345856666565]\n",
      "[0.06554830074310303, 0.11230040341615677, 0.12327110022306442, 0.08524730056524277, 0.4840409755706787, 0.4440883994102478, 0.2655763030052185]\n",
      "loss: 0.272558  [262144/343145] real loss: 0.2725582718849182\n",
      "[0.3202727437019348, 0.29567623138427734, 0.32255926728248596, 0.35279855132102966, 0.4480096399784088, 0.213504359126091, 0.10149140655994415]\n",
      "[0.26541009545326233, 0.3099217116832733, 0.2184906005859375, 0.5114564895629883, 0.38455599546432495, 0.13234469294548035, 0.14368890225887299]\n",
      "loss: 0.277611  [327680/343145] real loss: 0.27761104702949524\n",
      "[0.41298773884773254, 0.14884445071220398, 0.17381909489631653, 0.07907067984342575, 0.38873937726020813, 0.08686831593513489, 0.2882121801376343]\n",
      "[0.5207566022872925, 0.1547936052083969, 0.2309902161359787, 0.08032330125570297, 0.47910982370376587, 0.09726019948720932, 0.4505193829536438]\n",
      "LOSSES TRAIN: 0.2797748361315046 LOSSES TEST: 0.3290744778655824\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.284170  [    0/343145] real loss: 0.2841697633266449\n",
      "[0.1391996443271637, 0.1681138575077057, 0.177859365940094, 0.21003320813179016, 0.33026421070098877, 0.38973674178123474, 0.5125684142112732]\n",
      "[0.16683760285377502, 0.14990030229091644, 0.22411109507083893, 0.20281679928302765, 0.5658389925956726, 0.5034937858581543, 0.6412128210067749]\n",
      "loss: 0.265671  [65536/343145] real loss: 0.2656714618206024\n",
      "[0.11103126406669617, 0.19972212612628937, 0.46349483728408813, 0.3737320005893707, 0.16636298596858978, 0.2812340557575226, 0.4686608612537384]\n",
      "[0.17572209239006042, 0.23114870488643646, 0.7000251412391663, 0.3631053864955902, 0.24895501136779785, 0.21581631898880005, 0.9160116314888]\n",
      "loss: 0.281388  [131072/343145] real loss: 0.2813880741596222\n",
      "[0.19444215297698975, 0.26469388604164124, 0.08796465396881104, 0.25584569573402405, 0.08705417811870575, 0.21108104288578033, 0.10627691447734833]\n",
      "[0.21912699937820435, 0.3383774161338806, 0.08864320069551468, 0.3163388967514038, 0.14930029213428497, 0.2275218963623047, 0.16073259711265564]\n",
      "loss: 0.279738  [196608/343145] real loss: 0.2797379493713379\n",
      "[0.35414794087409973, 0.49827077984809875, 0.15527573227882385, 1.0575494766235352, 0.15297454595565796, 0.6448462009429932, 0.32524240016937256]\n",
      "[0.3949073255062103, 0.7884737253189087, 0.2228681892156601, 0.9996662735939026, 0.1467622071504593, 0.7308903336524963, 0.229966402053833]\n",
      "loss: 0.285258  [262144/343145] real loss: 0.28525814414024353\n",
      "[0.40479180216789246, 0.19086338579654694, 0.29616859555244446, 0.22511187195777893, 0.30974239110946655, 0.1839144080877304, 0.09587322175502777]\n",
      "[0.6081373691558838, 0.15874320268630981, 0.31349191069602966, 0.3073770999908447, 0.4084019064903259, 0.2049526870250702, 0.09287620335817337]\n",
      "loss: 0.282247  [327680/343145] real loss: 0.2822466492652893\n",
      "[0.8495273590087891, 0.21253831684589386, 0.2799515724182129, 0.6155622601509094, 0.5340448021888733, 0.9005946516990662, 0.26230934262275696]\n",
      "[0.5998818278312683, 0.318272203207016, 0.31446489691734314, 0.6452904343605042, 0.5037638545036316, 0.8153010010719299, 0.3502192795276642]\n",
      "LOSSES TRAIN: 0.2793976341684659 LOSSES TEST: 0.3321254551410675\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.270874  [    0/343145] real loss: 0.2708737254142761\n",
      "[0.12622210383415222, 0.26107361912727356, 0.2113543450832367, 0.19171671569347382, 0.5747563242912292, 0.1756649613380432, 0.8536686897277832]\n",
      "[0.0935015007853508, 0.3086193799972534, 0.28574898838996887, 0.21507160365581512, 0.44502881169319153, 0.3193720877170563, 0.9342029690742493]\n",
      "loss: 0.276415  [65536/343145] real loss: 0.27641549706459045\n",
      "[0.663029670715332, 0.16848739981651306, 0.4265104830265045, 0.2044043242931366, 0.23592224717140198, 0.2298503965139389, 0.16089284420013428]\n",
      "[0.8248274922370911, 0.25278159976005554, 0.4621526300907135, 0.2199639081954956, 0.3116927146911621, 0.37602710723876953, 0.2317647933959961]\n",
      "loss: 0.269663  [131072/343145] real loss: 0.26966291666030884\n",
      "[0.13582926988601685, 0.1462627500295639, 0.20455977320671082, 0.25130271911621094, 0.15636691451072693, 0.2090923935174942, 0.19490191340446472]\n",
      "[0.12745040655136108, 0.174435093998909, 0.2642458975315094, 0.2813938856124878, 0.1326977014541626, 0.2839483916759491, 0.19216330349445343]\n",
      "loss: 0.270510  [196608/343145] real loss: 0.2705104351043701\n",
      "[0.36611998081207275, 0.3236992657184601, 0.2705066204071045, 0.10754688829183578, 0.5774018168449402, 1.1606221199035645, 0.3699120581150055]\n",
      "[0.25590747594833374, 0.34289780259132385, 0.3729983866214752, 0.2260819971561432, 0.7245712280273438, 1.1536242961883545, 0.5321776866912842]\n",
      "loss: 0.276647  [262144/343145] real loss: 0.2766472399234772\n",
      "[0.11251883953809738, 0.2656877040863037, 0.3036588132381439, 0.27322301268577576, 0.15357926487922668, 0.45135074853897095, 0.20201608538627625]\n",
      "[0.11075650155544281, 0.29898208379745483, 0.304812490940094, 0.3909105956554413, 0.16188330948352814, 0.6995010375976562, 0.27041900157928467]\n",
      "loss: 0.270563  [327680/343145] real loss: 0.27056318521499634\n",
      "[0.18480266630649567, 0.5515053868293762, 0.5638535618782043, 0.18306289613246918, 0.1117541491985321, 1.929127812385559, 0.21489733457565308]\n",
      "[0.18097929656505585, 0.8443403840065002, 0.9036057591438293, 0.21146458387374878, 0.10545220226049423, 1.7539799213409424, 0.23948419094085693]\n",
      "LOSSES TRAIN: 0.2793139371843565 LOSSES TEST: 0.32927429108392625\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.286580  [    0/343145] real loss: 0.2865801453590393\n",
      "[1.4635300636291504, 0.4404968321323395, 0.4465719163417816, 0.11203594505786896, 0.14700740575790405, 0.3250604569911957, 0.5252946019172668]\n",
      "[1.5967521667480469, 0.2662699818611145, 0.5377559065818787, 0.12224080413579941, 0.2741072177886963, 0.3412463068962097, 0.7686907052993774]\n",
      "loss: 0.273365  [65536/343145] real loss: 0.2733650505542755\n",
      "[0.15873202681541443, 0.9850924611091614, 0.1954512745141983, 0.3532949686050415, 0.2985956370830536, 0.28978729248046875, 0.328855961561203]\n",
      "[0.296400785446167, 1.4786360263824463, 0.24116601049900055, 0.3849378228187561, 0.3534201979637146, 0.27416709065437317, 0.41013872623443604]\n",
      "loss: 0.286171  [131072/343145] real loss: 0.28617143630981445\n",
      "[0.22046329081058502, 0.4133658707141876, 0.1952502578496933, 0.30715951323509216, 0.3222540616989136, 0.1311354786157608, 0.14893491566181183]\n",
      "[0.21371929347515106, 0.533059298992157, 0.2281568944454193, 0.3737485110759735, 0.290356308221817, 0.13634470105171204, 0.18354150652885437]\n",
      "loss: 0.287206  [196608/343145] real loss: 0.28720611333847046\n",
      "[0.3618108034133911, 0.6578696370124817, 0.3378729820251465, 0.48352789878845215, 0.3449755012989044, 1.3220316171646118, 0.6705662608146667]\n",
      "[0.5292032957077026, 0.7489259839057922, 0.3732495903968811, 0.4951086938381195, 0.7429153323173523, 1.33717679977417, 0.9443307518959045]\n",
      "loss: 0.270696  [262144/343145] real loss: 0.27069589495658875\n",
      "[0.1727052927017212, 0.8401012420654297, 0.1971103996038437, 0.23128505051136017, 0.4084506630897522, 1.4581276178359985, 0.2596866190433502]\n",
      "[0.18685440719127655, 0.8551337718963623, 0.18136169016361237, 0.20934028923511505, 0.5786094665527344, 1.109196662902832, 0.45852696895599365]\n",
      "loss: 0.294282  [327680/343145] real loss: 0.29428166151046753\n",
      "[0.19641178846359253, 0.2129116803407669, 0.5900121331214905, 0.4762972295284271, 0.5066724419593811, 0.18683062493801117, 0.16931436955928802]\n",
      "[0.17868980765342712, 0.17948441207408905, 0.8938837051391602, 0.7570143938064575, 0.4209428131580353, 0.1827515959739685, 0.23498159646987915]\n",
      "LOSSES TRAIN: 0.2789617234042713 LOSSES TEST: 0.33041826600120183\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.288156  [    0/343145] real loss: 0.28815585374832153\n",
      "[0.3963530659675598, 0.12123878300189972, 0.43734556436538696, 0.1573726087808609, 0.22542254626750946, 0.22329968214035034, 0.14041054248809814]\n",
      "[0.3304644823074341, 0.08343259990215302, 0.5695908665657043, 0.1539808064699173, 0.210527703166008, 0.2507238984107971, 0.11153440177440643]\n",
      "loss: 0.297850  [65536/343145] real loss: 0.29784950613975525\n",
      "[0.7230727076530457, 0.25905048847198486, 0.27099859714508057, 0.24988214671611786, 0.34623682498931885, 0.259706974029541, 0.2792970836162567]\n",
      "[0.8544725179672241, 0.31914597749710083, 0.1449819952249527, 0.447330117225647, 0.3665558099746704, 0.28954389691352844, 0.3524658977985382]\n",
      "loss: 0.276208  [131072/343145] real loss: 0.27620774507522583\n",
      "[0.2158345878124237, 0.41393548250198364, 0.16453303396701813, 0.1251409947872162, 0.3724842667579651, 0.24704718589782715, 0.32082876563072205]\n",
      "[0.23165419697761536, 0.41509708762168884, 0.1847531944513321, 0.1555791050195694, 0.3410012125968933, 0.2866488993167877, 0.19059990346431732]\n",
      "loss: 0.283683  [196608/343145] real loss: 0.2836828827857971\n",
      "[0.47202253341674805, 0.10427231341600418, 0.21685446798801422, 0.20672908425331116, 0.1885267198085785, 0.2257525771856308, 0.5048287510871887]\n",
      "[0.5256143808364868, 0.17269420623779297, 0.24039870500564575, 0.20772840082645416, 0.22087299823760986, 0.17763490974903107, 0.38631671667099]\n",
      "loss: 0.268511  [262144/343145] real loss: 0.2685111463069916\n",
      "[0.19301392138004303, 0.24629846215248108, 0.9179332256317139, 0.547951340675354, 0.26621416211128235, 0.1840316355228424, 0.36507827043533325]\n",
      "[0.20519408583641052, 0.3107154071331024, 1.1746034622192383, 0.5488145351409912, 0.27490660548210144, 0.14710719883441925, 0.4444171190261841]\n",
      "loss: 0.281677  [327680/343145] real loss: 0.28167736530303955\n",
      "[0.20369286835193634, 0.42357325553894043, 0.5711454749107361, 0.2594587504863739, 0.24189108610153198, 0.44581708312034607, 0.2332638055086136]\n",
      "[0.21712689101696014, 0.38946229219436646, 0.4495241343975067, 0.2932545840740204, 0.2188269942998886, 0.507736086845398, 0.28692498803138733]\n",
      "LOSSES TRAIN: 0.27886074568544117 LOSSES TEST: 0.3325722756839934\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.278159  [    0/343145] real loss: 0.2781588137149811\n",
      "[0.3102673888206482, 0.37246400117874146, 0.08652956783771515, 0.20180624723434448, 0.27227872610092163, 0.5177227854728699, 0.26709458231925964]\n",
      "[0.4723106026649475, 0.4602030813694, 0.08505240082740784, 0.10218729823827744, 0.3311411142349243, 0.786412239074707, 0.22831100225448608]\n",
      "loss: 0.276397  [65536/343145] real loss: 0.2763974070549011\n",
      "[0.07930970191955566, 0.26760953664779663, 0.199498251080513, 0.19928111135959625, 0.20341211557388306, 0.17232882976531982, 0.5835599303245544]\n",
      "[0.181278795003891, 0.5393050312995911, 0.18847279250621796, 0.2516365051269531, 0.18418730795383453, 0.14023199677467346, 0.5241795182228088]\n",
      "loss: 0.274133  [131072/343145] real loss: 0.27413293719291687\n",
      "[0.17078369855880737, 0.18645158410072327, 0.34713733196258545, 0.22033943235874176, 0.2137862741947174, 0.2775787115097046, 0.23049801588058472]\n",
      "[0.19538749754428864, 0.21376070380210876, 0.38502249121665955, 0.3198387920856476, 0.16703151166439056, 0.2688854932785034, 0.26709750294685364]\n",
      "loss: 0.268063  [196608/343145] real loss: 0.26806318759918213\n",
      "[0.3263981342315674, 0.333297461271286, 0.4832572937011719, 0.4884611666202545, 0.2207687795162201, 0.24619463086128235, 0.3290878236293793]\n",
      "[0.36164429783821106, 0.32510849833488464, 0.3994095027446747, 0.4495241343975067, 0.24157840013504028, 0.23490889370441437, 0.37401679158210754]\n",
      "loss: 0.273270  [262144/343145] real loss: 0.2732698917388916\n",
      "[0.3817146420478821, 0.8346407413482666, 0.16143809258937836, 0.217316672205925, 0.1456567347049713, 0.1386793702840805, 0.4045602083206177]\n",
      "[0.41680169105529785, 0.9572762846946716, 0.16168740391731262, 0.32920822501182556, 0.13274450600147247, 0.1558833122253418, 0.5815930366516113]\n",
      "loss: 0.271197  [327680/343145] real loss: 0.271196573972702\n",
      "[0.7817465662956238, 0.4773254692554474, 0.384480357170105, 0.11483009904623032, 0.2018701732158661, 0.35947951674461365, 0.33096960186958313]\n",
      "[1.3576722145080566, 0.5214077830314636, 0.4660367965698242, 0.13842090964317322, 0.24233439564704895, 0.4742273986339569, 0.43673980236053467]\n",
      "LOSSES TRAIN: 0.278686890289897 LOSSES TEST: 0.32873940609750296\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.286480  [    0/343145] real loss: 0.28648048639297485\n",
      "[0.16609375178813934, 0.0954333245754242, 0.21733877062797546, 0.24546809494495392, 0.06260738521814346, 0.2465553730726242, 0.19603358209133148]\n",
      "[0.27535849809646606, 0.08822470158338547, 0.17563369870185852, 0.19987770915031433, 0.06005709990859032, 0.349927693605423, 0.20813949406147003]\n",
      "loss: 0.283219  [65536/343145] real loss: 0.2832193970680237\n",
      "[0.16667620837688446, 0.2601030766963959, 0.1526542752981186, 0.27858754992485046, 0.8593351244926453, 0.467462420463562, 0.2909024953842163]\n",
      "[0.17995069921016693, 0.2022068053483963, 0.12303759902715683, 0.2838769853115082, 1.341657042503357, 0.6086848974227905, 0.40995827317237854]\n",
      "loss: 0.272464  [131072/343145] real loss: 0.27246442437171936\n",
      "[0.419264018535614, 0.4131295084953308, 0.2400480955839157, 0.46292275190353394, 0.2864496111869812, 0.7242050170898438, 0.5272084474563599]\n",
      "[0.7249450087547302, 0.3882603943347931, 0.2831011116504669, 0.38489559292793274, 0.6104187965393066, 0.5155100226402283, 0.4832168221473694]\n",
      "loss: 0.271826  [196608/343145] real loss: 0.27182626724243164\n",
      "[0.5616999864578247, 0.651702344417572, 0.2594330310821533, 0.07428846508264542, 0.29341328144073486, 0.24512510001659393, 0.22272968292236328]\n",
      "[0.7877187728881836, 0.7664659023284912, 0.2162552922964096, 0.08424979448318481, 0.26998770236968994, 0.3944527804851532, 0.30096909403800964]\n",
      "loss: 0.339262  [262144/343145] real loss: 0.33926156163215637\n",
      "[0.15312936902046204, 0.18421690165996552, 0.15683050453662872, 0.8978970646858215, 0.111507847905159, 0.5327198505401611, 0.2034999579191208]\n",
      "[0.1793479025363922, 0.2879217863082886, 0.1582462042570114, 1.318485140800476, 0.10827239602804184, 0.5572407841682434, 0.44466322660446167]\n",
      "loss: 0.282181  [327680/343145] real loss: 0.2821807563304901\n",
      "[0.16547313332557678, 0.2723007798194885, 0.17053180932998657, 0.3276318609714508, 0.2066560834646225, 0.15627776086330414, 0.3175094425678253]\n",
      "[0.1612946093082428, 0.20702038705348969, 0.284661203622818, 0.36649149656295776, 0.1759141981601715, 0.17358510196208954, 0.35988521575927734]\n",
      "LOSSES TRAIN: 0.27871040787015644 LOSSES TEST: 0.3293028204214005\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.273989  [    0/343145] real loss: 0.27398937940597534\n",
      "[0.14640794694423676, 0.3644218444824219, 0.7500640153884888, 0.318462073802948, 0.30553722381591797, 0.3506488800048828, 0.18708141148090363]\n",
      "[0.2008313089609146, 0.4437052309513092, 1.640678882598877, 0.5089728832244873, 0.36104848980903625, 0.395529568195343, 0.17875570058822632]\n",
      "loss: 0.275045  [65536/343145] real loss: 0.27504512667655945\n",
      "[0.4993531107902527, 0.4333325922489166, 0.2199702262878418, 0.24089914560317993, 0.49496734142303467, 0.4794158935546875, 0.40979671478271484]\n",
      "[0.7956859469413757, 0.5371569991111755, 0.1590019017457962, 0.28330349922180176, 0.9042724967002869, 0.36273741722106934, 0.4855414927005768]\n",
      "loss: 0.298259  [131072/343145] real loss: 0.29825860261917114\n",
      "[0.2515057921409607, 0.16186022758483887, 0.19044475257396698, 0.22828219830989838, 0.0709494948387146, 0.5861258506774902, 0.3528130054473877]\n",
      "[0.2895255982875824, 0.20012639462947845, 0.24160990118980408, 0.26716670393943787, 0.08356740325689316, 0.9053292870521545, 0.3537727892398834]\n",
      "loss: 0.308260  [196608/343145] real loss: 0.3082595765590668\n",
      "[0.37850525975227356, 0.12066857516765594, 0.1659921556711197, 0.07981038093566895, 0.16603043675422668, 0.332397997379303, 0.33730900287628174]\n",
      "[0.4047892987728119, 0.16099271178245544, 0.2588987946510315, 0.10090840607881546, 0.31864258646965027, 0.40139928460121155, 0.3211629092693329]\n",
      "loss: 0.284614  [262144/343145] real loss: 0.28461435437202454\n",
      "[0.3849693238735199, 0.1464892476797104, 1.100847601890564, 0.29684385657310486, 0.19024060666561127, 0.5382524132728577, 0.2971065044403076]\n",
      "[0.3994204103946686, 0.19700349867343903, 1.6216539144515991, 0.3017497956752777, 0.23999200761318207, 0.7022249698638916, 0.3511672019958496]\n",
      "loss: 0.281088  [327680/343145] real loss: 0.28108763694763184\n",
      "[0.15057258307933807, 0.22952161729335785, 0.14750626683235168, 0.4057682752609253, 0.11026109009981155, 0.16148927807807922, 0.5521750450134277]\n",
      "[0.11419370025396347, 0.3145017921924591, 0.1464391052722931, 0.30661869049072266, 0.1744110882282257, 0.18277759850025177, 0.6842280030250549]\n",
      "LOSSES TRAIN: 0.2782965132168361 LOSSES TEST: 0.3312427756332216\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.275196  [    0/343145] real loss: 0.2751961350440979\n",
      "[0.18497148156166077, 0.45242053270339966, 0.22964760661125183, 0.2764590084552765, 0.2821318805217743, 0.6847867369651794, 0.1401177942752838]\n",
      "[0.17045530676841736, 0.41792169213294983, 0.2901169955730438, 0.28728508949279785, 0.30020710825920105, 1.050086259841919, 0.12846410274505615]\n",
      "loss: 0.270976  [65536/343145] real loss: 0.2709762156009674\n",
      "[0.6364956498146057, 0.2523824870586395, 0.15496328473091125, 0.47253307700157166, 0.2591547667980194, 0.07431631535291672, 0.0976073145866394]\n",
      "[0.7693017721176147, 0.21741721034049988, 0.17357060313224792, 0.622441291809082, 0.18808700144290924, 0.09181229770183563, 0.14954259991645813]\n",
      "loss: 0.289586  [131072/343145] real loss: 0.2895864248275757\n",
      "[0.43328794836997986, 0.2660592198371887, 0.2769356966018677, 0.570012629032135, 0.48112282156944275, 0.25745058059692383, 0.17757979035377502]\n",
      "[0.6509832143783569, 0.22415931522846222, 0.3329544961452484, 0.552442729473114, 0.6485750675201416, 0.2914530038833618, 0.29375800490379333]\n",
      "loss: 0.270642  [196608/343145] real loss: 0.27064165472984314\n",
      "[0.29149559140205383, 0.5329476594924927, 0.24901121854782104, 0.23559796810150146, 0.22163254022598267, 0.2322188913822174, 0.20193840563297272]\n",
      "[0.2635064125061035, 0.6786324977874756, 0.2716273069381714, 0.38480520248413086, 0.29125678539276123, 0.3384380042552948, 0.1563362032175064]\n",
      "loss: 0.276023  [262144/343145] real loss: 0.2760225832462311\n",
      "[0.4231824278831482, 0.23266136646270752, 0.7448252439498901, 0.2601345181465149, 0.5061920881271362, 0.2625199258327484, 0.29803866147994995]\n",
      "[0.4231312870979309, 0.20525678992271423, 0.9321359992027283, 0.3274419903755188, 0.6416119337081909, 0.40263137221336365, 0.5160313844680786]\n",
      "loss: 0.267429  [327680/343145] real loss: 0.2674288749694824\n",
      "[0.4422757923603058, 0.15453146398067474, 0.5243453979492188, 0.4674529731273651, 0.4631533920764923, 0.1612538993358612, 0.4486662447452545]\n",
      "[0.8514977097511292, 0.18646208941936493, 0.5742970705032349, 0.44653648138046265, 0.5010828971862793, 0.1439964920282364, 0.4784308969974518]\n",
      "LOSSES TRAIN: 0.27801914725984844 LOSSES TEST: 0.333951697463081\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.272895  [    0/343145] real loss: 0.27289482951164246\n",
      "[0.39926353096961975, 0.17862889170646667, 0.5947834849357605, 0.14494670927524567, 0.760695219039917, 0.45607849955558777, 0.19985991716384888]\n",
      "[0.6884669661521912, 0.23554790019989014, 0.41033822298049927, 0.11136089265346527, 0.9577956795692444, 0.8180415034294128, 0.251825213432312]\n",
      "loss: 0.271686  [65536/343145] real loss: 0.27168551087379456\n",
      "[0.2565577030181885, 0.19244223833084106, 0.06912492960691452, 0.20474904775619507, 0.4110785126686096, 0.368198424577713, 0.26739370822906494]\n",
      "[0.1615063101053238, 0.3329673111438751, 0.047062598168849945, 0.26392799615859985, 0.29115068912506104, 0.40067169070243835, 0.26617631316185]\n",
      "loss: 0.275099  [131072/343145] real loss: 0.27509868144989014\n",
      "[0.2847500145435333, 0.20590920746326447, 0.17331106960773468, 0.33281171321868896, 0.10501281917095184, 0.4035111665725708, 0.2709117531776428]\n",
      "[0.2773110866546631, 0.22780360281467438, 0.20800501108169556, 0.4794160723686218, 0.13720859587192535, 0.4014168977737427, 0.2683263123035431]\n",
      "loss: 0.269211  [196608/343145] real loss: 0.2692108452320099\n",
      "[0.1436302363872528, 0.17428220808506012, 0.18099330365657806, 0.3362833261489868, 0.39601922035217285, 0.8719463348388672, 0.24013833701610565]\n",
      "[0.1421167105436325, 0.14766760170459747, 0.1997227966785431, 0.33128058910369873, 0.6981167793273926, 2.0106048583984375, 0.26867660880088806]\n",
      "loss: 0.277623  [262144/343145] real loss: 0.2776229977607727\n",
      "[0.2301490157842636, 0.11447776854038239, 0.40118491649627686, 0.3474213182926178, 0.32793447375297546, 0.17938178777694702, 0.2922365367412567]\n",
      "[0.2461780160665512, 0.11416920274496078, 1.1516952514648438, 0.47276657819747925, 0.3594161868095398, 0.19480060040950775, 0.24271291494369507]\n",
      "loss: 0.272501  [327680/343145] real loss: 0.2725006937980652\n",
      "[0.1777455359697342, 0.5376938581466675, 0.23526698350906372, 0.1343759149312973, 0.17728738486766815, 0.40897223353385925, 0.23379957675933838]\n",
      "[0.2187809944152832, 0.5332654714584351, 0.258041113615036, 0.18200328946113586, 0.3110792934894562, 0.4578738808631897, 0.30723199248313904]\n",
      "LOSSES TRAIN: 0.2778101258334659 LOSSES TEST: 0.33374571942147757\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.277029  [    0/343145] real loss: 0.2770289182662964\n",
      "[0.21500401198863983, 0.12450587749481201, 0.7992692589759827, 0.10675350576639175, 0.1982826143503189, 0.14156195521354675, 0.8066475987434387]\n",
      "[0.3754788935184479, 0.14405810832977295, 1.0451459884643555, 0.3094486892223358, 0.24271801114082336, 0.17016910016536713, 0.5770382881164551]\n",
      "loss: 0.272222  [65536/343145] real loss: 0.2722218632698059\n",
      "[0.3234782814979553, 0.2641274631023407, 1.4282336235046387, 0.2668713331222534, 0.49723586440086365, 0.6323578953742981, 0.11523652076721191]\n",
      "[0.2785996198654175, 0.6483936905860901, 1.2473143339157104, 0.27950629591941833, 0.3976985812187195, 0.8513912558555603, 0.12687690556049347]\n",
      "loss: 0.278315  [131072/343145] real loss: 0.27831506729125977\n",
      "[0.40902143716812134, 0.19816866517066956, 1.3670647144317627, 0.3450230360031128, 0.083001047372818, 0.24026760458946228, 0.5717101097106934]\n",
      "[0.4376905858516693, 0.20646211504936218, 2.1092607975006104, 0.28633248805999756, 0.07109399884939194, 0.22449170053005219, 0.5213844180107117]\n",
      "loss: 0.269262  [196608/343145] real loss: 0.26926249265670776\n",
      "[0.13263753056526184, 0.24924293160438538, 0.46337419748306274, 0.22160425782203674, 2.1693289279937744, 0.1989707052707672, 0.13108505308628082]\n",
      "[0.12974999845027924, 0.3164834976196289, 0.47129908204078674, 0.3684921860694885, 1.3345332145690918, 0.18302109837532043, 0.13134460151195526]\n",
      "loss: 0.275209  [262144/343145] real loss: 0.2752090096473694\n",
      "[0.20880009233951569, 0.31880342960357666, 0.2294667512178421, 0.2151908278465271, 0.3909967243671417, 0.12900228798389435, 0.1237974613904953]\n",
      "[0.21086619794368744, 0.32931700348854065, 0.31636929512023926, 0.24481940269470215, 0.34056609869003296, 0.1342017948627472, 0.12014620006084442]\n",
      "loss: 0.273578  [327680/343145] real loss: 0.2735777795314789\n",
      "[0.640343964099884, 0.09280887246131897, 0.6201938390731812, 0.1926036775112152, 0.34239494800567627, 0.2519374489784241, 0.21880847215652466]\n",
      "[0.8038750886917114, 0.09212449938058853, 1.557350993156433, 0.21665790677070618, 0.38559460639953613, 0.30897921323776245, 0.2914898991584778]\n",
      "LOSSES TRAIN: 0.27812078027498155 LOSSES TEST: 0.3336272920880999\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.276876  [    0/343145] real loss: 0.27687591314315796\n",
      "[0.3278958201408386, 0.8655670285224915, 0.18422970175743103, 0.1506766378879547, 0.31827592849731445, 0.34179747104644775, 0.17803895473480225]\n",
      "[0.42263948917388916, 0.5184100866317749, 0.10562939941883087, 0.1581570953130722, 0.3708533048629761, 0.3602966070175171, 0.1546614021062851]\n",
      "loss: 0.279166  [65536/343145] real loss: 0.27916622161865234\n",
      "[0.275752454996109, 0.4719896912574768, 0.14256663620471954, 0.2434558868408203, 0.3027450740337372, 0.21720074117183685, 0.14091314375400543]\n",
      "[0.3202441930770874, 0.7011274099349976, 0.18262170255184174, 0.23730508983135223, 0.27258339524269104, 0.22941990196704865, 0.15770059823989868]\n",
      "loss: 0.275134  [131072/343145] real loss: 0.2751341164112091\n",
      "[0.13783089816570282, 0.19518126547336578, 0.24237148463726044, 0.2526659071445465, 0.18658825755119324, 0.22622691094875336, 0.3551943898200989]\n",
      "[0.14999990165233612, 0.2774856984615326, 0.3339797854423523, 0.3695749044418335, 0.16681548953056335, 0.2719237804412842, 0.4458051323890686]\n",
      "loss: 0.278575  [196608/343145] real loss: 0.2785749137401581\n",
      "[0.312314510345459, 0.1930575668811798, 0.19927015900611877, 0.4648337662220001, 0.3004629611968994, 0.37496650218963623, 0.27063435316085815]\n",
      "[0.34312641620635986, 0.2149869054555893, 0.2115940898656845, 0.4261317253112793, 0.3288741111755371, 0.4895164966583252, 0.3166041970252991]\n",
      "loss: 0.277501  [262144/343145] real loss: 0.2775005102157593\n",
      "[0.29106947779655457, 0.4916161596775055, 0.28550779819488525, 0.3946211636066437, 0.7193427085876465, 0.397106409072876, 0.1387343555688858]\n",
      "[0.3686656951904297, 0.6942993998527527, 0.4522212743759155, 0.558340311050415, 1.0155258178710938, 0.28590768575668335, 0.1960325986146927]\n",
      "loss: 0.277819  [327680/343145] real loss: 0.2778191566467285\n",
      "[0.20562879741191864, 0.18265610933303833, 0.21915021538734436, 0.17544664442539215, 0.7031320929527283, 0.39338743686676025, 0.3647243082523346]\n",
      "[0.23396450281143188, 0.470421701669693, 0.20435820519924164, 0.2025946080684662, 1.043015956878662, 0.4520445168018341, 0.392732709646225]\n",
      "LOSSES TRAIN: 0.27767448056311833 LOSSES TEST: 0.3335746753783453\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.280125  [    0/343145] real loss: 0.28012457489967346\n",
      "[0.28695183992385864, 0.385140061378479, 0.29833656549453735, 0.2699848413467407, 0.19174954295158386, 0.15027621388435364, 0.23827825486660004]\n",
      "[0.2903158962726593, 0.5510680675506592, 0.3788800835609436, 0.2515210211277008, 0.21528109908103943, 0.10349509865045547, 0.2993018925189972]\n",
      "loss: 0.265694  [65536/343145] real loss: 0.26569411158561707\n",
      "[0.26429474353790283, 0.21158462762832642, 0.289350301027298, 0.09813239425420761, 0.547874927520752, 0.22577700018882751, 0.2161269187927246]\n",
      "[0.29863241314888, 0.16667409241199493, 0.36160001158714294, 0.1645165979862213, 0.773139476776123, 0.29457971453666687, 0.31216320395469666]\n",
      "loss: 0.291461  [131072/343145] real loss: 0.2914605736732483\n",
      "[0.17809368669986725, 0.21219787001609802, 0.1925797313451767, 0.19828936457633972, 0.12974005937576294, 0.3165915608406067, 0.13689222931861877]\n",
      "[0.2119976133108139, 0.26285359263420105, 0.23124080896377563, 0.21428531408309937, 0.19420389831066132, 0.3445228934288025, 0.1615327000617981]\n",
      "loss: 0.283444  [196608/343145] real loss: 0.28344371914863586\n",
      "[0.22117961943149567, 0.27628982067108154, 0.0880197137594223, 0.1825869083404541, 0.23081818222999573, 0.20770327746868134, 0.09404085576534271]\n",
      "[0.22433818876743317, 0.30465149879455566, 0.09601549804210663, 0.22816960513591766, 0.11546630412340164, 0.34538379311561584, 0.073191799223423]\n",
      "loss: 0.272489  [262144/343145] real loss: 0.27248895168304443\n",
      "[0.4280174970626831, 0.13186019659042358, 0.5243418216705322, 0.8350867033004761, 0.2809014916419983, 0.09388789534568787, 0.2618764340877533]\n",
      "[0.353893905878067, 0.1505350023508072, 1.0407963991165161, 1.1817233562469482, 0.2508220076560974, 0.1233929991722107, 0.29465919733047485]\n",
      "loss: 0.269146  [327680/343145] real loss: 0.2691456079483032\n",
      "[0.25956350564956665, 0.11886051297187805, 0.2750418782234192, 0.5319432616233826, 0.3185938596725464, 0.13528217375278473, 0.40783625841140747]\n",
      "[0.22663268446922302, 0.1681768000125885, 0.3064267933368683, 0.6630455851554871, 0.4260300099849701, 0.1677560955286026, 0.41956448554992676]\n",
      "LOSSES TRAIN: 0.2777723159108843 LOSSES TEST: 0.33506021329334806\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.278842  [    0/343145] real loss: 0.27884235978126526\n",
      "[0.2602391541004181, 0.5359748005867004, 0.14516626298427582, 0.19694600999355316, 0.36790475249290466, 0.27657052874565125, 0.6751642823219299]\n",
      "[0.23570489883422852, 0.5873491764068604, 0.20269130170345306, 0.22919969260692596, 0.3094848096370697, 0.2873656153678894, 1.3568271398544312]\n",
      "loss: 0.278643  [65536/343145] real loss: 0.27864333987236023\n",
      "[0.21338070929050446, 0.15982338786125183, 0.3521265387535095, 0.4850950539112091, 0.25098717212677, 0.17107903957366943, 0.6322644948959351]\n",
      "[0.4272628128528595, 0.12733159959316254, 0.25033169984817505, 0.2385053038597107, 0.23434551060199738, 0.20284301042556763, 0.6853809952735901]\n",
      "loss: 0.266495  [131072/343145] real loss: 0.2664954960346222\n",
      "[0.21390733122825623, 0.639742910861969, 0.3701750934123993, 0.3256776034832001, 0.4749304950237274, 0.48668670654296875, 0.5880799889564514]\n",
      "[0.20794330537319183, 0.5128968954086304, 0.35028979182243347, 0.4444504976272583, 0.5729771852493286, 0.5243515968322754, 0.9537110924720764]\n",
      "loss: 0.277080  [196608/343145] real loss: 0.2770799696445465\n",
      "[0.354828417301178, 0.5752225518226624, 0.5412564873695374, 0.08164050430059433, 0.34181854128837585, 0.17428870499134064, 0.1604655683040619]\n",
      "[0.3736675977706909, 1.004166603088379, 0.5193660855293274, 0.08456449955701828, 0.4045735001564026, 0.1938880980014801, 0.29669761657714844]\n",
      "loss: 0.273771  [262144/343145] real loss: 0.2737709581851959\n",
      "[0.8812861442565918, 0.267525315284729, 0.2966000437736511, 0.29943519830703735, 0.32736632227897644, 0.2721603512763977, 0.16193023324012756]\n",
      "[1.1705260276794434, 0.23153480887413025, 0.42346668243408203, 0.3033967912197113, 0.447277307510376, 0.2168097048997879, 0.175674706697464]\n",
      "loss: 0.271366  [327680/343145] real loss: 0.2713661193847656\n",
      "[0.5565816164016724, 0.4404955506324768, 0.1735430359840393, 0.49324506521224976, 0.5299749970436096, 0.1518787145614624, 0.5242313742637634]\n",
      "[0.817960798740387, 0.5505381226539612, 0.13418099284172058, 0.6007553935050964, 0.7409173250198364, 0.11206720024347305, 0.7018260359764099]\n",
      "LOSSES TRAIN: 0.27760719330537886 LOSSES TEST: 0.33691018394061495\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.270904  [    0/343145] real loss: 0.27090418338775635\n",
      "[0.3732754588127136, 0.12122632563114166, 0.2622438371181488, 0.23774370551109314, 0.33317187428474426, 0.4767422378063202, 0.24065782129764557]\n",
      "[0.2989974915981293, 0.1588447093963623, 0.2824684977531433, 0.17160889506340027, 0.22173388302326202, 0.43326249718666077, 0.24849259853363037]\n",
      "loss: 0.318428  [65536/343145] real loss: 0.3184276819229126\n",
      "[0.600813090801239, 0.07490367442369461, 0.46627944707870483, 0.16761937737464905, 0.12556177377700806, 0.23747724294662476, 0.09686567634344101]\n",
      "[0.7209851145744324, 0.08666609972715378, 0.6092449426651001, 0.2257400006055832, 0.38929569721221924, 0.2973766028881073, 0.1607086956501007]\n",
      "loss: 0.274285  [131072/343145] real loss: 0.2742854058742523\n",
      "[0.3453916311264038, 0.16077840328216553, 0.982257604598999, 0.17826813459396362, 0.22652536630630493, 0.6813586354255676, 0.20651695132255554]\n",
      "[0.2740859091281891, 0.1515664905309677, 1.4835681915283203, 0.11263339221477509, 0.22255860269069672, 0.8807321190834045, 0.09156209975481033]\n",
      "loss: 0.268493  [196608/343145] real loss: 0.26849299669265747\n",
      "[0.6813346147537231, 0.4139360189437866, 0.43100857734680176, 0.36329394578933716, 0.12640133500099182, 0.17047765851020813, 0.07009075582027435]\n",
      "[0.6103442311286926, 0.35030338168144226, 0.33161240816116333, 0.37107160687446594, 0.126362606883049, 0.210356205701828, 0.08691339939832687]\n",
      "loss: 0.286421  [262144/343145] real loss: 0.28642064332962036\n",
      "[0.5295835733413696, 0.22123360633850098, 0.21381807327270508, 0.17364279925823212, 0.14374659955501556, 0.23883070051670074, 0.15369108319282532]\n",
      "[0.6404271721839905, 0.2739711105823517, 0.309018611907959, 0.1635873019695282, 0.12252140045166016, 0.316297322511673, 0.1659362018108368]\n",
      "loss: 0.272323  [327680/343145] real loss: 0.27232280373573303\n",
      "[0.11545952409505844, 0.16996103525161743, 0.30599626898765564, 0.3705819249153137, 0.5038098096847534, 0.14949646592140198, 0.05230020731687546]\n",
      "[0.10124669969081879, 0.16413690149784088, 0.44850897789001465, 0.3705134987831116, 1.5413908958435059, 0.1990155130624771, 0.03948640078306198]\n",
      "LOSSES TRAIN: 0.2766241551864715 LOSSES TEST: 0.3362706488087064\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.269094  [    0/343145] real loss: 0.2690943479537964\n",
      "[0.1184343695640564, 0.1150219589471817, 0.1935061365365982, 0.28509315848350525, 0.115028515458107, 0.41802167892456055, 0.13572734594345093]\n",
      "[0.2826825976371765, 0.12400549650192261, 0.2518652081489563, 0.369260311126709, 0.19973289966583252, 0.47055190801620483, 0.14669780433177948]\n",
      "loss: 0.284181  [65536/343145] real loss: 0.28418055176734924\n",
      "[0.13210251927375793, 0.22562718391418457, 0.4209498167037964, 0.23497650027275085, 0.603354275226593, 0.21432042121887207, 0.15831395983695984]\n",
      "[0.1469752937555313, 0.3318701982498169, 0.6096836924552917, 0.23611870408058167, 0.6759580969810486, 0.20741219818592072, 0.20329418778419495]\n",
      "loss: 0.270568  [131072/343145] real loss: 0.270567923784256\n",
      "[0.1992022544145584, 0.28250643610954285, 0.2675379514694214, 0.15764567255973816, 0.4146304726600647, 0.1939397156238556, 0.8385820984840393]\n",
      "[0.31611520051956177, 0.3029223084449768, 0.25248050689697266, 0.14726810157299042, 0.4674298167228699, 0.18113210797309875, 1.1133553981781006]\n",
      "loss: 0.277464  [196608/343145] real loss: 0.27746352553367615\n",
      "[0.15125544369220734, 1.1356686353683472, 0.28888893127441406, 0.5175262093544006, 0.2870628237724304, 0.2471248209476471, 0.34198445081710815]\n",
      "[0.24298760294914246, 1.4068034887313843, 0.3403001129627228, 0.4712887108325958, 0.2132880985736847, 0.3241667151451111, 0.2277367115020752]\n",
      "loss: 0.270361  [262144/343145] real loss: 0.2703607678413391\n",
      "[0.5823872089385986, 0.3378012478351593, 0.12456396967172623, 0.23367686569690704, 0.12518611550331116, 0.14746326208114624, 0.2981647253036499]\n",
      "[1.0560182332992554, 0.31620460748672485, 0.08958359807729721, 0.2523120939731598, 0.11149829626083374, 0.1494210958480835, 0.23343029618263245]\n",
      "loss: 0.280849  [327680/343145] real loss: 0.2808489203453064\n",
      "[0.3613256812095642, 0.22148311138153076, 0.330733984708786, 0.4687642455101013, 0.44786641001701355, 0.7803323268890381, 0.13456284999847412]\n",
      "[0.3730520009994507, 0.29193148016929626, 0.3384856879711151, 0.4181672930717468, 0.593638002872467, 1.131211280822754, 0.14725349843502045]\n",
      "LOSSES TRAIN: 0.27650523221208934 LOSSES TEST: 0.33463679466928753\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.275766  [    0/343145] real loss: 0.2757660448551178\n",
      "[0.24764105677604675, 3.4895474910736084, 0.5556358098983765, 0.1710381805896759, 0.17995887994766235, 0.45906004309654236, 0.24225668609142303]\n",
      "[0.26794761419296265, 1.2255160808563232, 0.6506999135017395, 0.17891670763492584, 0.17554879188537598, 0.8657556772232056, 0.22559960186481476]\n",
      "loss: 0.275793  [65536/343145] real loss: 0.2757929861545563\n",
      "[0.3725397288799286, 0.1842217594385147, 0.17084521055221558, 1.7291115522384644, 0.23310035467147827, 0.356880247592926, 1.500962257385254]\n",
      "[0.48292288184165955, 0.16865620017051697, 0.2017325907945633, 1.1606814861297607, 0.36142781376838684, 0.4644913077354431, 1.9994659423828125]\n",
      "loss: 0.274525  [131072/343145] real loss: 0.27452489733695984\n",
      "[0.477601557970047, 0.29607954621315, 0.18823522329330444, 0.203222393989563, 0.4238058924674988, 0.3288115859031677, 0.3450367748737335]\n",
      "[0.4641340970993042, 0.4252263009548187, 0.3203534185886383, 0.2547719180583954, 0.34593871235847473, 0.293471097946167, 0.47702550888061523]\n",
      "loss: 0.279619  [196608/343145] real loss: 0.2796191871166229\n",
      "[0.2912777066230774, 0.16598187386989594, 0.3747003972530365, 0.4408355951309204, 0.1458282768726349, 0.18748873472213745, 0.13377660512924194]\n",
      "[0.387057900428772, 0.1517142951488495, 0.3961060047149658, 0.44292300939559937, 0.15380050241947174, 0.19325590133666992, 0.15234389901161194]\n",
      "loss: 0.281794  [262144/343145] real loss: 0.28179386258125305\n",
      "[0.3165220320224762, 0.31802356243133545, 0.27373257279396057, 0.2280249446630478, 0.3613094985485077, 0.2946009635925293, 0.29040226340293884]\n",
      "[0.4040262997150421, 0.3017547130584717, 0.28937700390815735, 0.278031587600708, 0.46486589312553406, 0.31711140275001526, 0.3321317136287689]\n",
      "loss: 0.279319  [327680/343145] real loss: 0.27931880950927734\n",
      "[0.14573706686496735, 0.1274673193693161, 0.5039848685264587, 0.9066848158836365, 0.4893134832382202, 0.1592583805322647, 0.27325719594955444]\n",
      "[0.1336303949356079, 0.12264109402894974, 0.5166701078414917, 0.8688110113143921, 0.48921462893486023, 0.2275995910167694, 0.23785969614982605]\n",
      "LOSSES TRAIN: 0.27641432022764567 LOSSES TEST: 0.335414415314084\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.274344  [    0/343145] real loss: 0.27434372901916504\n",
      "[0.5217007994651794, 0.6605629324913025, 0.5691862106323242, 0.25763294100761414, 0.38492125272750854, 0.20321393013000488, 0.8669928908348083]\n",
      "[0.5155712962150574, 1.2770658731460571, 0.6833899021148682, 0.22158938646316528, 0.34414049983024597, 0.16563430428504944, 0.563270092010498]\n",
      "loss: 0.270714  [65536/343145] real loss: 0.2707139253616333\n",
      "[0.7072710990905762, 0.38392651081085205, 0.21762891113758087, 0.47529086470603943, 0.21843433380126953, 0.4127316474914551, 0.4125770926475525]\n",
      "[0.514681339263916, 0.41815420985221863, 0.17094139754772186, 0.5151845216751099, 0.24952848255634308, 0.7343137860298157, 0.41906243562698364]\n",
      "loss: 0.274567  [131072/343145] real loss: 0.27456724643707275\n",
      "[0.6626029014587402, 0.34050488471984863, 0.19369477033615112, 0.43355444073677063, 0.23420509696006775, 0.32791414856910706, 0.42794564366340637]\n",
      "[0.7819617390632629, 0.3764795958995819, 0.23286619782447815, 0.5195831060409546, 0.25531139969825745, 0.2986662983894348, 0.41063442826271057]\n",
      "loss: 0.279465  [196608/343145] real loss: 0.2794652581214905\n",
      "[0.20971903204917908, 0.34227266907691956, 0.12765400111675262, 0.28757748007774353, 0.5684720277786255, 0.2109014242887497, 0.2378241866827011]\n",
      "[0.27893051505088806, 0.4048108160495758, 0.137111097574234, 0.46752119064331055, 0.6019861102104187, 0.20392629504203796, 0.2614839971065521]\n",
      "loss: 0.275256  [262144/343145] real loss: 0.2752557098865509\n",
      "[0.4674724042415619, 0.8497803211212158, 0.13441364467144012, 0.5700072050094604, 0.25484803318977356, 0.45950835943222046, 0.11093398928642273]\n",
      "[0.4655110239982605, 0.8439420461654663, 0.18037830293178558, 0.5726723074913025, 0.3034957945346832, 0.7353981733322144, 0.1097801923751831]\n",
      "loss: 0.279931  [327680/343145] real loss: 0.27993103861808777\n",
      "[0.3392823040485382, 0.24691246449947357, 0.2867872416973114, 0.20216794312000275, 0.06770986318588257, 0.74288010597229, 0.2453024834394455]\n",
      "[0.6365119218826294, 0.3733544945716858, 0.21075159311294556, 0.1514092981815338, 0.10552459955215454, 0.6520496010780334, 0.33184680342674255]\n",
      "LOSSES TRAIN: 0.27654106595686506 LOSSES TEST: 0.33359469118572416\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.275477  [    0/343145] real loss: 0.27547702193260193\n",
      "[0.5293711423873901, 0.2648206055164337, 0.11453431844711304, 0.38594335317611694, 1.3039497137069702, 0.0787254273891449, 0.36606884002685547]\n",
      "[0.46308791637420654, 0.25481730699539185, 0.13792769610881805, 0.3961370885372162, 1.008339524269104, 0.08405129611492157, 0.43004798889160156]\n",
      "loss: 0.273584  [65536/343145] real loss: 0.2735835611820221\n",
      "[0.3193950057029724, 0.24091960489749908, 0.4764750599861145, 0.20449531078338623, 0.20760948956012726, 0.3071659803390503, 0.40828800201416016]\n",
      "[0.2643994092941284, 0.3196866810321808, 0.805068850517273, 0.25478529930114746, 0.3612543046474457, 0.3028711974620819, 0.6420987844467163]\n",
      "loss: 0.273170  [131072/343145] real loss: 0.27316999435424805\n",
      "[0.16694606840610504, 0.34569236636161804, 0.3783125579357147, 0.179124653339386, 0.23864559829235077, 0.2726117670536041, 1.2729542255401611]\n",
      "[0.200861394405365, 0.3679924011230469, 0.26555660367012024, 0.20216959714889526, 0.2223673015832901, 0.20010128617286682, 1.7529805898666382]\n",
      "loss: 0.275472  [196608/343145] real loss: 0.2754715383052826\n",
      "[0.20775379240512848, 0.1756870001554489, 0.9687514901161194, 0.30415332317352295, 0.4378725290298462, 0.09792909026145935, 0.5125983953475952]\n",
      "[0.20651580393314362, 0.1495172083377838, 1.361800193786621, 0.3531741797924042, 0.24142980575561523, 0.2588507831096649, 0.427430123090744]\n",
      "loss: 0.274726  [262144/343145] real loss: 0.27472633123397827\n",
      "[0.13541960716247559, 0.16002638638019562, 0.17218609154224396, 0.276839017868042, 0.5324752926826477, 0.22867920994758606, 0.35502877831459045]\n",
      "[0.17666319012641907, 0.3493206202983856, 0.24011309444904327, 0.5688624978065491, 0.3588675856590271, 0.21160471439361572, 0.4124889075756073]\n",
      "loss: 0.270690  [327680/343145] real loss: 0.27068981528282166\n",
      "[0.15032804012298584, 0.22958089411258698, 0.5913000106811523, 0.808253824710846, 0.19302652776241302, 0.3137128949165344, 0.1629343330860138]\n",
      "[0.1548510044813156, 0.21100318431854248, 0.6177890300750732, 1.0945188999176025, 0.41088438034057617, 0.22584261000156403, 0.1615666002035141]\n",
      "LOSSES TRAIN: 0.27645621200402576 LOSSES TEST: 0.337481385185605\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.280962  [    0/343145] real loss: 0.28096193075180054\n",
      "[0.4253624975681305, 0.19952866435050964, 0.4378601908683777, 0.20957139134407043, 0.4041171669960022, 0.7446522116661072, 0.6431129574775696]\n",
      "[0.25716641545295715, 0.21934059262275696, 0.688389778137207, 0.22877810895442963, 0.5059695839881897, 0.8440368175506592, 0.5999695062637329]\n",
      "loss: 0.266141  [65536/343145] real loss: 0.26614120602607727\n",
      "[0.29919037222862244, 0.20949044823646545, 0.2831423580646515, 0.18499808013439178, 0.18185308575630188, 0.2873527705669403, 0.2711009085178375]\n",
      "[0.3324134945869446, 0.24364620447158813, 0.27707159519195557, 0.1990002989768982, 0.18928049504756927, 0.44510412216186523, 0.257601797580719]\n",
      "loss: 0.277515  [131072/343145] real loss: 0.2775150537490845\n",
      "[0.4097364544868469, 0.35422027111053467, 0.37107688188552856, 0.34864306449890137, 0.22833365201950073, 0.27654004096984863, 0.7224754095077515]\n",
      "[0.5916559100151062, 0.37968799471855164, 0.2770528793334961, 0.5741912722587585, 0.2218669056892395, 0.2817871868610382, 0.5600883364677429]\n",
      "loss: 0.270457  [196608/343145] real loss: 0.2704572081565857\n",
      "[0.31557607650756836, 0.7210862040519714, 0.2774464190006256, 0.18458712100982666, 0.2807234227657318, 0.11332626640796661, 0.3876314163208008]\n",
      "[0.3650810122489929, 0.40359050035476685, 0.22034180164337158, 0.4355400800704956, 0.22790838778018951, 0.18108099699020386, 0.8209745287895203]\n"
     ]
    }
   ],
   "source": [
    "print(\"DEVICE:\", device)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "data_interval_len = int(600/2)\n",
    "data_ohlc_sample_len = 1 # 1 for each of open high low close\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    dataloader_train = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "    dataset_size = len(dataloader_train.dataset)\n",
    "    model.train()\n",
    "    losses_train = []\n",
    "    for batch, (Feature_X, feature_y) in enumerate(dataloader_train):\n",
    "\n",
    "#         xlogreturn1 = Feature_X['log_return1_2s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "#         xbookdirvolume1 = Feature_X['book_directional_volume1_2s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "#         X = torch.stack([xlogreturn1, \n",
    "#                          xbookdirvolume1], dim=2)\n",
    "#         X = X.reshape(-1,1,data_interval_len*data_ohlc_sample_len*2)\n",
    "        X = Feature_X['log_return1_2s'] * 1000\n",
    "        \n",
    "        y = feature_y * 100\n",
    "#         y = Feature_X['book_realized_volatility'] * 100\n",
    "        X = X.type(torch.cuda.FloatTensor)    \n",
    "        y = y.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        feature_y = feature_y.to(device)\n",
    "        pred = model(X)\n",
    "        pred.to(device)\n",
    "#         print(X.size(), \"input\")\n",
    "#         print(pred.size(), \"pred\")\n",
    "#         print(y.size(),'y')\n",
    "#         input()\n",
    "#         loss_fn_mse\n",
    "#         loss_mse = loss_fn_mse(y, pred)\n",
    "        loss_orig = loss_fn_orig(y, pred)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_orig.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        losses_train.append(loss_orig.item())\n",
    "        # we want 5 spread out output per epoch\n",
    "        if batch % int(dataset_size/5/batch_size) == 0:\n",
    "            loss, current = loss_orig.item(), batch * len(X)\n",
    "            # NOTE: real loss is same as upscaled normalized loss as it's percentage loss (rmspe)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{dataset_size:>5d}]\", 'real loss:', loss_fn_orig(feature_y.to('cuda:0'), (pred/100)).item())\n",
    "            print(pred.reshape(-1).tolist()[:7])\n",
    "            print(y.reshape(-1).tolist()[:7])\n",
    "            \n",
    "    dataloader_test = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "    dataset_size = len(dataloader_test.dataset)\n",
    "    model.eval()\n",
    "\n",
    "    losses_test = []\n",
    "    for batch, (Feature_X, feature_y) in enumerate(dataloader_test):\n",
    "        with torch.no_grad():\n",
    "#             X = Feature_X['book_realized_volatility']\n",
    "#         CNN approach\n",
    "#             xbookwap1 = Feature_X['book_wap1_1s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "#             xbookdirvolume1 = Feature_X['book_directional_volume1_1s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "#             X = torch.stack([xbookwap1, \n",
    "#                              xbookdirvolume1], dim=2)\n",
    "#             X = X.reshape(-1,1,data_interval_len*data_ohlc_sample_len*2)\n",
    "\n",
    "#         print(X)\n",
    "#         input()\n",
    "#             X = X.reshape(-1,int(600/30)*4*2)\n",
    "#             X = X.reshape(1,8,-1)\n",
    "#         print(X)\n",
    "#             X = torch.cat([X, Feature_X['book_realized_volatility'], Feature_X['trade_realized_volatility']],1)\n",
    "#             y = feature_y\n",
    "            X = Feature_X['log_return1_2s'] * 1000\n",
    "        \n",
    "            y = feature_y * 100\n",
    "#             X = torch.cat((X['x_realized_volatility'], X['x_wap_120s']), 1)\n",
    "#             X = Feature_X['x_wap_120s']\n",
    "#             y = Feature_X['x_realized_volatility']\n",
    "            X = X.type(torch.cuda.FloatTensor)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn_orig(y, pred)\n",
    "            losses_test.append(loss.item())\n",
    "            \n",
    "    print(\"LOSSES TRAIN:\", np.mean(losses_train), \"LOSSES TEST:\", np.mean(losses_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "92f6420b-e415-4c48-8e43-cb3c407b33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(OUTPUT_DIRECTORY,\"05_2s_datanormalized_logreturn_sequencial.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5800f3dd-258a-4873-ba48-98a26bca027a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr [[0.0036344075262357213], [0.0023030722939839593], [0.001974389597446672], [0.0053188394310924895], [0.002627147852732812]]\n",
      "curr1s [0.0032973839266358745, 0.0018837148282878475, 0.001543782455083293, 0.0045055278991471435, 0.0024511532570696552]\n",
      "pred [[0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903]]\n",
      "actual [[0.0034380510915070772], [0.002843644004315138], [0.0016469400143250823], [0.0045009939931333065], [0.0022277499083429575]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr [[0.005505567859000631], [0.002583564806666279], [0.003342226784178032], [0.001825386429605389], [0.0023499431049795972]]\n",
      "curr1s [0.004266288593053351, 0.002322206915645627, 0.0027153584052034044, 0.0014572253909269938, 0.0022752323247224055]\n",
      "pred [[0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903]]\n",
      "actual [[0.005065346136689186], [0.0032045149710029364], [0.0024034560192376375], [0.002544580027461052], [0.0019930589478462934]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr [[0.0036982866537401547], [0.001589579562834356], [0.00250350177478549], [0.0016810987015589993], [0.006155246519659815]]\n",
      "curr1s [0.0033246328278157124, 0.0014030817000914185, 0.001522057847835663, 0.0013125854564212302, 0.005895381673349276]\n",
      "pred [[0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903]]\n",
      "actual [[0.005089106038212776], [0.0017484510317444801], [0.002240682952105999], [0.0014124299632385373], [0.004447725135833025]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr [[0.0055066300279102524], [0.007521367502576807], [0.014150298200341176], [0.0022619951320607184], [0.0012587560031778458]]\n",
      "curr1s [0.004429237442109815, 0.005901219429802633, 0.012374638909804352, 0.0019100852788617752, 0.0011237069708421598]\n",
      "pred [[0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903], [0.0015419030096381903]]\n",
      "actual [[0.004927168134599924], [0.0065541500225663185], [0.011375034227967262], [0.0018453890224918723], [0.0010599199449643493]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24160/1852269083.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         )\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "dataloader_test = DataLoader(test_dataset, batch_size=5,\n",
    "                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "dataset_size = len(dataloader_test.dataset)\n",
    "model.eval()\n",
    "\n",
    "losses_test = []\n",
    "for batch, (Feature_X, feature_y) in enumerate(dataloader_test):\n",
    "    with torch.no_grad():\n",
    "        xlogreturn1 = Feature_X['log_return1_2s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "        xbookdirvolume1 = Feature_X['book_directional_volume1_2s'].reshape(-1,data_interval_len,data_ohlc_sample_len)\n",
    "        X = torch.stack([xlogreturn1, \n",
    "                         xbookdirvolume1], dim=2)\n",
    "        X = X.reshape(-1,1,data_interval_len*data_ohlc_sample_len*2)\n",
    "#         print(X)\n",
    "#         print(X.size())\n",
    "#         input()\n",
    "#         print(X)\n",
    "#         input()\n",
    "#             X = torch.cat([X, Feature_X['book_realized_volatility'], Feature_X['trade_realized_volatility']],1)\n",
    "        y = feature_y\n",
    "#         y = Feature_X['book_realized_volatility']\n",
    "#             X = torch.cat((X['x_realized_volatility'], X['x_wap_120s']), 1)\n",
    "#             X = Feature_X['x_wap_120s']\n",
    "#             y = Feature_X['x_realized_volatility']\n",
    "        X = X.type(torch.cuda.FloatTensor)\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        print(\"curr\", Feature_X['book_realized_volatility'].tolist())\n",
    "        print('curr1s',[np.sqrt(np.sum(pd.Series(closep)**2)) for closep in [x[::] for x in xlogreturn1.reshape(-1,data_interval_len*data_ohlc_sample_len).tolist()]])\n",
    "        print('pred', pred.tolist())\n",
    "        print('actual',y.tolist())\n",
    "#         input()\n",
    "        \n",
    "            \n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cea68b-9cf2-4a6c-8fab-d0e6b8f7654d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
