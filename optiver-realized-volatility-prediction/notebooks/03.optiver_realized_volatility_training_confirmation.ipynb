{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2f18e2-9894-4f0c-bd57-8b37afc02309",
   "metadata": {},
   "source": [
    "### Can our model predict current volatility?  (forget future; first it should be capable of predicting current one with given features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c4e895-fd66-490d-a8b8-d28b324d3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from optiver_features_handler import get_features_map_for_stock, get_row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750eb0e3-2860-490b-bc3c-2a512485a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join(\"..\",\"input\",\"optiver-realized-volatility-prediction\")\n",
    "OUTPUT_DIRECTORY = os.path.join(\"..\",\"output\")\n",
    "MODEL_OUTPUT_DIRECTORY = os.path.join(OUTPUT_DIRECTORY,\"models\")\n",
    "os.makedirs(OUTPUT_DIRECTORY,exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_DIRECTORY,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02947ab-aa1d-4af0-9d6e-7a51cff159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_interval_seconds = 24\n",
    "data_intervals_count = int(600/data_interval_seconds)\n",
    "class OptiverRealizedVolatilityDataset(Dataset):\n",
    "    def __init__(self, data_directory, mode=\"train\", lazy_load=True):\n",
    "        \"\"\"initializes Optiver Competition dataset\n",
    "        `mode`: train|test\n",
    "        `data_directory`: the datadirectory of the input data, where there are test.csv, train.csv, and parquet folders for trade_train.parquet and other relevant folders\n",
    "        \"\"\"\n",
    "        print(\"INIT: OptiverRealizedVolatilityDataset\")\n",
    "        if mode.lower() not in ['train','test']:\n",
    "            raise Exception(\"Invalid mode passed for Optiver dataset. Valid values:train|test\")\n",
    "        self.data_directory = data_directory\n",
    "        self.mode = mode.lower()\n",
    "        self.main_df = pd.read_csv(os.path.join(self.data_directory,f'{self.mode}.csv'))\n",
    "#         if self.mode == 'train':\n",
    "#             self.main_df['row_id'] = self.main_df.apply(lambda x: f\"{x['stock_id']:.0f}-{x['time_id']:.0f}\", axis=1)\n",
    "        if self.mode == 'test':\n",
    "            self.main_df['target'] = 0\n",
    "        \n",
    "        self.cache_stocks_done_set = set()\n",
    "        # this is our final features lookup where we park all our features which can be addressed by row_id\n",
    "        # which is individual train/test.csv row id using 'stock_id`-`time_id`\n",
    "        self.cache_rowid_feature_map = {}\n",
    "        row_id_series = self.main_df['stock_id'].astype(str) + \"-\" +self.main_df['time_id'].astype(str)\n",
    "        targets = self.main_df['target'].tolist()\n",
    "        self.stock_possible_timeids_list = {}\n",
    "        for idx, row_id in enumerate(row_id_series.tolist()):\n",
    "            stock_id = int(row_id.split('-')[0])\n",
    "            time_id = int(row_id.split('-')[1])\n",
    "            self.cache_rowid_feature_map[row_id] = {'target_realized_volatility':targets[idx], 'stock_id':stock_id,'time_id':time_id,'row_id':row_id}\n",
    "            \n",
    "            # below code is to make sure what timeids we expect from stock data extractor\n",
    "            # in case of missing parquet files we'll have to know the keys to fill default values into\n",
    "            if stock_id not in self.stock_possible_timeids_list:\n",
    "                self.stock_possible_timeids_list[stock_id] = []\n",
    "            self.stock_possible_timeids_list[stock_id].append(time_id)\n",
    "            \n",
    "        \n",
    "        if lazy_load == False:\n",
    "            worker_data = []\n",
    "            for gkey, gdf in self.main_df.groupby(['stock_id']):\n",
    "                worker_data.append((self.data_directory, self.mode, gkey))\n",
    "#             print(\"---------- CPU COUNG:\", multiprocessing.cpu_count())\n",
    "            # NOTE: this was hell of a hunt; this windows and pytorch and jupyter combination is too tedious\n",
    "            #       make sure the function that we distribute don't call pytorch\n",
    "            chunksize = multiprocessing.cpu_count() * 1\n",
    "            processed = 0\n",
    "            for worker_data_chunk in [worker_data[i * chunksize:(i + 1) * chunksize] for i in range((len(worker_data) + chunksize - 1) // chunksize )]:\n",
    "                with Pool(multiprocessing.cpu_count()) as p:\n",
    "                    \n",
    "                    feature_set_list = p.starmap(get_features_map_for_stock, worker_data_chunk)\n",
    "                    \n",
    "                    for feature_map in feature_set_list:\n",
    "                        for rowid, features_dict in feature_map.items():\n",
    "                            for fkey,fval in features_dict.items():\n",
    "                                self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                            self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                        # udpate the indications that we've already fetched this stock and the lazy loader code won't fetch this again\n",
    "                        self.cache_stocks_done_set.add(int(rowid.split('-')[0]))\n",
    "                    \n",
    "                    processed += chunksize\n",
    "                    print(f\"Processed and loaded {processed} stocks features.\")\n",
    "    \n",
    "    def __cache_generate_features(self, main_stock_id, main_time_id):\n",
    "            \n",
    "            main_row_id = get_row_id(main_stock_id, main_time_id)\n",
    "            if main_stock_id not in self.cache_stocks_done_set:\n",
    "#                 trade_df = pd.read_parquet(os.path.join(self.data_directory, f\"trade_{self.mode}.parquet\", f\"stock_id={stock_id}\"))   \n",
    "                # we'll combine the featureset with the bigger feature set of all stocks\n",
    "                feature_map = get_features_map_for_stock(self.data_directory, self.mode, main_stock_id)\n",
    "                # NOTE: sometime we might now have parquet files in that case we'll have 3 entried in .csv while only 1 gets returned in feature map\n",
    "                # we need to cover for that disparity\n",
    "                for time_id in self.stock_possible_timeids_list[main_stock_id]:\n",
    "                    expected_row_id = get_row_id(main_stock_id, time_id)\n",
    "                    if expected_row_id not in feature_map:\n",
    "                        feature_map[expected_row_id] = {}\n",
    "                for rowid, features_dict in feature_map.items():\n",
    "                    for fkey,fval in features_dict.items():\n",
    "                        self.cache_rowid_feature_map[rowid][fkey] = fval\n",
    "                    self.cache_rowid_feature_map[rowid]  = OptiverRealizedVolatilityDataset.transform_to_01_realized_volatility_linear_data(self.cache_rowid_feature_map[rowid])\n",
    "                self.cache_stocks_done_set.add(main_stock_id)\n",
    "#             print(self.cache_rowid_feature_map[main_row_id])\n",
    "#             print(torch.tensor([self.cache_rowid_feature_map[main_row_id].get('book_realized_volatility',0)]))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map[main_row_id].get('log_return1_2s', [0]*(int(600/2)))))\n",
    "#             print(torch.tensor(self.cache_rowid_feature_map.get('book_directional_volume1_2s', [0]*(int(600/2)))))\n",
    "            return self.cache_rowid_feature_map[main_row_id]\n",
    "        \n",
    "    @staticmethod\n",
    "    def transform_to_01_realized_volatility_linear_data(features_dict):\n",
    "        return (\n",
    "                {\n",
    "                    'row_id':features_dict['row_id'],\n",
    "                    'stock_id':torch.tensor(features_dict['stock_id'], dtype=torch.float32),\n",
    "                    'seconds_in_bucket_xs': torch.tensor(np.nan_to_num(features_dict.get('seconds_in_bucket_xs',  [(idx*data_interval_seconds)+data_interval_seconds for idx in range(0,int(data_intervals_count))])), dtype=torch.float32),\n",
    "                    'book_realized_volatility':torch.tensor([features_dict.get('book_realized_volatility',0)], dtype=torch.float32),\n",
    "                    # TRADE FEATURES\n",
    "                    'trade_logrett_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_logrett_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_logrett_realized_volatility_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_logrett_realized_volatility_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_logrett_std_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_logrett_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_logrett_mean_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_logrett_mean_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_size_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_size_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_size_std_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_size_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_order_count_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_order_count_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_order_count_std_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_order_count_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_trade_money_turnover_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_trade_money_turnover_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'trade_trade_money_turnover_std_xs': torch.tensor(np.nan_to_num(features_dict.get('trade_trade_money_turnover_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    \n",
    "                    \n",
    "                    'book_logret1_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret1_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret1_realized_volatility_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret1_realized_volatility_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret1_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret1_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret1_mean_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret1_mean_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret2_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret2_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret2_realized_volatility_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret2_realized_volatility_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret2_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret2_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_logret2_mean_xs': torch.tensor(np.nan_to_num(features_dict.get('book_logret2_mean_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_price_spread1_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_price_spread1_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_price_spread1_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_price_spread1_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_bid_spread_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_bid_spread_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_bid_spread_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_bid_spread_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_ask_spread_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_ask_spread_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_ask_spread_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_ask_spread_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_total_volume_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_total_volume_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_total_volume_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_total_volume_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_volume_imbalance_sum_xs': torch.tensor(np.nan_to_num(features_dict.get('book_volume_imbalance_sum_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "                    'book_volume_imbalance_std_xs': torch.tensor(np.nan_to_num(features_dict.get('book_volume_imbalance_std_xs', [0]*(int(600/data_interval_seconds)))), dtype=torch.float32),\n",
    "#                   \n",
    "                },\n",
    "                {'target_realized_volatility':torch.tensor([features_dict['target_realized_volatility']])}\n",
    "#                 [features_dict['target']]\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.main_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: handle for num_workers more than 0\n",
    "        #      using https://pytorch.org/docs/stable/data.html\n",
    "        #      using torch.util.data.get_worker_info()\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        stock_id = self.main_df.at[idx, 'stock_id']\n",
    "        time_id = self.main_df.at[idx, 'time_id']\n",
    "        x,y = self.__cache_generate_features(stock_id,time_id)\n",
    "#         x, y = self.__transform_to_01_realized_volatility_linear_data(features_dict)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efcee691-c9ce-481f-a4e8-dbf97b66b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT: OptiverRealizedVolatilityDataset\n",
      "Processed and loaded 16 stocks features.\n",
      "Processed and loaded 32 stocks features.\n",
      "Processed and loaded 48 stocks features.\n",
      "Processed and loaded 64 stocks features.\n",
      "Processed and loaded 80 stocks features.\n",
      "Processed and loaded 96 stocks features.\n",
      "Processed and loaded 112 stocks features.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    dataset = OptiverRealizedVolatilityDataset(DATA_DIRECTORY, mode=\"train\", lazy_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64d085c-aaed-4a28-9d44-93eb8e2d4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id\n",
      "2-19309\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_id\n",
      "tensor(2.)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds_in_bucket_xs\n",
      "tensor([ 24.,  48.,  72.,  96., 120., 144., 168., 192., 216., 240., 264., 288.,\n",
      "        312., 336., 360., 384., 408., 432., 456., 480., 504., 528., 552., 576.,\n",
      "        600.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_realized_volatility\n",
      "tensor([0.0040])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_logrett_sum_xs\n",
      "tensor([-2.8478e-03, -7.2492e-05, -2.9008e-04, -2.1763e-04,  2.1763e-04,\n",
      "         2.1758e-04, -5.0775e-04,  1.4512e-04,  1.4504e-04,  5.8008e-04,\n",
      "        -7.2512e-04, -4.3537e-04,  5.0790e-04,  5.8012e-04,  7.9707e-04,\n",
      "        -1.4485e-04,  3.6221e-04, -2.8978e-04,  1.4496e-04,  6.8760e-04,\n",
      "         3.6421e-05, -1.4474e-04, -1.4488e-04,  2.1725e-04,  2.1708e-04])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_logrett_realized_volatility_xs\n",
      "tensor([0.0030, 0.0004, 0.0002, 0.0003, 0.0002, 0.0003, 0.0004, 0.0002, 0.0001,\n",
      "        0.0003, 0.0003, 0.0004, 0.0007, 0.0006, 0.0006, 0.0002, 0.0003, 0.0003,\n",
      "        0.0004, 0.0004, 0.0007, 0.0002, 0.0001, 0.0002, 0.0003])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_logrett_std_xs\n",
      "tensor([1.5267e-03, 1.4602e-04, 1.0259e-04, 1.6908e-04, 9.7317e-05, 1.2562e-04,\n",
      "        1.6449e-04, 9.7425e-05, 8.3740e-05, 1.1025e-04, 3.3561e-05, 1.4510e-04,\n",
      "        1.9940e-04, 1.9765e-04, 1.6722e-04, 9.3560e-05, 1.3753e-04, 0.0000e+00,\n",
      "        1.4313e-04, 1.1091e-04, 3.4917e-04, 9.7089e-05, 1.0244e-04, 1.0981e-04,\n",
      "        1.9147e-04])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_logrett_mean_xs\n",
      "tensor([-7.1195e-04, -7.2492e-06, -1.4504e-04, -5.4408e-05,  4.3526e-05,\n",
      "         3.6264e-05, -8.4625e-05,  3.6281e-05,  4.8348e-05,  9.6680e-05,\n",
      "        -9.0640e-05, -7.2562e-05,  4.2325e-05,  7.2515e-05,  7.9707e-05,\n",
      "        -3.6213e-05,  7.2443e-05, -2.8978e-04,  2.0709e-05,  1.7190e-04,\n",
      "         7.2842e-06, -2.8948e-05, -7.2439e-05,  4.3450e-05,  7.2361e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_size_sum_xs\n",
      "tensor([ 402.,  640.,  201.,  451.,  800.,  601., 1087.,  431.,  409.,  799.,\n",
      "         966.,  603., 4179.,  612., 1782.,  500.,  446.,  100.,  665.,  735.,\n",
      "         835.,  731.,  103.,  635.,  700.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_size_std_xs\n",
      "tensor([ 80.8352,  47.8447,   0.7071, 123.8988,  89.4427,  62.9299, 125.6048,\n",
      "         64.7167, 110.2739,  94.0243,  71.4898, 108.9986, 401.8288,  71.3462,\n",
      "        123.0400,  50.0000,  54.6599,   0.0000, 100.7240,  58.0251, 123.9435,\n",
      "         86.4130,  68.5894,  71.7287, 152.7525])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_order_count_sum_xs\n",
      "tensor([ 6., 17.,  4.,  9., 10.,  9., 17.,  8.,  3., 19., 12.,  9., 48., 10.,\n",
      "        22.,  6., 13.,  1., 12., 10.,  8., 13.,  2.,  9.,  7.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_order_count_std_xs\n",
      "tensor([0.5774, 0.6749, 0.0000, 1.5000, 1.0000, 1.2247, 2.1370, 0.8165, 0.0000,\n",
      "        2.9269, 0.7559, 1.2247, 3.8612, 0.4629, 1.6193, 0.5774, 2.0736, 0.0000,\n",
      "        0.9512, 1.2910, 0.8944, 1.1402, 0.0000, 0.4472, 1.1547])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_trade_money_turnover_sum_xs\n",
      "tensor([ 401.8982,  639.7877,  200.9198,  450.7464,  799.4926,  600.8111,\n",
      "        1086.3618,  430.6898,  408.7345,  798.7413,  965.6999,  602.4466,\n",
      "        4175.3291,  611.8525, 1783.0212,  500.3625,  446.2887,  100.0725,\n",
      "         665.6512,  735.9205,  836.2103,  732.1522,  103.1348,  635.8870,\n",
      "         701.0295])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_trade_money_turnover_std_xs\n",
      "tensor([ 80.8116,  47.8285,   0.6914, 123.8310,  89.3738,  62.9140, 125.5577,\n",
      "         64.6721, 110.2012,  93.9651,  71.4772, 108.8799, 401.4522,  71.3398,\n",
      "        123.1043,  50.0266,  54.6953,   0.0000, 100.8267,  58.0941, 124.1399,\n",
      "         86.5529,  68.6786,  71.8251, 152.9440])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret1_sum_xs\n",
      "tensor([-3.3610e-03,  3.6049e-05, -2.8112e-04, -1.0570e-04,  4.2309e-04,\n",
      "        -4.0475e-05, -4.2095e-04,  4.8293e-05,  1.9556e-04,  5.4382e-04,\n",
      "        -7.7913e-04, -3.7914e-04,  4.3311e-04,  8.2661e-04,  7.3188e-04,\n",
      "        -2.1738e-04, -1.2032e-05,  2.4456e-04, -2.3720e-05,  5.8055e-04,\n",
      "         2.0761e-04, -3.8347e-04,  5.0376e-05,  1.8963e-04,  3.6530e-04])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret1_realized_volatility_xs\n",
      "tensor([0.0034, 0.0004, 0.0003, 0.0004, 0.0005, 0.0004, 0.0004, 0.0003, 0.0003,\n",
      "        0.0003, 0.0005, 0.0003, 0.0007, 0.0007, 0.0007, 0.0006, 0.0004, 0.0003,\n",
      "        0.0002, 0.0005, 0.0005, 0.0004, 0.0003, 0.0003, 0.0003])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret1_std_xs\n",
      "tensor([6.9050e-04, 8.9752e-05, 6.0223e-05, 7.8322e-05, 1.0720e-04, 7.6754e-05,\n",
      "        8.6127e-05, 6.7875e-05, 6.1794e-05, 5.8348e-05, 9.4337e-05, 6.9314e-05,\n",
      "        1.4752e-04, 1.4407e-04, 1.3349e-04, 1.2940e-04, 8.8889e-05, 5.6931e-05,\n",
      "        4.6380e-05, 9.8070e-05, 1.0945e-04, 9.2058e-05, 6.0414e-05, 6.3096e-05,\n",
      "        7.0501e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret1_mean_xs\n",
      "tensor([-1.4004e-04,  1.5673e-06, -1.1713e-05, -4.4043e-06,  1.7629e-05,\n",
      "        -1.6864e-06, -1.7540e-05,  2.0122e-06,  8.1481e-06,  2.2659e-05,\n",
      "        -3.2464e-05, -1.5797e-05,  1.8046e-05,  3.4442e-05,  3.0495e-05,\n",
      "        -9.0577e-06, -5.0133e-07,  1.0190e-05, -1.0313e-06,  2.4190e-05,\n",
      "         8.6504e-06, -1.5978e-05,  2.0990e-06,  7.9013e-06,  1.5221e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret2_sum_xs\n",
      "tensor([-2.9816e-03, -3.4497e-05, -1.4682e-04, -2.1759e-04,  4.5938e-04,\n",
      "        -4.8373e-05, -3.4264e-04, -2.8339e-05,  1.3435e-04,  6.0524e-04,\n",
      "        -7.8727e-04, -2.5839e-04,  2.9022e-04,  9.0042e-04,  7.1846e-04,\n",
      "        -2.6563e-04, -3.6187e-05,  3.2623e-04, -3.6507e-05,  5.4307e-04,\n",
      "         2.7143e-04, -4.7049e-04,  5.4275e-05,  2.2756e-04,  4.9563e-04])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret2_realized_volatility_xs\n",
      "tensor([0.0030, 0.0006, 0.0006, 0.0006, 0.0008, 0.0005, 0.0004, 0.0006, 0.0004,\n",
      "        0.0003, 0.0006, 0.0003, 0.0007, 0.0008, 0.0008, 0.0007, 0.0007, 0.0005,\n",
      "        0.0003, 0.0005, 0.0007, 0.0004, 0.0004, 0.0005, 0.0006])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret2_std_xs\n",
      "tensor([6.1293e-04, 1.3738e-04, 1.3071e-04, 1.2823e-04, 1.5895e-04, 1.1111e-04,\n",
      "        8.9660e-05, 1.1798e-04, 7.5505e-05, 5.4429e-05, 1.1605e-04, 6.8090e-05,\n",
      "        1.5024e-04, 1.5730e-04, 1.7031e-04, 1.5552e-04, 1.5530e-04, 1.0257e-04,\n",
      "        6.4694e-05, 1.0745e-04, 1.3994e-04, 9.0000e-05, 8.0365e-05, 1.0386e-04,\n",
      "        1.2932e-04])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_logret2_mean_xs\n",
      "tensor([-1.2423e-04, -1.4998e-06, -6.1176e-06, -9.0664e-06,  1.9141e-05,\n",
      "        -2.0156e-06, -1.4277e-05, -1.1808e-06,  5.5979e-06,  2.5218e-05,\n",
      "        -3.2803e-05, -1.0766e-05,  1.2093e-05,  3.7518e-05,  2.9936e-05,\n",
      "        -1.1068e-05, -1.5078e-06,  1.3593e-05, -1.5873e-06,  2.2628e-05,\n",
      "         1.1309e-05, -1.9604e-05,  2.2615e-06,  9.4816e-06,  2.0651e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_price_spread1_sum_xs\n",
      "tensor([0.0036, 0.0041, 0.0042, 0.0050, 0.0043, 0.0036, 0.0034, 0.0046, 0.0051,\n",
      "        0.0032, 0.0045, 0.0041, 0.0044, 0.0053, 0.0043, 0.0054, 0.0059, 0.0054,\n",
      "        0.0043, 0.0046, 0.0043, 0.0046, 0.0050, 0.0040, 0.0051])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_price_spread1_std_xs\n",
      "tensor([6.2267e-05, 4.8025e-05, 6.3865e-05, 5.7821e-05, 8.2778e-05, 6.2274e-05,\n",
      "        3.9901e-05, 7.6127e-05, 6.0186e-05, 6.2949e-05, 5.6241e-05, 4.0982e-05,\n",
      "        6.4087e-05, 5.4439e-05, 6.7466e-05, 7.6772e-05, 7.3428e-05, 5.1935e-05,\n",
      "        6.1118e-05, 5.0821e-05, 5.2206e-05, 6.2900e-05, 5.3629e-05, 5.8391e-05,\n",
      "        4.5161e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_bid_spread_sum_xs\n",
      "tensor([0.0022, 0.0017, 0.0020, 0.0023, 0.0022, 0.0020, 0.0018, 0.0020, 0.0019,\n",
      "        0.0020, 0.0020, 0.0021, 0.0018, 0.0020, 0.0021, 0.0020, 0.0018, 0.0019,\n",
      "        0.0018, 0.0017, 0.0020, 0.0019, 0.0018, 0.0020, 0.0020])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_bid_spread_std_xs\n",
      "tensor([3.2092e-05, 2.9427e-08, 3.4927e-05, 4.0969e-05, 3.3685e-05, 3.2522e-05,\n",
      "        1.4809e-05, 2.7630e-05, 2.0486e-05, 2.4524e-05, 2.4509e-05, 3.6939e-05,\n",
      "        1.4822e-05, 2.7622e-05, 3.0052e-05, 2.7574e-05, 1.4785e-05, 2.0451e-05,\n",
      "        2.0886e-05, 4.2340e-08, 2.4450e-05, 2.0467e-05, 1.4767e-05, 2.7566e-05,\n",
      "        2.4424e-05])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_ask_spread_sum_xs\n",
      "tensor([0.0026, 0.0018, 0.0019, 0.0017, 0.0020, 0.0022, 0.0020, 0.0019, 0.0020,\n",
      "        0.0017, 0.0017, 0.0020, 0.0022, 0.0017, 0.0017, 0.0019, 0.0021, 0.0020,\n",
      "        0.0017, 0.0019, 0.0020, 0.0017, 0.0022, 0.0019, 0.0017])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_ask_spread_std_xs\n",
      "tensor([3.7033e-05, 2.0891e-05, 2.0473e-05, 2.1647e-08, 2.4500e-05, 3.8536e-05,\n",
      "        2.7626e-05, 2.0474e-05, 2.7614e-05, 2.8774e-08, 2.5772e-08, 2.4525e-05,\n",
      "        3.9905e-05, 2.9635e-08, 5.4218e-08, 2.0466e-05, 3.0043e-05, 2.4444e-05,\n",
      "        3.5044e-09, 2.0443e-05, 2.7557e-05, 7.6900e-09, 3.8472e-05, 2.0428e-05,\n",
      "        2.3498e-08])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_total_volume_sum_xs\n",
      "tensor([16914., 17783., 19823., 18518., 16031., 16095., 17973., 18855., 21960.,\n",
      "        19286., 19325., 17377., 18828., 20957., 19712., 20508., 20030., 19486.,\n",
      "        19523., 21320., 19526., 19589., 22362., 24566., 23515.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_total_volume_std_xs\n",
      "tensor([194.8385, 148.1825, 142.5691, 132.0523, 165.3262, 162.2735, 114.7979,\n",
      "        157.7265, 225.4831, 172.8508, 182.9402, 261.1387, 182.4962, 164.9848,\n",
      "        156.0359, 220.3927, 218.4879, 156.3266, 124.7086, 192.4175, 232.8373,\n",
      "        222.2296, 243.2273, 242.1526, 161.3279])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_volume_imbalance_sum_xs\n",
      "tensor([2888., 2533., 3883., 2848., 3883., 4505., 2879., 3773., 4266., 4488.,\n",
      "        3419., 5057., 4040., 4549., 4124., 3292., 2892., 4408., 5709., 2734.,\n",
      "        6898., 4183., 3332., 5382., 5493.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_volume_imbalance_std_xs\n",
      "tensor([ 97.0310,  76.6754, 124.1023,  64.9037, 144.3510, 124.3653,  99.1242,\n",
      "        122.1692, 152.1113, 127.6939, 152.6192, 247.7113,  94.5891, 149.0349,\n",
      "        117.4118, 158.3764, 132.8183, 166.2365, 176.3091, 143.5242, 179.8468,\n",
      "        104.2407, 109.0292, 194.3447, 193.9974])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# for x in range(0,9):\n",
    "#     print(dataset[x])\n",
    "\n",
    "# dataset[10000] #[0]['bidp1_1s']\n",
    "for key,val in dataset[10000][0].items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaeb87d1-d4be-4351-b483-22ac0c168909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_idx in range(len(dataset)):\n",
    "    dataset[data_idx][0]['book_realized_volatility'] = dataset[data_idx][0]['book_realized_volatility'].type(torch.float32).to('cpu')\n",
    "#     print(dataset[data_idx][0]['book_realized_volatility'])\n",
    "#     input()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ec3227-ffc6-4099-b51c-04a3bd2df633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seconds_in_bucket_xs': {'mean': 312.0, 'std': 173.06646728515625},\n",
       " 'book_realized_volatility': {'mean': 0.005850940477102995,\n",
       "  'std': 0.004778958857059479},\n",
       " 'trade_logrett_sum_xs': {'mean': -1.1226925167306945e-08,\n",
       "  'std': 0.0012633935548365116},\n",
       " 'trade_logrett_realized_volatility_xs': {'mean': 0.0005547573091462255,\n",
       "  'std': 0.0011005407432094216},\n",
       " 'trade_logrett_std_xs': {'mean': 0.0002125719329342246,\n",
       "  'std': 0.000520365487318486},\n",
       " 'trade_logrett_mean_xs': {'mean': 2.2360411549016135e-06,\n",
       "  'std': 0.0006506441859528422},\n",
       " 'trade_size_sum_xs': {'mean': 1274.408447265625, 'std': 3957.27392578125},\n",
       " 'trade_size_std_xs': {'mean': 201.2566680908203, 'std': 809.9418334960938},\n",
       " 'trade_order_count_sum_xs': {'mean': 14.93747329711914,\n",
       "  'std': 31.093172073364258},\n",
       " 'trade_order_count_std_xs': {'mean': 1.9885706901550293,\n",
       "  'std': 3.986957311630249},\n",
       " 'trade_trade_money_turnover_sum_xs': {'mean': 1274.364990234375,\n",
       "  'std': 3957.194580078125},\n",
       " 'trade_trade_money_turnover_std_xs': {'mean': 201.25364685058594,\n",
       "  'std': 809.8814697265625},\n",
       " 'book_logret1_sum_xs': {'mean': -9.877491713439213e-09,\n",
       "  'std': 0.0013098383788019419},\n",
       " 'book_logret1_realized_volatility_xs': {'mean': 0.0008679572492837906,\n",
       "  'std': 0.001236740150488913},\n",
       " 'book_logret1_std_xs': {'mean': 0.00023386265092995018,\n",
       "  'std': 0.0003532674163579941},\n",
       " 'book_logret1_mean_xs': {'mean': 9.141682255631167e-08,\n",
       "  'std': 0.00013150273298379034},\n",
       " 'book_logret2_sum_xs': {'mean': -9.768747588623228e-09,\n",
       "  'std': 0.0013809562660753727},\n",
       " 'book_logret2_realized_volatility_xs': {'mean': 0.0011465881252661347,\n",
       "  'std': 0.00145239126868546},\n",
       " 'book_logret2_std_xs': {'mean': 0.00031500737532041967,\n",
       "  'std': 0.00042466234299354255},\n",
       " 'book_logret2_mean_xs': {'mean': 9.769648556812172e-08,\n",
       "  'std': 0.0001457101752748713},\n",
       " 'book_price_spread1_sum_xs': {'mean': 0.008905505761504173,\n",
       "  'std': 0.00932735949754715},\n",
       " 'book_price_spread1_std_xs': {'mean': 0.00013038843462709337,\n",
       "  'std': 0.00018358806846663356},\n",
       " 'book_bid_spread_sum_xs': {'mean': 0.0030224656220525503,\n",
       "  'std': 0.0032615496311336756},\n",
       " 'book_bid_spread_std_xs': {'mean': 7.655585795873776e-05,\n",
       "  'std': 0.0001423279318260029},\n",
       " 'book_ask_spread_sum_xs': {'mean': 0.0030542113818228245,\n",
       "  'std': 0.003295465372502804},\n",
       " 'book_ask_spread_std_xs': {'mean': 7.811487739672884e-05,\n",
       "  'std': 0.00014516572991851717},\n",
       " 'book_total_volume_sum_xs': {'mean': 65197.703125, 'std': 372891.21875},\n",
       " 'book_total_volume_std_xs': {'mean': 394.8986511230469,\n",
       "  'std': 1568.0399169921875},\n",
       " 'book_volume_imbalance_sum_xs': {'mean': 15863.017578125,\n",
       "  'std': 113432.6953125},\n",
       " 'book_volume_imbalance_std_xs': {'mean': 385.7958984375,\n",
       "  'std': 1644.90966796875}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_dict = {key:[] for key in dataset[0][0].keys()}\n",
    "for data_idx in range(len(dataset)):\n",
    "    for feature_key,feature_val in dataset[data_idx][0].items():\n",
    "        all_feature_dict[feature_key].append(feature_val)\n",
    "        \n",
    "standard_scaling_feature_map = {}\n",
    "for key,val in all_feature_dict.items():\n",
    "    if type(val[0]) is not list and type(val[0]) is not str and val[0].type() is not str:\n",
    "        if len(val[0].size())>0:\n",
    "            mean = torch.mean(torch.cat(val).reshape(-1)).item()\n",
    "            std = torch.std(torch.cat(val).reshape(-1)).item()\n",
    "            standard_scaling_feature_map[key] = {'mean':mean,'std':std}\n",
    "#             print(key, 'mean', , 'std', )\n",
    "standard_scaling_feature_map       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6352c9e6-a077-479b-abe6-b7e128e98a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seconds_in_bucket_xs': {'mean': 312.0, 'std': 173.06646728515625},\n",
       " 'book_realized_volatility': {'mean': 0.005850940477102995,\n",
       "  'std': 0.004778958857059479},\n",
       " 'trade_logrett_sum_xs': {'mean': -1.1226925167306945e-08,\n",
       "  'std': 0.0012633935548365116},\n",
       " 'trade_logrett_realized_volatility_xs': {'mean': 0.0005547573091462255,\n",
       "  'std': 0.0011005407432094216},\n",
       " 'trade_logrett_std_xs': {'mean': 0.0002125719329342246,\n",
       "  'std': 0.000520365487318486},\n",
       " 'trade_logrett_mean_xs': {'mean': 2.2360411549016135e-06,\n",
       "  'std': 0.0006506441859528422},\n",
       " 'trade_size_sum_xs': {'mean': 1274.408447265625, 'std': 3957.27392578125},\n",
       " 'trade_size_std_xs': {'mean': 201.2566680908203, 'std': 809.9418334960938},\n",
       " 'trade_order_count_sum_xs': {'mean': 14.93747329711914,\n",
       "  'std': 31.093172073364258},\n",
       " 'trade_order_count_std_xs': {'mean': 1.9885706901550293,\n",
       "  'std': 3.986957311630249},\n",
       " 'trade_trade_money_turnover_sum_xs': {'mean': 1274.364990234375,\n",
       "  'std': 3957.194580078125},\n",
       " 'trade_trade_money_turnover_std_xs': {'mean': 201.25364685058594,\n",
       "  'std': 809.8814697265625},\n",
       " 'book_logret1_sum_xs': {'mean': -9.877491713439213e-09,\n",
       "  'std': 0.0013098383788019419},\n",
       " 'book_logret1_realized_volatility_xs': {'mean': 0.0008679572492837906,\n",
       "  'std': 0.001236740150488913},\n",
       " 'book_logret1_std_xs': {'mean': 0.00023386265092995018,\n",
       "  'std': 0.0003532674163579941},\n",
       " 'book_logret1_mean_xs': {'mean': 9.141682255631167e-08,\n",
       "  'std': 0.00013150273298379034},\n",
       " 'book_logret2_sum_xs': {'mean': -9.768747588623228e-09,\n",
       "  'std': 0.0013809562660753727},\n",
       " 'book_logret2_realized_volatility_xs': {'mean': 0.0011465881252661347,\n",
       "  'std': 0.00145239126868546},\n",
       " 'book_logret2_std_xs': {'mean': 0.00031500737532041967,\n",
       "  'std': 0.00042466234299354255},\n",
       " 'book_logret2_mean_xs': {'mean': 9.769648556812172e-08,\n",
       "  'std': 0.0001457101752748713},\n",
       " 'book_price_spread1_sum_xs': {'mean': 0.008905505761504173,\n",
       "  'std': 0.00932735949754715},\n",
       " 'book_price_spread1_std_xs': {'mean': 0.00013038843462709337,\n",
       "  'std': 0.00018358806846663356},\n",
       " 'book_bid_spread_sum_xs': {'mean': 0.0030224656220525503,\n",
       "  'std': 0.0032615496311336756},\n",
       " 'book_bid_spread_std_xs': {'mean': 7.655585795873776e-05,\n",
       "  'std': 0.0001423279318260029},\n",
       " 'book_ask_spread_sum_xs': {'mean': 0.0030542113818228245,\n",
       "  'std': 0.003295465372502804},\n",
       " 'book_ask_spread_std_xs': {'mean': 7.811487739672884e-05,\n",
       "  'std': 0.00014516572991851717},\n",
       " 'book_total_volume_sum_xs': {'mean': 65197.703125, 'std': 372891.21875},\n",
       " 'book_total_volume_std_xs': {'mean': 394.8986511230469,\n",
       "  'std': 1568.0399169921875},\n",
       " 'book_volume_imbalance_sum_xs': {'mean': 15863.017578125,\n",
       "  'std': 113432.6953125},\n",
       " 'book_volume_imbalance_std_xs': {'mean': 385.7958984375,\n",
       "  'std': 1644.90966796875}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaling_feature_map ={'seconds_in_bucket_xs': {'mean': 312.0, 'std': 173.06646728515625},\n",
    " 'book_realized_volatility': {'mean': 0.005850940477102995,\n",
    "  'std': 0.004778958857059479},\n",
    " 'trade_logrett_sum_xs': {'mean': -1.1226925167306945e-08,\n",
    "  'std': 0.0012633935548365116},\n",
    " 'trade_logrett_realized_volatility_xs': {'mean': 0.0005547573091462255,\n",
    "  'std': 0.0011005407432094216},\n",
    " 'trade_logrett_std_xs': {'mean': 0.0002125719329342246,\n",
    "  'std': 0.000520365487318486},\n",
    " 'trade_logrett_mean_xs': {'mean': 2.2360411549016135e-06,\n",
    "  'std': 0.0006506441859528422},\n",
    " 'trade_size_sum_xs': {'mean': 1274.408447265625, 'std': 3957.27392578125},\n",
    " 'trade_size_std_xs': {'mean': 201.2566680908203, 'std': 809.9418334960938},\n",
    " 'trade_order_count_sum_xs': {'mean': 14.93747329711914,\n",
    "  'std': 31.093172073364258},\n",
    " 'trade_order_count_std_xs': {'mean': 1.9885706901550293,\n",
    "  'std': 3.986957311630249},\n",
    " 'trade_trade_money_turnover_sum_xs': {'mean': 1274.364990234375,\n",
    "  'std': 3957.194580078125},\n",
    " 'trade_trade_money_turnover_std_xs': {'mean': 201.25364685058594,\n",
    "  'std': 809.8814697265625},\n",
    " 'book_logret1_sum_xs': {'mean': -9.877491713439213e-09,\n",
    "  'std': 0.0013098383788019419},\n",
    " 'book_logret1_realized_volatility_xs': {'mean': 0.0008679572492837906,\n",
    "  'std': 0.001236740150488913},\n",
    " 'book_logret1_std_xs': {'mean': 0.00023386265092995018,\n",
    "  'std': 0.0003532674163579941},\n",
    " 'book_logret1_mean_xs': {'mean': 9.141682255631167e-08,\n",
    "  'std': 0.00013150273298379034},\n",
    " 'book_logret2_sum_xs': {'mean': -9.768747588623228e-09,\n",
    "  'std': 0.0013809562660753727},\n",
    " 'book_logret2_realized_volatility_xs': {'mean': 0.0011465881252661347,\n",
    "  'std': 0.00145239126868546},\n",
    " 'book_logret2_std_xs': {'mean': 0.00031500737532041967,\n",
    "  'std': 0.00042466234299354255},\n",
    " 'book_logret2_mean_xs': {'mean': 9.769648556812172e-08,\n",
    "  'std': 0.0001457101752748713},\n",
    " 'book_price_spread1_sum_xs': {'mean': 0.008905505761504173,\n",
    "  'std': 0.00932735949754715},\n",
    " 'book_price_spread1_std_xs': {'mean': 0.00013038843462709337,\n",
    "  'std': 0.00018358806846663356},\n",
    " 'book_bid_spread_sum_xs': {'mean': 0.0030224656220525503,\n",
    "  'std': 0.0032615496311336756},\n",
    " 'book_bid_spread_std_xs': {'mean': 7.655585795873776e-05,\n",
    "  'std': 0.0001423279318260029},\n",
    " 'book_ask_spread_sum_xs': {'mean': 0.0030542113818228245,\n",
    "  'std': 0.003295465372502804},\n",
    " 'book_ask_spread_std_xs': {'mean': 7.811487739672884e-05,\n",
    "  'std': 0.00014516572991851717},\n",
    " 'book_total_volume_sum_xs': {'mean': 65197.703125, 'std': 372891.21875},\n",
    " 'book_total_volume_std_xs': {'mean': 394.8986511230469,\n",
    "  'std': 1568.0399169921875},\n",
    " 'book_volume_imbalance_sum_xs': {'mean': 15863.017578125,\n",
    "  'std': 113432.6953125},\n",
    " 'book_volume_imbalance_std_xs': {'mean': 385.7958984375,\n",
    "  'std': 1644.90966796875}}\n",
    "standard_scaling_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d58ff-26aa-4b02-b2ac-991ccb366c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2124b8d-39fb-4801-a3c1-378ee390a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_train = DataLoader(dataset, batch_size=10000,shuffle=True, num_workers=0, pin_memory=True)\n",
    "# sizes = set()\n",
    "# for train_batch_idx, (feature_dict, feature_y) in enumerate(dataloader_train):\n",
    "#     print(f\"{np.min(feature_dict['trade_price_local_standardized_xs'].tolist())}\")\n",
    "#     input()\n",
    "        \n",
    "        \n",
    "#         print(val)\n",
    "#         input()\n",
    "#     print(x)\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca3693b7-4338-49c6-8a4f-9a8205d4aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a72c9b-fab8-4536-b125-abc46cc800b6",
   "metadata": {},
   "source": [
    "### Learnings about model CNN input\n",
    "- it's better to use multiple channel for logreturn1 and logreturn2 than stacking it and using as one channel\n",
    "- 2 channels input for CNN is better than stacking it(dim 2, which is logret1_t1, logret2_t1, logret1_t2, logret2_t2...) and using it as one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4b98ff-b328-465e-a04e-c25eef8ea358",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model = None\n",
    "\n",
    "\n",
    "def loss_fn_mse(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)))\n",
    "\n",
    "def loss_fn_mspe(y, pred):\n",
    "    return torch.mean(torch.square((y-pred)/y))\n",
    "\n",
    "def loss_fn_orig(y, pred):\n",
    "    return torch.sqrt(torch.mean(torch.square((y-pred)/y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a6a979-c114-4525-953f-f5c368fe26d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_stocks = dataset.main_df['stock_id'].max()\n",
    "number_of_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7de51c7-de13-45ff-8513-5d890d691352",
   "metadata": {},
   "outputs": [],
   "source": [
    "realize_volatility_scale_factor = 1000\n",
    "def scale_optiver_feature(feature_name, feature_tensor):\n",
    "    standard_scaling_feature_map ={'seconds_in_bucket_xs': {'mean': 312.0, 'std': 173.06646728515625},\n",
    "             'book_realized_volatility': {'mean': 0.005850940477102995,\n",
    "              'std': 0.004778958857059479},\n",
    "             'trade_logrett_sum_xs': {'mean': -1.1226925167306945e-08,\n",
    "              'std': 0.0012633935548365116},\n",
    "             'trade_logrett_realized_volatility_xs': {'mean': 0.0005547573091462255,\n",
    "              'std': 0.0011005407432094216},\n",
    "             'trade_logrett_std_xs': {'mean': 0.0002125719329342246,\n",
    "              'std': 0.000520365487318486},\n",
    "             'trade_logrett_mean_xs': {'mean': 2.2360411549016135e-06,\n",
    "              'std': 0.0006506441859528422},\n",
    "             'trade_size_sum_xs': {'mean': 1274.408447265625, 'std': 3957.27392578125},\n",
    "             'trade_size_std_xs': {'mean': 201.2566680908203, 'std': 809.9418334960938},\n",
    "             'trade_order_count_sum_xs': {'mean': 14.93747329711914,\n",
    "              'std': 31.093172073364258},\n",
    "             'trade_order_count_std_xs': {'mean': 1.9885706901550293,\n",
    "              'std': 3.986957311630249},\n",
    "             'trade_trade_money_turnover_sum_xs': {'mean': 1274.364990234375,\n",
    "              'std': 3957.194580078125},\n",
    "             'trade_trade_money_turnover_std_xs': {'mean': 201.25364685058594,\n",
    "              'std': 809.8814697265625},\n",
    "             'book_logret1_sum_xs': {'mean': -9.877491713439213e-09,\n",
    "              'std': 0.0013098383788019419},\n",
    "             'book_logret1_realized_volatility_xs': {'mean': 0.0008679572492837906,\n",
    "              'std': 0.001236740150488913},\n",
    "             'book_logret1_std_xs': {'mean': 0.00023386265092995018,\n",
    "              'std': 0.0003532674163579941},\n",
    "             'book_logret1_mean_xs': {'mean': 9.141682255631167e-08,\n",
    "              'std': 0.00013150273298379034},\n",
    "             'book_logret2_sum_xs': {'mean': -9.768747588623228e-09,\n",
    "              'std': 0.0013809562660753727},\n",
    "             'book_logret2_realized_volatility_xs': {'mean': 0.0011465881252661347,\n",
    "              'std': 0.00145239126868546},\n",
    "             'book_logret2_std_xs': {'mean': 0.00031500737532041967,\n",
    "              'std': 0.00042466234299354255},\n",
    "             'book_logret2_mean_xs': {'mean': 9.769648556812172e-08,\n",
    "              'std': 0.0001457101752748713},\n",
    "             'book_price_spread1_sum_xs': {'mean': 0.008905505761504173,\n",
    "              'std': 0.00932735949754715},\n",
    "             'book_price_spread1_std_xs': {'mean': 0.00013038843462709337,\n",
    "              'std': 0.00018358806846663356},\n",
    "             'book_bid_spread_sum_xs': {'mean': 0.0030224656220525503,\n",
    "              'std': 0.0032615496311336756},\n",
    "             'book_bid_spread_std_xs': {'mean': 7.655585795873776e-05,\n",
    "              'std': 0.0001423279318260029},\n",
    "             'book_ask_spread_sum_xs': {'mean': 0.0030542113818228245,\n",
    "              'std': 0.003295465372502804},\n",
    "             'book_ask_spread_std_xs': {'mean': 7.811487739672884e-05,\n",
    "              'std': 0.00014516572991851717},\n",
    "             'book_total_volume_sum_xs': {'mean': 65197.703125, 'std': 372891.21875},\n",
    "             'book_total_volume_std_xs': {'mean': 394.8986511230469,\n",
    "              'std': 1568.0399169921875},\n",
    "             'book_volume_imbalance_sum_xs': {'mean': 15863.017578125,\n",
    "              'std': 113432.6953125},\n",
    "             'book_volume_imbalance_std_xs': {'mean': 385.7958984375,\n",
    "              'std': 1644.90966796875}}\n",
    "    \n",
    "#     if feature_name in ['book_realized_volatility_xs','trade_realized_volatility_xs']:\n",
    "#         # we expect feature_tensor to be log returns tensor\n",
    "#         feature_tensor = feature_tensor ** 2\n",
    "# #         print(feature_tensor)\n",
    "#         feature_tensor = torch.cumsum(feature_tensor,1)\n",
    "#         # scale it to make each step realize volatility extrapolatable to 10 min window\n",
    "# #         feature_tensor = feature_tensor * torch.tensor([data_intervals_count/idx for idx in range(1,data_intervals_count+1,1)])\n",
    "#         feature_tensor = torch.sqrt(feature_tensor) * realize_volatility_scale_factor\n",
    "        \n",
    "        \n",
    "    if feature_name in standard_scaling_feature_map:\n",
    "        return (feature_tensor - standard_scaling_feature_map[feature_name]['mean'])/standard_scaling_feature_map[feature_name]['std']\n",
    "    if feature_name in ['trade_price_local_standardized_xs','book_wap1_local_standardized_xs']:\n",
    "        #TODO: the kaggle version of pytorch dont have nan_to_num, do something here!\n",
    "        feature_tensor = torch.masked_fill(feature_tensor, torch.isinf(feature_tensor),0)\n",
    "#         feature_tensor = torch.nan_to_num(feature_tensor,nan=0, posinf=0, neginf=0)\n",
    "#     print(feature_tensor)\n",
    "#     print(torch.any(torch.isnan(feature_tensor)))\n",
    "#     input()\n",
    "    return feature_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5b110429-4ffd-4923-8f5e-392e119ee6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4069089047552552e-05, 0.0, 0.0, -5.153622623765841e-06, 0.0, 5.153622623765841e-06, -5.153622623765841e-06, 0.0, 5.153622623765841e-06, -5.153622623765841e-06, 0.00010633138299454004, 0.0, 0.0009790477342903614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.433621764590498e-05, 0.0006783748394809663, -0.0002597005513962358, -0.0005221677129156888, 0.0, 0.0, 0.000813585938885808, 0.0003656581975519657, -1.145963051385479e-05, -0.00018618373724166304, 0.0, 0.0, -0.0005129064666107297, 0.0, 0.0, 0.0, 0.0, 0.0011864528059959412, 2.314435050720931e-06, -2.314435050720931e-06, 1.4098625342739979e-06, 0.0, 0.0, 3.63462240784429e-05, -3.544165156199597e-05, 0.0, 2.5135821488220245e-05, -4.4884842509418377e-07, -2.7001407943316735e-05, 0.0, 0.0, 0.0, 0.0, 1.953613173100166e-05, -0.00029404371161945164, 0.00014178302080836147, 0.0, -0.00017039723752532154, 0.0, 0.00029905393603257835, 0.0, 8.536389941582456e-05, 0.0007332738023251295, 0.0, -0.00030460659763775766, 0.0, 0.0, 0.0, -0.00027336712810210884, 0.00033845967845991254, -0.0005317581235431135, -0.00013631452748086303, -0.0005515966331586242, 9.454708560951985e-06, -1.5355070672740112e-06, -3.3939306831598515e-07, 0.0, 1.8047078356175916e-06, -1.4668955373053905e-05, 0.0, 0.0, 0.0, 1.5064826584421098e-05, -3.9587095557180874e-07, 0.0004907596739940345, -0.0004907596739940345, 0.00047508638817816973, -0.00012432671792339534, -3.31878472934477e-05, 3.31878472934477e-05, 0.0001464514498366043, 0.0004999037482775748, -0.0002288101677550003, -0.0001512342569185421, -3.24178472510539e-05, 0.0, -2.0951132682967e-05, -2.8281148843234405e-05, 2.2611191070609493e-06, 0.0004499052884057164, -0.0004732590459752828, 0.0001663063740124926, -0.0004274111124686897, 0.0003695436753332615, -0.00014174895477481186, 0.0, 0.0, 0.0002200630697188899, 6.781615866202628e-06, 0.00014473772898782045, 0.00027860712725669146, 5.4744350563851185e-06, -0.0002567959309089929, -3.0030403195269173e-06, 2.8173286409582943e-05, 2.2508695565193193e-06, 1.836708361224737e-05, 0.0, 0.0, 0.0, 0.0, 0.0, -2.6866923690249678e-06, 0.0, -2.6571754005999537e-06, -0.0004578891093842685, 0.00017568672774359584, 0.0, 0.0, -5.089767114441202e-07, -0.0007047392427921295, 0.0, 0.00046173387090675533, 0.0, 0.0, 0.0, 0.0, 0.0001475988101447001, 0.0, -0.0004133258480578661, 0.0, -0.00014711436233483255, 0.00011219051521038637, 6.692564369359388e-08, 5.064027391199488e-06, 1.4932238627807237e-05, 3.0565149700123584e-07, -4.976063337380765e-06, 0.00036952432128600776, 7.126942364266142e-05, -0.00031192050664685667, 0.00016929436242207885, -0.00010449384717503563, 0.0003286258433945477, 0.00017643070896156132, 0.0, -0.00022424038616009057, 0.0, 0.0, -0.000281190819805488, 0.0, 0.0, -8.87096939550247e-06, 0.00030460505513474345, 0.0, 0.0, 0.0, 0.0, -0.0006167168612591922, 0.0, 0.0003122488851659, 0.0, 4.567876658256864e-06, -4.567876658256864e-06, 4.567876658256864e-06, 0.0, -4.567876658256864e-06, 0.0, 0.0, 4.567876658256864e-06, -4.567876658256864e-06, 0.00025018263841047883, 0.0, 0.0, 0.0, 0.00015262018132489175, 0.0, -0.00012679051724262536, 0.00038074940675869584, 3.4987973407396566e-08, 0.0, 0.0, 3.5469663544063224e-06, 0.0, 0.0, 2.5741017452673987e-05, 0.0, -0.0009202152723446488, 0.0007422423805110157, -0.00028558558551594615, -7.724105671513826e-05, -0.00023184805468190461, 0.0, 0.0006653895252384245, 0.0, 0.0, -9.61347632255638e-06, 0.0, 0.0, 0.0, -0.00013951840810477734, -0.00034098760806955397, 2.512548213928767e-08, 0.00013711937936022878, -0.00011935727525269613, 0.0002303203073097393, -0.00017255225975532085, 5.4871947213541716e-05, -5.685907672159374e-05, 7.979189103934914e-05, 2.025296271312982e-05, -7.364688644884154e-05, 0.0001454590237699449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8.991984213935211e-05, -0.0001869743864517659, 0.0, -0.0004820090834982693, 0.0003077396540902555, 0.00020741892512887716, -0.0003315159701742232, 0.0003315159701742232, 0.0, 0.0, 0.0, 0.0, 0.00014073423517402261, 0.0, 0.0, -4.4644595618592575e-05, 4.813226041733287e-05, 8.048442623476149e-07, 0.0, 5.48786601939355e-06, 0.0, 0.0, 0.0, -8.285418152809143e-05, 1.021672687784303e-06, -0.00011893433111254126, 1.1106620149803348e-05, -0.00021140926401130855, 0.00037280184915289283, -0.0003532850823830813, -4.621091648004949e-05, 0.0, 2.6694162443163805e-05, 1.2726035492960364e-05, 0.0, 0.00031291559571400285, 0.0, -0.00033471768256276846, -0.00044197123497724533, -8.027252079045866e-06, 0.00031226116698235273, 0.0, -0.0006760089891031384, -0.0007172264740802348, -1.0520007265313325e-07, 0.0, 0.0, 0.0, 0.0003248033463023603, 0.000307276874082163, 0.0, 0.0, 0.0, 2.592711098259315e-05, 0.0005434341728687286, 0.00014832500892225653, 0.0, 0.0, 0.00021338123769965023, 0.0, 0.00010989093425450847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[[0.033562202006578445, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.01229142677038908, 1.9634710497484775e-06, 0.012295353226363659, -0.01229142677038908, 1.9634710497484775e-06, 0.012295353226363659, -0.01229142677038908, 0.25364357233047485, 1.9634710497484775e-06, 2.3354108333587646, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.03419940546154976, 1.6181892156600952, -0.6194846630096436, -1.2455706596374512, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9407202005386353, 0.8722386360168457, -0.027333702892065048, -0.4441184997558594, 1.9634710497484775e-06, 1.9634710497484775e-06, -1.2234790325164795, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 2.8301522731781006, 0.005522789433598518, -0.005518862511962652, 0.0033650326076895, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.08670181035995483, -0.08454012870788574, 1.9634710497484775e-06, 0.059960655868053436, -0.0010687141912057996, -0.0644068717956543, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.04660322144627571, -0.7014064192771912, 0.33820950984954834, 1.9634710497484775e-06, -0.40646156668663025, 1.9634710497484775e-06, 0.7133616209030151, 1.9634710497484775e-06, 0.20362798869609833, 1.7491445541381836, 1.9634710497484775e-06, -0.7266030311584473, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.6520847678184509, 0.8073596358299255, -1.2684475183486938, -0.32516106963157654, -1.315770149230957, 0.022555112838745117, -0.0036608169320970774, -0.000807620701380074, 1.9634710497484775e-06, 0.004306891933083534, -0.034989189356565475, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.03593742102384567, -0.0009423423907719553, 1.1706541776657104, -1.1706503629684448, 1.1332674026489258, -0.2965655028820038, -0.07916393131017685, 0.07916785776615143, 0.34934553503990173, 1.192466378211975, -0.5457990765571594, -0.3607504069805145, -0.0773271843791008, 1.9634710497484775e-06, -0.04997461661696434, -0.06745955348014832, 0.005395609885454178, 1.0732007026672363, -1.1289045810699463, 0.3967072367668152, -1.019539475440979, 0.8815070390701294, -0.3381243050098419, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.5249378085136414, 0.01617874950170517, 0.34525763988494873, 0.6645880937576294, 0.01306061539798975, -0.6125560402870178, -0.007161453366279602, 0.06720618903636932, 0.005371160805225372, 0.04381458833813667, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.006406840402632952, 1.9634710497484775e-06, -0.00633643101900816, -1.0922412872314453, 0.41908299922943115, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.001212143455632031, -1.681074619293213, 1.9634710497484775e-06, 1.1014164686203003, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.35208243131637573, 1.9634710497484775e-06, -0.9859406352043152, 1.9634710497484775e-06, -0.3509228825569153, 0.26761987805366516, 0.00016160709492396563, 0.012081634253263474, 0.035621147602796555, 0.0007310609216801822, -0.011867878958582878, 0.8814608454704285, 0.17000719904899597, -0.7440494894981384, 0.403834730386734, -0.2492564171552658, 0.783902108669281, 0.420857697725296, 1.9634710497484775e-06, -0.5348983407020569, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.6707472801208496, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.021158741787075996, 0.7266032099723816, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -1.4711071252822876, 1.9634710497484775e-06, 0.744836688041687, 1.9634710497484775e-06, 0.010898121632635593, -0.010894195176661015, 0.010898121632635593, 1.9634710497484775e-06, -0.010894195176661015, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.010898121632635593, -0.010894195176661015, 0.5967846512794495, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.36406034231185913, 1.9634710497484775e-06, -0.30244261026382446, 0.9082370400428772, 8.542336581740528e-05, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.008462854661047459, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.0614042803645134, 1.9634710497484775e-06, -2.195068597793579, 1.770538091659546, -0.6812304854393005, -0.1842479407787323, -0.5530456304550171, 1.9634710497484775e-06, 1.5872142314910889, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.022929908707737923, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.3328035771846771, -0.8133858442306519, 6.18974954704754e-05, 0.32708489894866943, -0.28471145033836365, 0.5494052767753601, -0.4116021394729614, 0.13089285790920258, -0.13562899827957153, 0.19033658504486084, 0.048313140869140625, -0.1756744384765625, 0.34697818756103516, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.21449175477027893, -0.4460045099258423, 1.9634710497484775e-06, -1.149776816368103, 0.73408043384552, 0.4947766065597534, -0.7907922863960266, 0.7907962203025818, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.33570775389671326, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.10649272799491882, 0.1148160845041275, 0.0019218294182792306, 1.9634710497484775e-06, 0.013092653825879097, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, -0.1976374238729477, 0.002439049305394292, -0.2837025821208954, 0.026495562866330147, -0.5042911767959595, 0.8892790079116821, -0.842720091342926, -0.1102290078997612, 1.9634710497484775e-06, 0.06367789953947067, 0.03035849705338478, 1.9634710497484775e-06, 0.746427059173584, 1.9634710497484775e-06, -0.7984296083450317, -1.0542709827423096, -0.0191461481153965, 0.7448660135269165, 1.9634710497484775e-06, -1.6125417947769165, -1.7108615636825562, -0.00024897954426705837, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.7747839689254761, 0.7329765558242798, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.06184818595647812, 1.296303391456604, 0.3538146913051605, 1.9634710497484775e-06, 1.9634710497484775e-06, 0.5089990496635437, 1.9634710497484775e-06, 0.26213449239730835, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06, 1.9634710497484775e-06]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27852/1179846173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logret1_xs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mrealized_volatility_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_optiver_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'realized_volatility_xs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logret1_xs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'book_realized_volatility'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         )\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    feature_x = dataset[idx][0]\n",
    "    test = scale_optiver_feature('logret1_xs', feature_x['logret1_xs'].reshape(1,-1))\n",
    "    print(feature_x['logret1_xs'].tolist())\n",
    "    print(test.tolist())\n",
    "    input()\n",
    "    realized_volatility_xs = scale_optiver_feature('realized_volatility_xs', feature_x['logret1_xs'].reshape(1,-1))\n",
    "    print(feature_x['book_realized_volatility'])\n",
    "#     print(feature_x['logret1_xs'])\n",
    "    print(realized_volatility_xs)\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e35973-37f1-408a-b47f-3a8fa6c9879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "class StockIdEmbedding(nn.Module):\n",
    "    def __init__(self,number_of_stock_embeddings=126+10, number_of_stock_embedding_dimention=2, mode='train'):\n",
    "        super(StockIdEmbedding, self).__init__()\n",
    "        self.use_stock_id = use_stock_id\n",
    "        \n",
    "        self.number_of_stock_embeddings = number_of_stock_embeddings\n",
    "        self.number_of_stock_embedding_dimention = number_of_stock_embedding_dimention\n",
    "        self.stock_embedding = nn.Embedding(self.number_of_stock_embeddings, self.number_of_stock_embedding_dimention)\n",
    "        self.mode = mode\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(self.number_of_stock_embedding_dimention, 32),\n",
    "            nn.Hardswish(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Hardswish(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "    def get_feature_gen_train_modes(self):\n",
    "        return []\n",
    "    \n",
    "    def set_mode(self,mode):\n",
    "        self.mode = mode\n",
    "    \n",
    "    def forward(self, feature_dict):\n",
    "        \n",
    "        stock_id_clamped = torch.clamp(feature_dict['stock_id'],0,self.number_of_stock_embeddings-1)\n",
    "        stock_id_clamped = stock_id_clamped.type(torch.cuda.IntTensor)\n",
    "        stock_id_clamped = stock_id_clamped.to(device).reshape(-1,1)\n",
    "        embedding_logits = self.stock_embedding(stock_id_clamped)\n",
    "        embedding_logits = embedding_logits.reshape(-1,self.number_of_stock_embedding_dimention)\n",
    "        \n",
    "        if self.mode == 'stock_id_embedding':\n",
    "            return embedding_logits\n",
    "\n",
    "            \n",
    "        logits = self.linear_stack(embedding_logits)\n",
    "        return logits\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, feature_generator_mode_hidden_size=64, mode='train'):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.use_stock_id = use_stock_id\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mode = mode\n",
    "        self.feature_generator_mode_hidden_size = feature_generator_mode_hidden_size\n",
    "        self.stock_id_embedding = StockIdEmbedding(number_of_stock_embedding_dimention=12, mode='stock_id_embedding')\n",
    "        self.cnn_stack = nn.Sequential(\n",
    "            nn.Conv1d(16, 24, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Hardswish(),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.Conv1d(24, 32, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Hardswish(),\n",
    "#             nn.Dropout(0.07),\n",
    "            nn.Conv1d(32, 48, kernel_size=2, stride=1, padding=0),\n",
    "            nn.Hardswish(),\n",
    "#             nn.Dropout(0.1),\n",
    "\n",
    "        )\n",
    "        self.linear_stack = nn.Sequential(\n",
    "#             nn.LazyLinear(256),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(0.05),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(512, 512),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.LazyLinear(self.feature_generator_mode_hidden_size),\n",
    "#             nn.Hardswish(),\n",
    "\n",
    "        )\n",
    "        self.linear_hybrid = nn.Sequential(\n",
    "            nn.Linear(self.feature_generator_mode_hidden_size, 32),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(256, 256),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_feature_gen_train_modes(self):\n",
    "        return []\n",
    "    \n",
    "    def set_mode(self,mode):\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train_stock_id_embedding':\n",
    "            self.stock_id_embedding.set_mode('train')\n",
    "        else:\n",
    "            self.stock_id_embedding.set_mode('stock_id_embedding')\n",
    "    \n",
    "    def forward(self, feature_dict):\n",
    "#         logits = self.basic_stack(x)\n",
    "#         x = self.flatten(x)\n",
    "        x = torch.cat([\n",
    "            scale_optiver_feature('trade_size_sum_xs',feature_dict['trade_size_sum_xs']).to(device),\n",
    "            scale_optiver_feature('trade_size_std_xs',feature_dict['trade_size_std_xs']).to(device),\n",
    "            scale_optiver_feature('trade_order_count_sum_xs',feature_dict['trade_order_count_sum_xs']).to(device),\n",
    "            scale_optiver_feature('trade_order_count_std_xs',feature_dict['trade_order_count_std_xs']).to(device),\n",
    "            scale_optiver_feature('trade_trade_money_turnover_sum_xs',feature_dict['trade_trade_money_turnover_sum_xs']).to(device),\n",
    "            scale_optiver_feature('trade_trade_money_turnover_std_xs',feature_dict['trade_trade_money_turnover_std_xs']).to(device),\n",
    "            scale_optiver_feature('book_price_spread1_sum_xs',feature_dict['book_price_spread1_sum_xs']).to(device),\n",
    "            scale_optiver_feature('book_price_spread1_std_xs',feature_dict['book_price_spread1_std_xs']).to(device),\n",
    "            scale_optiver_feature('book_bid_spread_sum_xs',feature_dict['book_bid_spread_sum_xs']).to(device),\n",
    "            scale_optiver_feature('book_bid_spread_std_xs',feature_dict['book_bid_spread_std_xs']).to(device),\n",
    "            scale_optiver_feature('book_ask_spread_sum_xs',feature_dict['book_ask_spread_sum_xs']).to(device),\n",
    "            scale_optiver_feature('book_ask_spread_std_xs',feature_dict['book_ask_spread_std_xs']).to(device),\n",
    "            scale_optiver_feature('book_total_volume_sum_xs',feature_dict['book_total_volume_sum_xs']).to(device),\n",
    "            scale_optiver_feature('book_total_volume_std_xs',feature_dict['book_total_volume_std_xs']).to(device),\n",
    "            scale_optiver_feature('book_volume_imbalance_sum_xs',feature_dict['book_volume_imbalance_sum_xs']).to(device),\n",
    "            scale_optiver_feature('book_volume_imbalance_std_xs',feature_dict['book_volume_imbalance_std_xs']).to(device),\n",
    "                            \n",
    "#                             scale_optiver_feature('book_logret1_sum_xs',feature_dict['book_logret1_sum_xs']).to(device),\n",
    "#                             scale_optiver_feature('book_logret1_realized_volatility_xs',feature_dict['book_logret1_realized_volatility_xs']).to(device),\n",
    "                            \n",
    "            \n",
    "#                             scale_optiver_feature('book_logret1_std_xs',feature_dict['book_logret1_std_xs']).to(device),\n",
    "#                             scale_optiver_feature('book_logret1_mean_xs',feature_dict['book_logret1_mean_xs']).to(device),\n",
    "                            \n",
    "               \n",
    "            \n",
    "#                             scale_optiver_feature('logrett_xs',feature_dict['logrett_xs']).to(device),\n",
    "\n",
    "#                                 feature_dict['logret1_xs'].to(device)*10000,\n",
    "                            \n",
    "#                                     feature_dict['book_price_spread1_xs'].to(device)*1000, \n",
    "#                                 feature_dict['book_bid_spread_xs'].to(device)*10000, \n",
    "#                                 feature_dict['book_ask_spread_xs'].to(device)*10000, \n",
    "\n",
    "#                                 torch.log(feature_dict['book_total_volume_xs'].to(device)+1),\n",
    "#                                 torch.log(feature_dict['book_volume_imbalance_xs'].to(device)+1),\n",
    "\n",
    "#                                 torch.log(feature_dict['trade_money_turnover_per_order_xs'].to(device)+1),\n",
    "                          ], 1)\n",
    "\n",
    "#         x = torch.nan_to_num(feature_dict['logrett_xs']).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        \n",
    "#         print(x)\n",
    "#         input()\n",
    "#         if torch.isnan(x).any():\n",
    "# #             print(x)\n",
    "#             print(feature_dict)\n",
    "#             input()\n",
    "        x = x.to(device)\n",
    "        x = x.reshape(-1,16,data_intervals_count)\n",
    "        \n",
    "        logits = self.cnn_stack(x)\n",
    "        logits = self.flatten(logits)\n",
    "        \n",
    "        #         if self.use_stock_id:\n",
    "        embedding_logits = self.stock_id_embedding(feature_dict)\n",
    "        \n",
    "        if self.mode == 'train_stock_id_embedding':\n",
    "            # in that case embedding logits are predicted volatility\n",
    "            return embedding_logits\n",
    "        \n",
    "#         print('cat',logits.size(), embedding_logits.size())\n",
    "        logits = torch.cat([logits,embedding_logits], 1)\n",
    "#         logits = embedding_logits\n",
    "        \n",
    "        \n",
    "        logits = self.linear_stack(logits)\n",
    "        \n",
    "        if self.mode == 'hidden_generator':\n",
    "            return logits\n",
    "#         logits = torch.cat( [logits, \n",
    "#                              torch.log(feature_dict['trade_money_turnover_mean'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001), \n",
    "#                                            torch.log(feature_dict['trade_money_turnover_std'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001),\n",
    "#                                            torch.log(feature_dict['trade_price_mean'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001),\n",
    "#                                            torch.log(feature_dict['book_money_turnover_mean'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001),\n",
    "#                                            torch.log(feature_dict['book_money_turnover_std'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001),\n",
    "#                                            torch.log(feature_dict['book_price_mean'].type(torch.cuda.FloatTensor).to(device).reshape(-1,1)+0.001)\n",
    "#                                       ], 1)\n",
    "        \n",
    "#         if self.use_stock_id:\n",
    "#             stock_id = torch.tensor(feature_dict['stock_id']).reshape(-1,1)\n",
    "#             stock_id = stock_id.to(device)\n",
    "#             logits = torch.cat([logits, stock_id], 1)\n",
    "            \n",
    "        logits = self.linear_hybrid(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "316cdf05-8827-491b-805c-902be90598c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VolatilityGRU(nn.Module):\n",
    "#     def __init__(self, input_size=1, hidden_size=64, repeated_cells=1):\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "class MultiFetGRU(nn.Module):\n",
    "    def __init__(self,feature_names, hidden_size=64, layers=1, dropout=0, features_out=32, mode=\"train\"):\n",
    "        \"\"\"single feature, feature learner\n",
    "        `mode`: train|feature_generator\n",
    "        \"\"\"\n",
    "        super(MultiFetGRU,self).__init__()\n",
    "        if type(feature_names) == str:\n",
    "            feature_names = [feature_names]\n",
    "        self.feature_names = feature_names\n",
    "        self.input_size_ = len(self.feature_names)\n",
    "        \n",
    "        self.hidden_size_ = hidden_size\n",
    "        self.repeated_lstm_cells_ = layers\n",
    "        self.dropout_ = dropout\n",
    "        self.features_out = features_out\n",
    "        \n",
    "        self.rnn_ = nn.GRU(self.input_size_, self.hidden_size_, self.repeated_lstm_cells_, batch_first=True, dropout=self.dropout_)\n",
    "        \n",
    "        self.linear_feature_stack_ = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size_*self.repeated_lstm_cells_, self.features_out),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Linear(128, self.features_out),\n",
    "        )\n",
    "        \n",
    "        self.linear_trainer_stack_ = nn.Sequential(\n",
    "#             nn.Linear(self.features_out, 128),\n",
    "            nn.Linear(self.features_out, 1),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.Hardswish(),\n",
    "#             nn.Linear(128, 1),   \n",
    "        )\n",
    "        \n",
    "    def set_mode(self, mode):\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, feature_dict, h0_tensor=None):\n",
    "        \n",
    "            \n",
    "        feature_x = []\n",
    "        for feature_name in self.feature_names:\n",
    "            if feature_name == 'book_realized_volatility_xs':\n",
    "                feature_tensor = feature_dict['logret1_xs']\n",
    "            elif feature_name == 'trade_realized_volatility_xs':\n",
    "                feature_tensor = feature_dict['logrett_xs']\n",
    "            else:\n",
    "                feature_tensor = feature_dict[feature_name]\n",
    "                \n",
    "            feature_x.append(scale_optiver_feature(feature_name, feature_tensor).to(device))\n",
    "            \n",
    "        feature_x = torch.stack(feature_x,dim=2) #.reshape(-1, data_intervals_count, self.input_size_)\n",
    "        \n",
    "        if self.mode in [\"feature_generator\",\"train\"]:\n",
    "            if h0_tensor is None:\n",
    "#                 h_0_ = torch.rand(self.repeated_lstm_cells_, feature_x.size(0), self.hidden_size_, device=device) #hidden state\n",
    "                h_0_ = torch.zeros(self.repeated_lstm_cells_, feature_x.size(0), self.hidden_size_, device=device) #hidden state\n",
    "            else:\n",
    "                h_0_ = h0_tensor\n",
    "            output_, hn_ = self.rnn_(feature_x, h_0_) #lstm with input, hidden, and internal state\n",
    "            hn_ = hn_.reshape(-1, self.hidden_size_*self.repeated_lstm_cells_) #reshaping the data for Dense layer next  \n",
    "            \n",
    "            out_ = self.linear_feature_stack_(hn_)\n",
    "            \n",
    "            if self.mode == \"train\":\n",
    "                out_ = self.linear_trainer_stack_(out_)\n",
    "            \n",
    "            return out_\n",
    "            \n",
    "            \n",
    "            \n",
    "class VolatilityBSModel(nn.Module):\n",
    "    def __init__(self, mode=\"hybrid\"):\n",
    "        \"\"\"various rnn features' fusion with fully connected nn\n",
    "        `mode`: hybrid|<feature_name>\n",
    "        \"\"\"\n",
    "        super(VolatilityBSModel, self).__init__()\n",
    "        self.mode = mode\n",
    "#         self.feature_list = ['logrett_xs','trade_volume_xs','trade_ordercount_xs','trade_money_turnover_xs','trade_money_turnover_per_order_xs',\n",
    "#                              'logret1_xs',\n",
    "#                              'book_price_spread1_xs','book_bid_spread_xs','book_ask_spread_xs',\n",
    "#                              'book_total_volume_xs','book_volume_imbalance_xs','book_money_turnover_intention1_xs','book_wap1_local_standardized_xs','trade_price_local_standardized_xs']\n",
    "#         self.feature_list = [[x] for x in self.feature_list]\n",
    "        # 'trade_volume_xs','trade_ordercount_xs','trade_money_turnover_xs','trade_money_turnover_per_order_xs',\n",
    "#                             #realized_volatility_xs  \n",
    "        self.feature_list = [['trade_logrett_sum_xs','trade_logrett_realized_volatility_xs','trade_logrett_std_xs',\n",
    "                             'trade_logrett_mean_xs'],\n",
    "                             ['trade_size_sum_xs','trade_size_std_xs','trade_order_count_sum_xs','trade_order_count_std_xs','trade_order_count_std_xs','trade_trade_money_turnover_sum_xs','trade_trade_money_turnover_std_xs'],\n",
    "                             ['book_logret1_sum_xs','book_logret1_realized_volatility_xs','book_logret1_std_xs',\n",
    "                             'book_logret1_mean_xs']\n",
    "                             ,['book_logret2_sum_xs','book_logret2_realized_volatility_xs','book_logret2_std_xs','book_logret2_mean_xs'],\n",
    "                             ['book_price_spread1_sum_xs','book_price_spread1_std_xs','book_bid_spread_sum_xs','book_bid_spread_std_xs','book_ask_spread_sum_xs',\n",
    "                              'book_ask_spread_std_xs','book_total_volume_sum_xs','book_total_volume_std_xs','book_volume_imbalance_sum_xs','book_volume_imbalance_std_xs']]\n",
    "        # ['trade_price_local_standardized_xs','trade_money_turnover_xs','book_money_turnover_intention1_xs','book_wap1_local_standardized_xs']\n",
    "#         self.feature_list = [['logrett_xs','logret1_xs'],['trade_volume_xs','trade_ordercount_xs','trade_money_turnover_per_order_xs','book_money_turnover_intention1_xs','trade_price_local_standardized_xs','book_wap1_local_standardized_xs'],['book_price_spread1_xs','book_bid_spread_xs','book_ask_spread_xs',\n",
    "#                              'book_total_volume_xs','book_volume_imbalance_xs']]\n",
    "         \n",
    "        self.feature_gen_feature_size = 128\n",
    "        self.feature_gen_models = {}\n",
    "        self.rnn_hidden_size = 32\n",
    "        self.rnn_layers = 1\n",
    "        self.stock_embedding_dimention = 12\n",
    "        self.stock_id_embedding = StockIdEmbedding(number_of_stock_embedding_dimention=self.stock_embedding_dimention, mode='stock_id_embedding')\n",
    "        self.hidden_generator_network = NeuralNetwork(feature_generator_mode_hidden_size=self.rnn_hidden_size*self.rnn_layers*1)\n",
    "        \n",
    "        for k in self.feature_list:\n",
    "            self.feature_gen_models[str(k)]=MultiFetGRU(k, hidden_size=self.rnn_hidden_size, layers=self.rnn_layers, dropout=0.0, features_out=self.feature_gen_feature_size) \n",
    "            self.feature_gen_models[str(k)].to(device)\n",
    "        \n",
    "        \n",
    "        self.linear_fusion = nn.Sequential(\n",
    "            #self.feature_gen_feature_size*len(self.feature_list) + self.rnn_hidden_size*self.rnn_layers + 2 + 1\n",
    "            nn.LazyLinear(512),\n",
    "            nn.Hardswish(),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.Linear(512,256),\n",
    "            nn.Hardswish(),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.Linear(256,128),\n",
    "            nn.Hardswish(),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.Linear(128,64),\n",
    "            nn.Hardswish(),\n",
    "#             nn.Dropout(0.05),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "        self.set_mode(self.mode)\n",
    "    \n",
    "    def get_feature_gen_train_modes(self):\n",
    "        return self.feature_list\n",
    "    \n",
    "    def set_mode(self, mode):\n",
    "        print(f\"------- set mode : {mode} -----------\")\n",
    "        self.mode = mode\n",
    "        for feature_gen_model in self.feature_gen_models.values():\n",
    "            feature_gen_model.set_mode('feature_generator' if self.mode in ['hybrid','hybrid_feature_out','hidden_generator','ultimate'] else 'train')\n",
    "        if self.mode == 'hidden_generator':\n",
    "            self.hidden_generator_network.set_mode('train')\n",
    "        else:\n",
    "            self.hidden_generator_network.set_mode('hidden_generator')\n",
    "        self.stock_id_embedding.set_mode('stock_id_embedding')\n",
    "    \n",
    "    def parameters(self):\n",
    "        \n",
    "        generator_sources_map = {str(k):[v] for k,v in self.feature_gen_models.items()}\n",
    "        generator_sources_map['hybrid']= [self.linear_fusion, self.stock_id_embedding]\n",
    "        generator_sources_map['hidden_generator'] = [self.hidden_generator_network] \n",
    "        generator_sources_map['ultimate']= [self.linear_fusion, self.hidden_generator_network, self.stock_id_embedding] + list(self.feature_gen_models.values())\n",
    "        params = []\n",
    "        # mode and key is actually str version of array of strings with feature name as values e.g. ['logret1_xs','volume_xs']\n",
    "        if str(self.mode) in generator_sources_map:\n",
    "            for generator_source in generator_sources_map[str(self.mode)]:\n",
    "                for param in generator_source.parameters():\n",
    "                    params.append(param)\n",
    "        else:\n",
    "            return super(VolatilityBSModel,self).parameters()\n",
    "        return params\n",
    "    \n",
    "    \n",
    "    def forward(self, feature_dict):\n",
    "        \n",
    "        \n",
    "        if self.mode in self.feature_list:\n",
    "            \n",
    "            \n",
    "            # pass in some randomness to the initial hidden tensor to force it to learn some stuff on its own\n",
    "            # otherwise as the initial hidden layer contains solid infor to minimize the loss; it'll just use that hidden layer to minimize and instead\n",
    "            # learn to not learn and directly bypass initial hidden\n",
    "#             h0_tensor.masked_fill_((torch.rand(h0_tensor.size()) > 0.5).to(device), 0.0)\n",
    "#             h0_tensor = torch.zeros(self.rnn_layers, -1, self.rnn_hidden_size)\n",
    "            out = self.feature_gen_models[str(self.mode)](feature_dict, h0_tensor=None)\n",
    "            return out\n",
    "        \n",
    "        if self.mode in ['hidden_generator']:\n",
    "            out = self.hidden_generator_network(feature_dict)\n",
    "            return out\n",
    "        \n",
    "        if self.mode in ['hybrid','hybrid_feature_out','ultimate']:\n",
    "            generated_features = []\n",
    "            for feature_name, feature_gen_model in self.feature_gen_models.items():\n",
    "#                 h0_tensor = torch.zeros(self.rnn_layers, -1, self.rnn_hidden_size)\n",
    "                features_out = feature_gen_model(feature_dict, h0_tensor=None)\n",
    "                generated_features.append(features_out)\n",
    "                \n",
    "                \n",
    "            combined_features = torch.cat(generated_features, 1)#.reshape(-1, self.feature_gen_feature_size*len(self.feature_list))\n",
    "            \n",
    "            cnn_features = self.hidden_generator_network(feature_dict)\n",
    "#             cnn_features = cnn_features.reshape(self.rnn_layers,-1,self.rnn_hidden_size)\n",
    "            combined_features = torch.cat([combined_features,cnn_features],1)\n",
    "    \n",
    "            embedding_logits = self.stock_id_embedding(feature_dict)\n",
    "            combined_features = torch.cat([combined_features,embedding_logits],1)\n",
    "            \n",
    "            realized_volatility_logits = feature_dict['book_realized_volatility'].to(device).reshape(-1,1)\n",
    "            realized_volatility_logits = realized_volatility_logits * realize_volatility_scale_factor\n",
    "            combined_features = torch.cat([combined_features,realized_volatility_logits],1)\n",
    "            \n",
    "            if self.mode == 'hybrid_feature_out':\n",
    "                return combined_features\n",
    "            \n",
    "            out = self.linear_fusion(combined_features)\n",
    "            return out\n",
    "        \n",
    "#         input(\"--- out got\")\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "9a33b331-4eb1-4c09-84df-01b687ac3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VolatilityBSModel(use_stock_id=use_stock_id)\n",
    "# # model = NeuralNetwork(use_stock_id=False)\n",
    "# model.to(device)\n",
    "# adam_for_modes = {}\n",
    "\n",
    "# for modeidx, mode in enumerate(['yoyo','trade','experiment','book','hybrid']*1):\n",
    "#     epochs = 1\n",
    "#     model.mode = mode\n",
    "#     print(model.parameters())\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1840c-2bc4-4521-933f-994f1ceb014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VolatilityBSModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9218f-b67a-49af-bd37-ff307bd12ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49a121-34ca-498f-9267-4c20a04e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "    print()\n",
    "    print()\n",
    "    print(layer)\n",
    "    print(\"-------\")\n",
    "    for l in layer.children():\n",
    "        print([x for x in l.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1f24f-c586-4e1b-aad6-fb4671c87232",
   "metadata": {},
   "source": [
    "#### analyze the initial weights (or change them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "931890cf-e329-4a15-b0d0-352dc27f985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @torch.no_grad()\n",
    "# def init_weights(m):\n",
    "# #     print(m)\n",
    "#     if type(m) == nn.Linear:\n",
    "# #         m.weight.fill_(1.0)\n",
    "#         torch.nn.init.xavier_uniform_(m.weight,gain=10)\n",
    "#         m.bias.data.uniform_(-1,1)\n",
    "# #     elif type(m) == nn.ReLU:\n",
    "# #         print(m.data)\n",
    "#     else:\n",
    "#         print(type(m))\n",
    "# #         print(m.weight)\n",
    "# model.apply(init_weights)\n",
    "# # for param in model.parameters():\n",
    "# # #     print(param)\n",
    "# #       print(param.data.size(), param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c79a7d-9e08-4433-9c77-1af049f349d6",
   "metadata": {},
   "source": [
    "### LEarning rate: our base line is 0.34 loss as that's what the optiver guys have when they use current 10 min realize vol and use it as target (copy to prediction). We create simplest neural network and work with learning rates to figure out what's best and when we see something in range of 0.35 then we've found good Learning rate\n",
    "- #### SGD: 1e-7 works best\n",
    "- #### ADAM: 1e-5, (NOTE: 1e-3 makes it behave dumb where some deep local minima gets stuck and produces constant output!)\n",
    "- TODO: analyze that constant output phenomenon more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5cb3871f-5215-4afb-92fc-47ae2d385fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-4\n",
    "# batch_size = 4096\n",
    "# epochs = 100\n",
    "\n",
    "# input_scaling = 1\n",
    "# output_scaling = 1\n",
    "\n",
    "# # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "# strategyname = \"ret1_n_ret2\"\n",
    "# summary_writer = SummaryWriter(f'../output/training_tensorboard/{strategyname}_scaleIn{input_scaling}Out{output_scaling}_{learning_rate}_{batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aadc54b-6009-4af6-bfb6-f6619c6acd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a7ed1-80f8-4a57-90b4-223345dde76b",
   "metadata": {},
   "source": [
    "### Learnings about training\n",
    "- (non scaling)logreturns input and volatility output; non scaled makes the model predict constant output with no variety(close to 0 std dev)\n",
    "- scaling input rids of variety issue, \n",
    "- scaling output makes the model start with low rmse initially so there's less ground to cover and we can iterate over ideas rapidly due to less epochs needed to achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef34a31-7317-47c0-a94f-9bebe2fd2e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n",
      "------- set mode : hybrid -----------\n",
      "------- set mode : hidden_generator -----------\n",
      "Current epochs: 2 LR : 0.001 batch_size: 256\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "---------- gg_hybridEXP20_CNNRNN_5s_StkFalse_0.001_256 hidden_generator ----------\n",
      "train: 0.5041880149449876 [16896/343145]\n",
      "train: 0.2879476402677707 [34048/343145]\n",
      "train: 0.274033146562861 [51200/343145]\n",
      "train: 0.277100759655682 [68352/343145]\n",
      "train: 0.2658251506179126 [85504/343145]\n",
      "train: 0.26029674864527 [102656/343145]\n",
      "train: 0.26301314982015694 [119808/343145]\n",
      "train: 0.26163914599525395 [136960/343145]\n",
      "train: 0.2575937538449444 [154112/343145]\n",
      "train: 0.25698648237470373 [171264/343145]\n",
      "train: 0.2602234707394643 [188416/343145]\n",
      "train: 0.26620888643300356 [205568/343145]\n",
      "train: 0.2778204913014796 [222720/343145]\n",
      "train: 0.25452305932543173 [239872/343145]\n",
      "train: 0.2605293657797486 [257024/343145]\n",
      "train: 0.2544078573362151 [274176/343145]\n",
      "train: 0.25765465755960837 [291328/343145]\n",
      "train: 0.2557400207021343 [308480/343145]\n",
      "train: 0.2516108464394043 [325632/343145]\n",
      "train: 0.251602540042863 [342784/343145]\n",
      "train: 0.24077652394771576 test: 0.25161337156203534 [343040/343145]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "---------- gg_hybridEXP20_CNNRNN_5s_StkFalse_0.001_256 hidden_generator ----------\n",
      "train: 0.24911157633451855 [16896/343145]\n",
      "train: 0.2533427634790762 [34048/343145]\n",
      "train: 0.2465414636170686 [51200/343145]\n",
      "train: 0.24760504066944122 [68352/343145]\n",
      "train: 0.2455624993612517 [85504/343145]\n",
      "train: 0.2506767976195065 [102656/343145]\n",
      "train: 0.251180766011352 [119808/343145]\n",
      "train: 0.24749354706771337 [136960/343145]\n",
      "train: 0.24658657588175872 [154112/343145]\n",
      "train: 0.25706903169404216 [171264/343145]\n",
      "train: 0.24599698964339584 [188416/343145]\n",
      "train: 0.255760299403276 [205568/343145]\n",
      "train: 0.24937861112516319 [222720/343145]\n",
      "train: 0.24490782596282104 [239872/343145]\n",
      "train: 0.24998768229982746 [257024/343145]\n",
      "train: 0.25023744044019214 [274176/343145]\n",
      "train: 0.2466973851420986 [291328/343145]\n",
      "train: 0.24300332456382354 [308480/343145]\n",
      "train: 0.24870424083809353 [325632/343145]\n",
      "train: 0.24925491725330923 [342784/343145]\n",
      "train: 0.2367699295282364 test: 0.2540624728426337 [343040/343145]\n",
      "------- set mode : ['trade_logrett_sum_xs', 'trade_logrett_realized_volatility_xs', 'trade_logrett_std_xs', 'trade_logrett_mean_xs'] -----------\n",
      "Current epochs: 2 LR : 0.001 batch_size: 256\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "---------- gg_hybridEXP20_CNNRNN_5s_StkFalse_0.001_256 ['trade_logrett_sum_xs', 'trade_logrett_realized_volatility_xs', 'trade_logrett_std_xs', 'trade_logrett_mean_xs'] ----------\n",
      "train: 0.6777863600360814 [16896/343145]\n",
      "train: 0.48674333140031617 [34048/343145]\n",
      "train: 0.3561880223786653 [51200/343145]\n",
      "train: 0.3361770243787054 [68352/343145]\n",
      "train: 0.3364659614527403 [85504/343145]\n",
      "train: 0.32264119742521596 [102656/343145]\n",
      "train: 0.32050904942982233 [119808/343145]\n",
      "train: 0.3266697806208881 [136960/343145]\n",
      "train: 0.3164415688657049 [154112/343145]\n",
      "train: 0.34238938030911914 [171264/343145]\n",
      "train: 0.32086940932629715 [188416/343145]\n",
      "train: 0.3371117782236925 [205568/343145]\n",
      "train: 0.3199359005066886 [222720/343145]\n",
      "train: 0.3069973103146055 [239872/343145]\n",
      "train: 0.3094571481889753 [257024/343145]\n",
      "train: 0.31237001561406835 [274176/343145]\n",
      "train: 0.30877262309416015 [291328/343145]\n",
      "train: 0.31652313515321534 [308480/343145]\n",
      "train: 0.3094960153102875 [325632/343145]\n",
      "train: 0.3140819379642828 [342784/343145]\n",
      "train: 0.30720001459121704 test: 0.3072080041858412 [343040/343145]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "---------- gg_hybridEXP20_CNNRNN_5s_StkFalse_0.001_256 ['trade_logrett_sum_xs', 'trade_logrett_realized_volatility_xs', 'trade_logrett_std_xs', 'trade_logrett_mean_xs'] ----------\n",
      "train: 0.31556955199031267 [16896/343145]\n",
      "train: 0.32154506845260733 [34048/343145]\n",
      "train: 0.3071912166787617 [51200/343145]\n",
      "train: 0.3199837959524411 [68352/343145]\n",
      "train: 0.3058206323367446 [85504/343145]\n",
      "train: 0.3003504044974028 [102656/343145]\n",
      "train: 0.30493522891357766 [119808/343145]\n",
      "train: 0.3061261795349975 [136960/343145]\n",
      "train: 0.30900947282563396 [154112/343145]\n",
      "train: 0.30973321199417114 [171264/343145]\n",
      "train: 0.3065080300195893 [188416/343145]\n",
      "train: 0.3093166969605346 [205568/343145]\n",
      "train: 0.30380709847407555 [222720/343145]\n",
      "train: 0.3239080483344064 [239872/343145]\n",
      "train: 0.3091762266052303 [257024/343145]\n",
      "train: 0.30885352038625463 [274176/343145]\n",
      "train: 0.3048235129064588 [291328/343145]\n",
      "train: 0.3047717138012843 [308480/343145]\n",
      "train: 0.3194055370430448 [325632/343145]\n",
      "train: 0.30551757207557334 [342784/343145]\n",
      "train: 0.3008570969104767 test: 0.3019869305370819 [343040/343145]\n",
      "------- set mode : ['trade_size_sum_xs', 'trade_size_std_xs', 'trade_order_count_sum_xs', 'trade_order_count_std_xs', 'trade_order_count_std_xs', 'trade_trade_money_turnover_sum_xs', 'trade_trade_money_turnover_std_xs'] -----------\n",
      "Current epochs: 2 LR : 0.001 batch_size: 256\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "---------- gg_hybridEXP20_CNNRNN_5s_StkFalse_0.001_256 ['trade_size_sum_xs', 'trade_size_std_xs', 'trade_order_count_sum_xs', 'trade_order_count_std_xs', 'trade_order_count_std_xs', 'trade_trade_money_turnover_sum_xs', 'trade_trade_money_turnover_std_xs'] ----------\n",
      "train: 0.6316550698742938 [16896/343145]\n",
      "train: 0.5479141126817731 [34048/343145]\n",
      "train: 0.5323555389446999 [51200/343145]\n",
      "train: 0.536444777873025 [68352/343145]\n",
      "train: 0.5200861207584837 [85504/343145]\n",
      "train: 0.5209931646710011 [102656/343145]\n",
      "train: 0.5178653967024675 [119808/343145]\n",
      "train: 0.5199482547703074 [136960/343145]\n",
      "train: 0.5157263777149257 [154112/343145]\n",
      "train: 0.5111186023968369 [171264/343145]\n",
      "train: 0.5174730375631532 [188416/343145]\n",
      "train: 0.5078933034370194 [205568/343145]\n",
      "train: 0.5236238005445965 [222720/343145]\n"
     ]
    }
   ],
   "source": [
    "# model = None\n",
    "strategyname = \"gg_hybridEXP20_CNNRNN_5s\"\n",
    "\n",
    "\n",
    "print(\"DEVICE:\", device)\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "training_configs = []\n",
    "learning_rates_to_try = [1e-3]# 1e-4]\n",
    "batch_sizes_to_try = [256]#, 512]#,10000, 128]\n",
    "# input_scalings_to_try = [1000]\n",
    "# output_scalings_to_try = [10000]\n",
    "\n",
    "for learning_rate in learning_rates_to_try:\n",
    "    for batch_size in batch_sizes_to_try:\n",
    "        for use_stock_id in [False]:\n",
    "            training_configs.append({\n",
    "                'learning_rate':learning_rate,\n",
    "                'batch_size':batch_size,\n",
    "                'use_stock_id': use_stock_id\n",
    "            })\n",
    "\n",
    "epochs = 200\n",
    "for training_config in training_configs:\n",
    "    \n",
    "    learning_rate = training_config['learning_rate']\n",
    "    batch_size = training_config['batch_size']\n",
    "    use_stock_id = training_config['use_stock_id']\n",
    "    # TRAINING SETUP\n",
    "    \n",
    "    #refresh the model\n",
    "    \n",
    "    STRATEGY_NAME_WITH_ATTRS = f\"{strategyname}_Stk{use_stock_id}_{learning_rate}_{batch_size}\"\n",
    "    summary_writer = SummaryWriter(f'../output/training_tensorboard/{STRATEGY_NAME_WITH_ATTRS}')\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    model = VolatilityBSModel()\n",
    "#     model = NeuralNetwork()\n",
    "#     model = StockIdEmbedding(number_of_stock_embedding_dimention=3)\n",
    "#     model\n",
    "    model.to(device)\n",
    "    optimizer_for_modes = {}\n",
    "    optimizer_scheduler_for_modes = {}\n",
    "    \n",
    "    feature_modes = ['logrett_xs','trade_volume_xs','trade_ordercount_xs','trade_money_turnover_per_order_xs',\n",
    "                             'logret1_xs',\n",
    "                             'book_price_spread1_xs','book_bid_spread_xs','book_ask_spread_xs',\n",
    "                             'book_total_volume_xs','book_volume_imbalance_xs']\n",
    "#     feature_modes = model.get_feature_gen_train_modes()\n",
    "    done_epochs = -1\n",
    "    for modeidx, mode in enumerate(['hidden_generator']+model.get_feature_gen_train_modes()+['hybrid']+['ultimate']):#+model.get_feature_gen_train_modes()+['hybrid']):#'train_stock_id_embedding','train']):#+['hidden_generator']*2 + feature_modes + ['hybrid']*2):\n",
    "        model.set_mode(mode)\n",
    "        \n",
    "#         batch_size\n",
    "        if mode == 'ultimate':\n",
    "            epochs = 5\n",
    "#             learning_rate = 1e-3\n",
    "#             batch_size = 1024\n",
    "        if mode in ['hybrid']:\n",
    "            epochs = 2\n",
    "#             learning_rate = 1e-3\n",
    "#             batch_size = 256\n",
    "        if mode in model.get_feature_gen_train_modes()+['hidden_generator']:\n",
    "            \n",
    "            epochs = 2\n",
    "#             learning_rate = 1e-3\n",
    "#             batch_size = 64\n",
    "            \n",
    "        print(f\"Current epochs: {epochs} LR : {learning_rate} batch_size: {batch_size}\")\n",
    "#             batch_size = 2\n",
    "#             learning_rate = 1e-5\n",
    "#             batch_size = 16\n",
    "#             learning_rate=1e-4\n",
    "        \n",
    "        \n",
    "#         print(model.parameters())\n",
    "#         input()\n",
    "#         continue\n",
    "        \n",
    "        if str(mode) not in optimizer_for_modes:\n",
    "            optimizer_for_modes[str(mode)] = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "            optimizer_scheduler_for_modes[str(mode)] = torch.optim.lr_scheduler.ExponentialLR(optimizer_for_modes[str(mode)], gamma=0.99)\n",
    "#             optimizer_for_modes[str(mode)] = torch.optim.RMSprop(model.parameters())\n",
    "#             if mode in model.get_feature_gen_train_modes():\n",
    "#                 optimizer_for_modes[str(mode)] = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        optimizer = optimizer_for_modes[str(mode)]\n",
    "        optimizer_scheduler = optimizer_scheduler_for_modes[str(mode)]\n",
    "        \n",
    "        # TRAINING SETUP DONE\n",
    "\n",
    "        \n",
    "\n",
    "        data_ohlc_sample_len = 1 # 1 for each of open high low close\n",
    "        losses_train = []\n",
    "        for t in range(epochs):\n",
    "            done_epochs += 1\n",
    "            \n",
    "            print(f\"Epoch {done_epochs+1}\\n-------------------------------\")\n",
    "            print(\"----------\", STRATEGY_NAME_WITH_ATTRS, mode,\"----------\")\n",
    "\n",
    "            dataloader_train = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0, pin_memory=True)\n",
    "            model.train()\n",
    "\n",
    "            for train_batch_idx, (Feature_X, feature_y) in enumerate(dataloader_train):\n",
    "                \n",
    "                y = feature_y['target_realized_volatility'].to(device) * realize_volatility_scale_factor \n",
    "\n",
    "                pred = model(Feature_X)\n",
    "#                 pred.to(device)\n",
    "#                 print(pred)\n",
    "#                 input()\n",
    "                loss_orig = loss_fn_orig(y, pred)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_orig.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "                losses_train.append(loss_orig.item())\n",
    "\n",
    "                if (t*int(train_size/batch_size) + train_batch_idx + 1) % int(train_size/20/batch_size) == 0:\n",
    "\n",
    "                    # NOTE: real loss is same as upscaled normalized loss as it's percentage loss (rmspe)\n",
    "                    prediction_variety = np.std((pred/realize_volatility_scale_factor).reshape(-1).tolist()) * 100\n",
    "                    #NOTE: prediction variety is important as model sometimes predits a constant value! regardless of the input, then per batch variety is lowest(0 std dev)\n",
    "\n",
    "\n",
    "                    summary_writer.add_scalar(\"Prediction Variety\", prediction_variety, done_epochs*(train_size) + (train_batch_idx*batch_size))\n",
    "                    summary_writer.add_scalar(\"Training Loss\", np.mean(losses_train), done_epochs*(train_size) + (train_batch_idx*batch_size))\n",
    "\n",
    "                    print(\"train:\", np.mean(losses_train), f\"[{train_batch_idx*batch_size:>5d}/{train_size:>5d}]\")\n",
    "                    losses_train = []\n",
    "            optimizer_scheduler.step()\n",
    "            dataloader_test = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                    shuffle=True, num_workers=0, pin_memory=True)\n",
    "            dataset_size = len(dataloader_test.dataset)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            losses_test = []\n",
    "            for _, (Feature_X, feature_y) in enumerate(dataloader_test):\n",
    "                with torch.no_grad():\n",
    "                    y = feature_y['target_realized_volatility'].to(device) * realize_volatility_scale_factor\n",
    "                    pred = model(Feature_X)\n",
    "                    loss = loss_fn_orig(y, pred)\n",
    "                    losses_test.append(loss.item())\n",
    "\n",
    "\n",
    "    #                 summary_writer.add_scalar(\"Epoch Training Loss\", np.mean(losses_train), (t+1)*train_size)\n",
    "            summary_writer.add_scalar(\"Test Loss\", np.mean(losses_test), done_epochs*(train_size) + (train_batch_idx*batch_size))\n",
    "            print(\"train:\", np.mean(losses_train), \"test:\", np.mean(losses_test), f\"[{train_batch_idx*batch_size:>5d}/{train_size:>5d}]\")\n",
    "            losses_test = []\n",
    "            if (t+1)%50==0:\n",
    "                torch.save(model.state_dict(), os.path.join(MODEL_OUTPUT_DIRECTORY,f\"{STRATEGY_NAME_WITH_ATTRS}_epoch_{t}_tloss_{loss:.4f}.pth\"))\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9c40a983-cebc-400b-9b8b-95c2e4874894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c865e507-c49e-401a-b561-c0c1cba9e80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stock_id</th>\n",
       "      <th>70</th>\n",
       "      <th>75</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.705222</td>\n",
       "      <td>0.579442</td>\n",
       "      <td>0.449084</td>\n",
       "      <td>0.813176</td>\n",
       "      <td>0.743353</td>\n",
       "      <td>0.573379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.744891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>0.469144</td>\n",
       "      <td>0.732183</td>\n",
       "      <td>0.739383</td>\n",
       "      <td>0.533038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.808020</td>\n",
       "      <td>0.754178</td>\n",
       "      <td>0.580484</td>\n",
       "      <td>0.473728</td>\n",
       "      <td>0.749465</td>\n",
       "      <td>0.756734</td>\n",
       "      <td>0.525109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.760358</td>\n",
       "      <td>0.660425</td>\n",
       "      <td>0.516831</td>\n",
       "      <td>0.285894</td>\n",
       "      <td>0.710278</td>\n",
       "      <td>0.650910</td>\n",
       "      <td>0.364603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.770228</td>\n",
       "      <td>0.753502</td>\n",
       "      <td>0.611220</td>\n",
       "      <td>0.576678</td>\n",
       "      <td>0.745659</td>\n",
       "      <td>0.778682</td>\n",
       "      <td>0.663163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.576149</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474793</td>\n",
       "      <td>0.560188</td>\n",
       "      <td>0.614096</td>\n",
       "      <td>0.499395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.340020</td>\n",
       "      <td>0.469144</td>\n",
       "      <td>0.474793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376075</td>\n",
       "      <td>0.555407</td>\n",
       "      <td>0.634929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.732183</td>\n",
       "      <td>0.560188</td>\n",
       "      <td>0.376075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758198</td>\n",
       "      <td>0.506475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.765444</td>\n",
       "      <td>0.739383</td>\n",
       "      <td>0.614096</td>\n",
       "      <td>0.555407</td>\n",
       "      <td>0.758198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.754608</td>\n",
       "      <td>0.721407</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>0.621860</td>\n",
       "      <td>0.706099</td>\n",
       "      <td>0.779024</td>\n",
       "      <td>0.685978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.870479</td>\n",
       "      <td>0.735199</td>\n",
       "      <td>0.600032</td>\n",
       "      <td>0.445861</td>\n",
       "      <td>0.825894</td>\n",
       "      <td>0.803625</td>\n",
       "      <td>0.532197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.740288</td>\n",
       "      <td>0.692165</td>\n",
       "      <td>0.533340</td>\n",
       "      <td>0.539652</td>\n",
       "      <td>0.685939</td>\n",
       "      <td>0.747160</td>\n",
       "      <td>0.595898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.820951</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.626719</td>\n",
       "      <td>0.525911</td>\n",
       "      <td>0.791776</td>\n",
       "      <td>0.792502</td>\n",
       "      <td>0.716967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.570766</td>\n",
       "      <td>0.402027</td>\n",
       "      <td>0.779568</td>\n",
       "      <td>0.763643</td>\n",
       "      <td>0.542926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.745952</td>\n",
       "      <td>0.719873</td>\n",
       "      <td>0.629644</td>\n",
       "      <td>0.498651</td>\n",
       "      <td>0.741755</td>\n",
       "      <td>0.753600</td>\n",
       "      <td>0.632786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.763163</td>\n",
       "      <td>0.714092</td>\n",
       "      <td>0.562613</td>\n",
       "      <td>0.474837</td>\n",
       "      <td>0.735885</td>\n",
       "      <td>0.754644</td>\n",
       "      <td>0.622048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.911003</td>\n",
       "      <td>0.725142</td>\n",
       "      <td>0.549348</td>\n",
       "      <td>0.298335</td>\n",
       "      <td>0.832846</td>\n",
       "      <td>0.761384</td>\n",
       "      <td>0.454619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.854270</td>\n",
       "      <td>0.744462</td>\n",
       "      <td>0.602939</td>\n",
       "      <td>0.477151</td>\n",
       "      <td>0.841559</td>\n",
       "      <td>0.802465</td>\n",
       "      <td>0.571472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.746706</td>\n",
       "      <td>0.591059</td>\n",
       "      <td>0.443440</td>\n",
       "      <td>0.810087</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.619799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.781451</td>\n",
       "      <td>0.753629</td>\n",
       "      <td>0.601444</td>\n",
       "      <td>0.494994</td>\n",
       "      <td>0.720945</td>\n",
       "      <td>0.736164</td>\n",
       "      <td>0.565407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stock_id        70        75        80        81        82        83        8 \n",
       "stock_id                                                                      \n",
       "74        0.811194  0.705222  0.579442  0.449084  0.813176  0.743353  0.573379\n",
       "75        0.744891  1.000000  0.589083  0.469144  0.732183  0.739383  0.533038\n",
       "76        0.808020  0.754178  0.580484  0.473728  0.749465  0.756734  0.525109\n",
       "77        0.760358  0.660425  0.516831  0.285894  0.710278  0.650910  0.364603\n",
       "78        0.770228  0.753502  0.611220  0.576678  0.745659  0.778682  0.663163\n",
       "80        0.576149  0.589083  1.000000  0.474793  0.560188  0.614096  0.499395\n",
       "81        0.340020  0.469144  0.474793  1.000000  0.376075  0.555407  0.634929\n",
       "82        0.844946  0.732183  0.560188  0.376075  1.000000  0.758198  0.506475\n",
       "83        0.765444  0.739383  0.614096  0.555407  0.758198  1.000000  0.622576\n",
       "84        0.754608  0.721407  0.589519  0.621860  0.706099  0.779024  0.685978\n",
       "85        0.870479  0.735199  0.600032  0.445861  0.825894  0.803625  0.532197\n",
       "86        0.740288  0.692165  0.533340  0.539652  0.685939  0.747160  0.595898\n",
       "87        0.820951  0.752925  0.626719  0.525911  0.791776  0.792502  0.716967\n",
       "88        0.816374  0.731109  0.570766  0.402027  0.779568  0.763643  0.542926\n",
       "89        0.745952  0.719873  0.629644  0.498651  0.741755  0.753600  0.632786\n",
       "90        0.763163  0.714092  0.562613  0.474837  0.735885  0.754644  0.622048\n",
       "93        0.911003  0.725142  0.549348  0.298335  0.832846  0.761384  0.454619\n",
       "94        0.854270  0.744462  0.602939  0.477151  0.841559  0.802465  0.571472\n",
       "95        0.880381  0.746706  0.591059  0.443440  0.810087  0.780505  0.619799\n",
       "96        0.781451  0.753629  0.601444  0.494994  0.720945  0.736164  0.565407"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p = dataset.main_df.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "corr[[70,75,80,81,82,83,8]][65:85]\n",
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "28b838c3-3aea-416a-8b20-cf2eacddb2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Learned ----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Default ---------------------\n",
      "------- set mode : hybrid -----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"----------- Learned ----------\")\n",
    "stock_ids = torch.tensor(dataset.main_df['stock_id'].unique())\n",
    "# print(stock_ids)\n",
    "\n",
    "embedding_predictor = model.hidden_generator_network.stock_id_embedding #.set_mode('stock_id_embedding')\n",
    "pred = embedding_predictor({'stock_id':stock_ids})\n",
    "datapoints = pred.tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([75,70])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([76,78,82,85,87,88,94,95])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "embedding_predictor = model.stock_id_embedding #.set_mode('stock_id_embedding')\n",
    "pred = embedding_predictor({'stock_id':stock_ids})\n",
    "datapoints = pred.tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([75,70])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([76,78,82,85,87,88,94,95])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "plt.show()\n",
    "\n",
    "print(\"------------- Default ---------------------\")\n",
    "default_model = VolatilityBSModel().to(device)\n",
    "embedding_predictor = default_model.hidden_generator_network.stock_id_embedding #.set_mode('stock_id_embedding')\n",
    "pred = embedding_predictor({'stock_id':stock_ids})\n",
    "datapoints = pred.tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([75,70])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([76,78,82,85,87,88,94,95])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "embedding_predictor = default_model.stock_id_embedding #.set_mode('stock_id_embedding')\n",
    "pred = embedding_predictor({'stock_id':stock_ids})\n",
    "datapoints = pred.tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([75,70])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "datapoints = embedding_predictor({'stock_id':torch.tensor([76,78,82,85,87,88,94,95])}).tolist()\n",
    "plt.scatter([x[0] for x in datapoints], [x[1] for x in datapoints])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "99ec365f-201b-44f7-826c-2017b8bbc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), os.path.join(MODEL_OUTPUT_DIRECTORY,f\"13_{STRATEGY_NAME_WITH_ATTRS}_epoch_{t}_tloss_{np.mean(losses_test):.4f}.pth\"))\n",
    "model_statedict = {'base':model.state_dict()}\n",
    "for k,v in model.feature_gen_models.items():\n",
    "    model_statedict[k] = v.state_dict()\n",
    "\n",
    "torch.save(model_statedict, os.path.join(MODEL_OUTPUT_DIRECTORY,f\"16_{STRATEGY_NAME_WITH_ATTRS}_epoch_{t}_tloss_{np.mean(losses_test):.4f}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "50cf1a35-5d02-43e8-b242-66d082ac237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0a1f5760-8926-4064-8bf2-bddd62c80bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74227704-6e5f-41fd-b9a2-242d0b8e9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optiver_custom_collate_func(batch):\n",
    "    output_x = {}\n",
    "    for k,v in batch[0][0].items():\n",
    "        output_x[k] = []\n",
    "    \n",
    "    for x_dict in [x[0] for x in batch]:\n",
    "        for k,v in x_dict.items():\n",
    "            output_x[k].append(v)\n",
    "    \n",
    "    for k,v in batch[0][0].items():\n",
    "        if type(output_x[k][0]) != str:\n",
    "            output_x[k] = torch.stack(output_x[k])\n",
    "        \n",
    "    output_y = []\n",
    "    for y in [x[1] for x in batch]:\n",
    "        output_y.append(y)\n",
    "    output_y = torch.stack(output_y)\n",
    "    \n",
    "    return (output_x, output_y)\n",
    "#     input()\n",
    "#     print(batch)\n",
    "# #     return batch\n",
    "#     input()\n",
    "#     return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "17cea68b-9cf2-4a6c-8fab-d0e6b8f7654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id\n",
      "['96-13771']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_id\n",
      "tensor([96.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds_in_bucket_xs\n",
      "tensor([[  5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,  60.,\n",
      "          65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115., 120.,\n",
      "         125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175., 180.,\n",
      "         185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235., 240.,\n",
      "         245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295., 300.,\n",
      "         305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355., 360.,\n",
      "         365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415., 420.,\n",
      "         425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475., 480.,\n",
      "         485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535., 540.,\n",
      "         545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595., 600.]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logrett_xs\n",
      "tensor([[-0.2583, -0.2583, -0.2583, -0.2583, -0.2565, -0.2560, -0.2566, -1.2919,\n",
      "         -0.0621, -0.0615, -0.0621, -0.0621, -0.2757, -0.2751,  2.5545, -0.3759,\n",
      "          1.5375, -1.2732, -1.4517, -0.6660, -0.6666, -0.6661, -0.0943, -0.8810,\n",
      "         -0.8745, -3.8643, -2.0211, -0.0137, -1.3876, -0.1028, -0.2772, -0.2766,\n",
      "         -2.2825, -0.0269,  1.6510, -1.3265,  2.1354,  2.1350,  0.5107,  0.5112,\n",
      "         -0.6612, -0.1995, -0.1995, -2.8131, -2.8139, -1.4733, -1.5446,  0.1518,\n",
      "          1.3928, -0.8829, -0.2122, -0.2122, -0.4472, -0.4466, -0.4472,  1.6626,\n",
      "          1.2654,  1.2647,  1.1127,  1.5446,  1.5443,  2.4143,  0.7716,  0.7715,\n",
      "         -0.4849, -0.8379, -1.7267, -0.9193, -0.5514, -0.5508, -0.2246, -0.2252,\n",
      "         -0.2252, -0.2247,  0.4583,  0.6620,  1.0186,  1.1863, -0.5597,  0.2849,\n",
      "          0.2855,  0.2849, -0.0747, -0.8219, -0.8220, -0.0287, -0.0287, -0.0287,\n",
      "          2.1707, -0.2222, -0.2222, -0.2222, -0.7705, -0.7706, -0.7707, -0.7707,\n",
      "          0.2205,  0.6614,  0.6619,  0.8823, -0.8029, -0.8023, -0.8030, -2.0030,\n",
      "         -0.0884,  0.2498,  0.2504,  0.2498, -1.9602, -2.1202, -5.4583, -0.6376,\n",
      "         -0.6383,  0.7615,  0.7620,  0.0221, -0.6903, -0.6897, -0.6903, -0.6904]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_volume_xs\n",
      "tensor([[5.3033, 0.0000, 0.0000, 5.3375, 0.0000, 0.0000, 5.3230, 5.2095, 0.0000,\n",
      "         0.0000, 0.0000, 2.1972, 0.0000, 5.1417, 4.7875, 6.5191, 4.1431, 4.8203,\n",
      "         4.6634, 0.0000, 0.0000, 6.4630, 3.0445, 2.8332, 6.4677, 4.8363, 4.5951,\n",
      "         6.3648, 4.7958, 5.5175, 0.0000, 5.3566, 6.4568, 6.1203, 5.9081, 3.2581,\n",
      "         0.0000, 6.5568, 0.0000, 0.6931, 2.1972, 0.0000, 4.6634, 0.0000, 5.7268,\n",
      "         4.3175, 1.3863, 4.9836, 0.6931, 0.6931, 0.0000, 6.2916, 0.0000, 0.0000,\n",
      "         4.6151, 6.0113, 0.0000, 0.6931, 5.3033, 0.0000, 6.1485, 4.6250, 0.0000,\n",
      "         4.6151, 6.2226, 5.3230, 2.9444, 4.6151, 0.0000, 3.0445, 0.0000, 0.0000,\n",
      "         0.0000, 5.7746, 3.6376, 0.6931, 6.0331, 1.6094, 5.2883, 0.0000, 0.0000,\n",
      "         5.7170, 4.7274, 0.0000, 4.9558, 0.0000, 0.0000, 4.9345, 4.6250, 0.0000,\n",
      "         0.0000, 5.3327, 0.0000, 0.0000, 0.0000, 1.0986, 0.6931, 0.0000, 1.0986,\n",
      "         0.6931, 0.0000, 0.0000, 5.6312, 4.6250, 5.7557, 0.0000, 0.0000, 1.0986,\n",
      "         5.7203, 4.7274, 6.2710, 0.0000, 0.6931, 0.0000, 4.9488, 4.8283, 0.0000,\n",
      "         0.0000, 0.0000, 4.6250]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_ordercount_xs\n",
      "tensor([[1.9459, 0.0000, 0.0000, 2.1972, 0.0000, 0.0000, 1.7918, 2.0794, 0.0000,\n",
      "         0.0000, 0.0000, 1.9459, 0.0000, 1.0986, 2.0794, 2.7081, 1.3863, 1.3863,\n",
      "         1.3863, 0.0000, 0.0000, 2.1972, 0.6931, 1.0986, 2.0794, 1.0986, 1.3863,\n",
      "         2.6391, 1.6094, 2.0794, 0.0000, 2.0794, 2.7081, 2.5649, 2.3979, 0.6931,\n",
      "         0.0000, 2.6391, 0.0000, 0.6931, 1.3863, 0.0000, 1.0986, 0.0000, 2.0794,\n",
      "         1.3863, 0.6931, 1.3863, 0.6931, 0.6931, 0.0000, 2.4849, 0.0000, 0.0000,\n",
      "         1.0986, 2.5649, 0.0000, 0.6931, 1.3863, 0.0000, 2.9444, 1.0986, 0.0000,\n",
      "         1.0986, 2.3979, 1.6094, 1.6094, 1.3863, 0.0000, 0.6931, 0.0000, 0.0000,\n",
      "         0.0000, 2.3979, 1.0986, 0.6931, 2.7081, 0.6931, 1.9459, 0.0000, 0.0000,\n",
      "         2.0794, 1.3863, 0.0000, 1.3863, 0.0000, 0.0000, 2.4849, 1.3863, 0.0000,\n",
      "         0.0000, 1.7918, 0.0000, 0.0000, 0.0000, 1.0986, 0.6931, 0.0000, 1.0986,\n",
      "         0.6931, 0.0000, 0.0000, 1.7918, 1.3863, 2.6391, 0.0000, 0.0000, 1.0986,\n",
      "         2.6391, 1.9459, 2.4849, 0.0000, 0.6931, 0.0000, 2.6391, 1.7918, 0.0000,\n",
      "         0.0000, 0.0000, 1.0986]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_money_turnover_xs\n",
      "tensor([[5.3024, 0.0000, 0.0000, 5.3366, 0.0000, 0.0000, 5.3220, 5.2083, 0.0000,\n",
      "         0.0000, 0.0000, 2.1962, 0.0000, 5.1404, 4.7865, 6.5181, 4.1423, 4.8193,\n",
      "         4.6623, 0.0000, 0.0000, 6.4617, 3.0432, 2.8319, 6.4662, 4.8344, 4.5930,\n",
      "         6.3626, 4.7936, 5.5152, 0.0000, 5.3543, 6.4542, 6.1178, 5.9057, 3.2557,\n",
      "         0.0000, 6.5547, 0.0000, 0.6922, 2.1954, 0.0000, 4.6614, 0.0000, 5.7242,\n",
      "         4.3147, 1.3841, 4.9807, 0.6917, 0.6917, 0.0000, 6.2886, 0.0000, 0.0000,\n",
      "         4.6121, 6.0084, 0.0000, 0.6918, 5.3008, 0.0000, 6.1462, 4.6230, 0.0000,\n",
      "         4.6133, 6.2206, 5.3210, 2.9424, 4.6129, 0.0000, 3.0423, 0.0000, 0.0000,\n",
      "         0.0000, 5.7721, 3.6353, 0.6920, 6.0309, 1.6078, 5.2861, 0.0000, 0.0000,\n",
      "         5.7150, 4.7253, 0.0000, 4.9536, 0.0000, 0.0000, 4.9322, 4.6229, 0.0000,\n",
      "         0.0000, 5.3307, 0.0000, 0.0000, 0.0000, 1.0970, 0.6920, 0.0000, 1.0971,\n",
      "         0.6921, 0.0000, 0.0000, 5.6288, 4.6224, 5.7532, 0.0000, 0.0000, 1.0969,\n",
      "         5.7175, 4.7245, 6.2677, 0.0000, 0.6913, 0.0000, 4.9453, 4.8249, 0.0000,\n",
      "         0.0000, 0.0000, 4.6213]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade_money_turnover_per_order_xs\n",
      "tensor([[3.5353, 0.0000, 0.0000, 3.2903, 0.0000, 0.0000, 3.7319, 3.7785, 0.0000,\n",
      "         0.0000, 0.0000, 1.2229, 0.0000, 4.4531, 2.8894, 4.6450, 3.0749, 3.7367,\n",
      "         3.9878, 0.0000, 0.0000, 5.2162, 3.0432, 2.1959, 4.5295, 4.8344, 4.5930,\n",
      "         4.7957, 3.9296, 4.8843, 0.0000, 3.4363, 4.5166, 4.8029, 4.8006, 3.2557,\n",
      "         0.0000, 5.0585, 0.0000, 0.6922, 1.2978, 0.0000, 3.9776, 0.0000, 3.7977,\n",
      "         3.2425, 1.3841, 3.8957, 0.6917, 0.6917, 0.0000, 3.9091, 0.0000, 0.0000,\n",
      "         3.9288, 3.5501, 0.0000, 0.6918, 5.0114, 0.0000, 3.2916, 3.9396, 0.0000,\n",
      "         3.9300, 4.0547, 4.9082, 1.7030, 3.5339, 0.0000, 3.0423, 0.0000, 0.0000,\n",
      "         0.0000, 4.3371, 2.9681, 0.6920, 4.2836, 1.6078, 3.5194, 0.0000, 0.0000,\n",
      "         3.7886, 3.6443, 0.0000, 3.8690, 0.0000, 0.0000, 3.0954, 3.9492, 0.0000,\n",
      "         0.0000, 4.0278, 0.0000, 0.0000, 0.0000, 0.6919, 0.6920, 0.0000, 0.6920,\n",
      "         0.6921, 0.0000, 0.0000, 4.0336, 3.5432, 4.0198, 0.0000, 0.0000, 0.6919,\n",
      "         3.4135, 3.4472, 4.2308, 0.0000, 0.6913, 0.0000, 4.6442, 3.2470, 0.0000,\n",
      "         0.0000, 0.0000, 4.6213]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logret1_xs\n",
      "tensor([[-7.7680e-01, -7.7680e-01, -6.8623e-02,  6.7328e-01, -4.8532e-02,\n",
      "          3.7172e-01,  5.6857e-02, -2.5074e-01, -9.9375e-01,  1.7405e-01,\n",
      "          6.8433e-02,  7.0038e-01,  1.2492e-01, -1.3495e+00,  1.0666e+00,\n",
      "          5.1070e-01, -4.1751e-02, -6.4015e-03, -6.7136e-01, -2.6296e-02,\n",
      "          3.9817e-02, -9.8889e-01, -8.4128e-01, -1.1107e+00, -2.2903e+00,\n",
      "         -1.5481e+00, -1.5099e+00, -9.2775e-01, -7.4993e-01, -1.3067e+00,\n",
      "          1.8113e-01, -3.6812e-01, -2.8201e+00,  1.3158e-01,  1.6369e+00,\n",
      "          1.9151e-01,  3.7371e-01,  1.7664e+00,  1.1575e+00, -1.1125e-01,\n",
      "          7.9329e-02,  8.9109e-01, -3.4531e+00, -2.2108e+00, -1.5161e+00,\n",
      "         -5.4590e-01, -7.1532e-01,  1.3627e-01, -5.4038e-01,  9.0180e-01,\n",
      "         -7.0203e-01, -1.4106e+00, -1.5298e-01, -1.5299e-01, -1.0891e-03,\n",
      "          2.9099e+00, -2.2905e-01, -4.5718e-01,  2.1538e+00,  1.5167e-01,\n",
      "          4.0605e+00,  1.8936e-01,  5.3510e-01,  1.5238e+00,  4.5908e-01,\n",
      "         -1.1990e+00, -7.9428e-01, -1.3792e+00,  2.2514e-01, -9.8336e-01,\n",
      "          8.9667e-01, -5.0048e-01, -5.0050e-01, -9.5374e-01,  6.0001e-02,\n",
      "          2.2383e-01,  3.2025e-01,  1.1402e+00,  5.8908e-01, -1.5750e+00,\n",
      "         -3.1343e-02,  1.3332e+00,  5.6344e-01,  9.6391e-01,  3.1342e-01,\n",
      "         -3.0081e+00, -5.3374e-01, -6.4902e-01,  1.7861e+00, -1.9742e-01,\n",
      "          1.2865e+00, -3.0998e-01, -1.3622e+00,  5.5502e-01,  0.0000e+00,\n",
      "         -2.9586e+00,  1.2638e+00,  7.6171e-01,  6.1231e-01,  9.0020e-01,\n",
      "         -1.0147e-03, -1.3182e+00, -1.3183e+00, -7.5227e-01, -1.5973e+00,\n",
      "         -8.1991e-01,  1.1986e+00,  1.4711e-01, -2.0264e+00, -1.3291e+00,\n",
      "         -5.3050e+00, -2.0951e+00,  5.3387e-01, -7.8693e-02,  5.3789e-01,\n",
      "          1.9783e+00, -2.8291e+00,  1.2949e+00, -1.7899e-01, -4.8892e-02]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logret2_xs\n",
      "tensor([[ 0.9859,  0.9859, -0.1455, -1.2756,  1.5009, -0.0909, -0.0406, -0.5837,\n",
      "         -0.5796, -0.9822,  0.3893,  0.4608, -0.0628, -0.1517,  0.0359,  0.9919,\n",
      "         -0.5060,  0.0652, -1.9585, -0.5432,  0.4822, -0.3305, -0.2238,  0.0935,\n",
      "         -2.9143, -2.2891, -1.2099, -1.0210, -2.9866,  0.9696,  0.1230, -1.1505,\n",
      "         -1.7135,  0.2416,  1.8676, -0.2321,  0.1684,  1.8445, -0.0817, -1.3762,\n",
      "          1.8866,  1.9385, -2.1587, -1.1067, -4.4063, -0.5619, -0.2444, -0.4791,\n",
      "         -0.6453, -0.6869,  1.8901, -2.1611, -0.0178, -0.0178, -0.3498,  0.6256,\n",
      "          0.5493,  2.6553,  1.5744, -0.6500,  2.3321,  2.1582,  1.2279,  0.2242,\n",
      "         -0.4004, -0.2631, -2.0794, -0.5214,  0.0000,  1.0671, -0.2156, -0.0635,\n",
      "         -0.0635, -3.0902,  1.6110,  0.0915, -0.6223,  1.2058, -0.1832,  0.1907,\n",
      "         -0.1133,  1.5597,  0.1667, -1.8668, -0.6013, -0.3198,  1.0539, -1.2939,\n",
      "          2.3039,  1.6961,  0.4793, -3.0270, -1.4520,  1.6252, -0.0483, -1.6339,\n",
      "          0.6728,  1.1467, -0.3846, -0.1781,  1.4351, -0.7536, -0.7537, -1.5527,\n",
      "         -2.6237,  0.2717, -0.5195,  0.2717,  0.9765, -3.4961, -3.2493, -3.2187,\n",
      "         -0.4303,  0.1247,  1.2807,  0.0454, -2.5902,  1.0193,  0.6861, -0.4485]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_directional_volume1_xs\n",
      "tensor([[   4.2000,   70.0000,  106.3333,   34.7500,  245.0000,  212.0000,\n",
      "          303.2000,  -21.7500,  -24.3333,  -51.5000,  -70.2000,  -80.0000,\n",
      "         -127.0000,   -1.0000,   12.2500,   61.5000,   82.0000,   57.6667,\n",
      "         -217.0000, -191.0000, -199.0000, -127.8000, -184.5000, -257.2500,\n",
      "          -76.4000, -102.6000,  -63.4000,  -81.2500, -136.7500,   20.0000,\n",
      "          -77.7500, -219.5000,  -30.7500,   14.0000,   -4.5000,  -96.0000,\n",
      "           -4.0000,   64.7500,  -74.0000,  -94.6000,  -91.0000,  -99.0000,\n",
      "          -40.0000,   97.0000,   81.7500, -100.0000, -100.6667, -118.3333,\n",
      "          -33.0000,  -98.2500,  -50.0000, -121.7500,    0.0000,  -99.0000,\n",
      "          -99.0000,  -98.6000, -152.5000,    0.0000,   35.6000,  148.5000,\n",
      "          -74.5000,   76.7500,  157.0000, -159.2000, -155.4000,  -12.7500,\n",
      "          -58.2000,  -11.0000, -111.0000,  -21.6000, -104.3333,    0.0000,\n",
      "          -28.0000,  -46.2500,  -99.0000,  -98.5000,   26.7500,   -1.5000,\n",
      "          -19.2500,   88.7500,   80.5000,  111.4000,   -8.2500,  -66.0000,\n",
      "          -85.5000,  -19.6000,   -2.5000,   75.0000,  143.5000,  176.0000,\n",
      "          100.0000,  -32.2000,    2.0000,    7.0000,    7.0000,   10.0000,\n",
      "          -12.5000,  -23.0000,  -98.5000, -188.0000,  -99.0000,    0.0000,\n",
      "          -80.0000,  -24.7500,   -3.0000,    0.8000,    1.0000,    0.6667,\n",
      "           21.0000,  -49.5000,  -33.0000,  -44.0000, -137.4000, -115.0000,\n",
      "          -28.7500,  -14.6667,   11.3333,  -23.3333,  -93.2500, -123.7500]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_directional_volume2_xs\n",
      "tensor([[  17.8000,  -99.0000,  -99.0000,   26.2500,  -41.7500,    0.0000,\n",
      "           34.0000,    5.7500,  -95.6667,  -46.5000,  -89.8000,  -77.0000,\n",
      "          -44.6000,  -24.0000,  -44.0000,   51.5000,   33.0000,  -10.6667,\n",
      "           18.0000,   55.0000,   16.0000,   -8.0000, -165.7500, -162.7500,\n",
      "          -50.6000,  -72.4000, -159.6000,  -76.2500,   56.2500,   -7.5000,\n",
      "          -50.0000,   68.0000,  -71.2500,  -93.5000, -121.2500,  -68.4000,\n",
      "          -77.0000,   23.5000,  -19.5000,   78.2000,   15.6000,  -78.0000,\n",
      "         -126.6667, -101.0000,   50.5000,  -15.7500,  -48.3333,  -87.6667,\n",
      "           57.6667,  244.5000, -154.0000,  -52.7500,    0.0000,  -99.0000,\n",
      "          -59.0000,   61.6000,   38.0000, -100.0000,  -95.6000,   47.5000,\n",
      "           37.2500,  101.2500,  -39.0000,  -51.2000,    1.8000,   13.2500,\n",
      "           26.4000,    0.0000,    0.0000, -145.4000,  -91.3333,    0.0000,\n",
      "          -95.0000,   14.2500,  -60.0000,  -59.5000,  113.5000,  -10.2500,\n",
      "          105.7500,   -4.0000,   50.7500,   -2.4000,  -19.7500,  112.0000,\n",
      "          164.7500,   71.0000,   -0.5000,   55.2000,    3.2500,  -11.7500,\n",
      "          -20.0000,   78.8000,  178.0000,   -3.0000,   -2.0000,    0.0000,\n",
      "          -10.5000,  -22.0000,  -12.5000,  -13.5000, -157.0000,    0.0000,\n",
      "         -276.0000, -144.2500,   32.2500,    1.6000,   50.0000,    6.6667,\n",
      "          -96.4000,  -43.7500, -127.2500, -120.8000,  -86.8000,  -89.3333,\n",
      "          -79.7500,   15.3333,   35.3333,  -50.0000,  -13.7500,   -7.7500]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_price_spread1_xs\n",
      "tensor([[0.2467, 0.1835, 0.1762, 0.1817, 0.2643, 0.2423, 0.2291, 0.2313, 0.2644,\n",
      "         0.2313, 0.2115, 0.2159, 0.1939, 0.2644, 0.1982, 0.2863, 0.1982, 0.1909,\n",
      "         0.2129, 0.2203, 0.1982, 0.2379, 0.2754, 0.1598, 0.2645, 0.3086, 0.2337,\n",
      "         0.1764, 0.2701, 0.2371, 0.1433, 0.1709, 0.2592, 0.1930, 0.2812, 0.4852,\n",
      "         0.2315, 0.3583, 0.3032, 0.2161, 0.1852, 0.2095, 0.4852, 0.3639, 0.3033,\n",
      "         0.2869, 0.2648, 0.2059, 0.1839, 0.1986, 0.1986, 0.2428, 0.2042, 0.1655,\n",
      "         0.1765, 0.3839, 0.2923, 0.3089, 0.2912, 0.1985, 0.2426, 0.2150, 0.2425,\n",
      "         0.2160, 0.2028, 0.2976, 0.1940, 0.3308, 0.3308, 0.2823, 0.2646, 0.2536,\n",
      "         0.2426, 0.2812, 0.2647, 0.1765, 0.1599, 0.1102, 0.3583, 0.2646, 0.2316,\n",
      "         0.2249, 0.4355, 0.3528, 0.3307, 0.3573, 0.2095, 0.2250, 0.2316, 0.3087,\n",
      "         0.2205, 0.2602, 0.3307, 0.2867, 0.2867, 0.2206, 0.2206, 0.2867, 0.2867,\n",
      "         0.3308, 0.2425, 0.2536, 0.2647, 0.2702, 0.2702, 0.2603, 0.0662, 0.0882,\n",
      "         0.2162, 0.2152, 0.3423, 0.3048, 0.2739, 0.2576, 0.2484, 0.3165, 0.3239,\n",
      "         0.3092, 0.2485, 0.2264]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_price_spread2_xs\n",
      "tensor([[0.3083, 0.2569, 0.2423, 0.2863, 0.4240, 0.4185, 0.3788, 0.3689, 0.3672,\n",
      "         0.2864, 0.2732, 0.2908, 0.3172, 0.3084, 0.2808, 0.3359, 0.3480, 0.3230,\n",
      "         0.3451, 0.3304, 0.3084, 0.3305, 0.3690, 0.3250, 0.3482, 0.3880, 0.2954,\n",
      "         0.2977, 0.4190, 0.3749, 0.2977, 0.3088, 0.3584, 0.3253, 0.4631, 0.6175,\n",
      "         0.4742, 0.5071, 0.4631, 0.4145, 0.4101, 0.3748, 0.6028, 0.5072, 0.4964,\n",
      "         0.4523, 0.3751, 0.3163, 0.2795, 0.2538, 0.2647, 0.2979, 0.2704, 0.2428,\n",
      "         0.2560, 0.4457, 0.4192, 0.4853, 0.5559, 0.3639, 0.3473, 0.3693, 0.4079,\n",
      "         0.3439, 0.2998, 0.3858, 0.3704, 0.5292, 0.5292, 0.3837, 0.3528, 0.3418,\n",
      "         0.3308, 0.5128, 0.3419, 0.2647, 0.2812, 0.3252, 0.5568, 0.3749, 0.2977,\n",
      "         0.3043, 0.5181, 0.4410, 0.4576, 0.4367, 0.2702, 0.3484, 0.3969, 0.4355,\n",
      "         0.3748, 0.4587, 0.4852, 0.3970, 0.3970, 0.3970, 0.3529, 0.3970, 0.3970,\n",
      "         0.4631, 0.3749, 0.4301, 0.4853, 0.4026, 0.3971, 0.3618, 0.2868, 0.2941,\n",
      "         0.4192, 0.3531, 0.5354, 0.3755, 0.3357, 0.3018, 0.3698, 0.5152, 0.5889,\n",
      "         0.4417, 0.3147, 0.2871]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_bid_spread_xs\n",
      "tensor([[0.3964, 0.4404, 0.4404, 0.3303, 0.2752, 0.4404, 0.4404, 0.5507, 0.4405,\n",
      "         0.3304, 0.3969, 0.5289, 0.7491, 0.2202, 0.3306, 0.2206, 1.0133, 1.1015,\n",
      "         0.8815, 0.8815, 0.8815, 0.2203, 0.5510, 0.7161, 0.2203, 0.5292, 0.2204,\n",
      "         0.2204, 1.1580, 0.9374, 0.4414, 0.7718, 0.2205, 0.2757, 1.0479, 0.6619,\n",
      "         1.9852, 0.3310, 0.9923, 1.1028, 0.7498, 0.5510, 0.5145, 0.9926, 1.1034,\n",
      "         0.9933, 0.8093, 0.5885, 0.4412, 0.3309, 0.4412, 0.2758, 0.4138, 0.5519,\n",
      "         0.5742, 0.3976, 0.6624, 0.2206, 1.6769, 0.6618, 0.6062, 0.8820, 0.9924,\n",
      "         0.6174, 0.5732, 0.6612, 1.2788, 0.2205, 0.2205, 0.3969, 0.6614, 0.6614,\n",
      "         0.6614, 1.0478, 0.3308, 0.5512, 0.6614, 1.0477, 0.6066, 0.2205, 0.2205,\n",
      "         0.5732, 0.6064, 0.6617, 0.7722, 0.4854, 0.2211, 0.6616, 0.8821, 0.6062,\n",
      "         0.8823, 0.9704, 0.8824, 0.8824, 0.8824, 0.2205, 0.2205, 0.2205, 0.4416,\n",
      "         0.6615, 0.6620, 0.7724, 0.8827, 0.7172, 0.8826, 0.2650, 1.5443, 1.5443,\n",
      "         0.4854, 0.9381, 0.6624, 0.2208, 0.2208, 0.2208, 0.7176, 1.6193, 0.9574,\n",
      "         1.1046, 0.4415, 0.3864]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_ask_spread_xs\n",
      "tensor([[0.2201, 0.2937, 0.2201, 0.7155, 1.3213, 1.3213, 1.0569, 0.8260, 0.5873,\n",
      "         0.2202, 0.2202, 0.2202, 0.4847, 0.2202, 0.4958, 0.2752, 0.4844, 0.2203,\n",
      "         0.4405, 0.2202, 0.2202, 0.7049, 0.3855, 0.9361, 0.6170, 0.2644, 0.3966,\n",
      "         0.9920, 0.3306, 0.4410, 1.1027, 0.6063, 0.7722, 1.0477, 0.7716, 0.6612,\n",
      "         0.4412, 1.1571, 0.6063, 0.8821, 1.4989, 1.1017, 0.6612, 0.4408, 0.8271,\n",
      "         0.6616, 0.2944, 0.5150, 0.5150, 0.2211, 0.2205, 0.2757, 0.2482, 0.2206,\n",
      "         0.2206, 0.2205, 0.6066, 1.5440, 0.9702, 0.9923, 0.4408, 0.6612, 0.6616,\n",
      "         0.6614, 0.3967, 0.2205, 0.4848, 1.7637, 1.7637, 0.6173, 0.2204, 0.2204,\n",
      "         0.2204, 1.2680, 0.4409, 0.3307, 0.5515, 1.1026, 1.3777, 0.8820, 0.4409,\n",
      "         0.2204, 0.2203, 0.2204, 0.4960, 0.3088, 0.3857, 0.5732, 0.7713, 0.6611,\n",
      "         0.6611, 1.0142, 0.6617, 0.2204, 0.2204, 1.5439, 1.1028, 0.8823, 0.6616,\n",
      "         0.6618, 0.6618, 0.9925, 1.3233, 0.6068, 0.3860, 0.7503, 0.6621, 0.5149,\n",
      "         1.5444, 0.4411, 1.2692, 0.4860, 0.3977, 0.2211, 0.4967, 0.3677, 1.6927,\n",
      "         0.2207, 0.2207, 0.2207]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_total_volume_xs\n",
      "tensor([[7.0309, 6.2653, 6.4536, 6.9670, 7.5380, 6.1377, 7.9356, 6.8617, 5.9738,\n",
      "         6.4877, 6.7581, 6.9295, 7.1538, 4.0775, 6.9866, 8.0020, 8.0449, 7.4685,\n",
      "         6.9315, 6.6958, 6.8459, 7.1808, 7.6401, 7.7558, 6.8200, 6.8896, 7.6658,\n",
      "         6.9575, 7.2086, 7.2800, 7.4512, 7.1982, 7.6113, 7.3402, 7.2034, 7.4343,\n",
      "         5.5568, 7.4372, 6.7811, 7.0379, 7.0527, 6.1026, 6.8512, 6.1841, 6.9866,\n",
      "         6.2577, 6.9660, 6.9949, 7.1025, 7.5486, 6.0426, 7.0148, 0.0000, 6.0039,\n",
      "         7.0992, 7.2485, 7.2086, 6.2166, 7.6192, 6.4877, 7.1808, 7.4691, 6.8035,\n",
      "         7.3746, 7.6540, 6.5028, 6.6412, 4.0943, 5.0752, 6.9508, 6.5073, 0.0000,\n",
      "         6.3333, 6.6053, 5.7900, 5.8021, 7.5262, 6.8669, 7.0344, 6.6067, 6.8565,\n",
      "         7.4110, 7.0344, 6.7811, 7.0493, 6.3491, 5.3423, 7.0951, 6.8669, 6.8835,\n",
      "         5.7961, 6.9037, 5.4337, 5.4765, 5.4806, 4.7958, 4.6151, 3.9512, 5.4510,\n",
      "         6.1985, 5.7071, 0.0000, 6.1026, 7.0758, 6.1985, 5.6937, 4.7095, 3.5553,\n",
      "         7.0510, 6.7238, 6.7499, 6.7923, 7.1884, 6.5876, 6.9670, 6.7105, 6.3404,\n",
      "         6.2672, 6.3784, 6.6107]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_volume_imbalance_xs\n",
      "tensor([[4.6653, 3.4012, 2.1203, 4.1271, 5.3193, 5.3613, 5.8236, 5.0783, 4.7958,\n",
      "         4.5951, 5.0814, 5.0626, 5.1510, 3.2581, 3.8011, 4.9090, 5.0999, 4.1795,\n",
      "         5.2983, 4.9200, 5.2149, 4.9185, 5.8615, 6.0426, 4.8520, 5.1705, 5.4116,\n",
      "         5.2730, 4.4886, 4.6492, 4.8579, 5.1090, 4.6347, 5.0073, 4.8422, 5.1084,\n",
      "         4.4067, 4.9541, 4.5747, 2.8565, 4.3360, 5.1818, 5.1259, 4.6052, 4.8922,\n",
      "         4.7600, 5.0106, 5.3327, 4.7391, 4.9921, 5.3230, 5.1676, 0.0000, 5.2933,\n",
      "         5.0739, 3.6376, 4.7493, 4.6151, 4.9459, 5.2832, 4.0818, 5.1874, 4.7791,\n",
      "         5.3538, 5.0408, 3.8607, 4.2370, 2.4849, 4.7185, 5.1240, 5.2815, 0.0000,\n",
      "         4.8203, 3.9120, 5.0752, 5.0689, 4.9505, 3.3759, 4.8363, 4.4514, 4.8847,\n",
      "         4.7005, 3.4177, 4.1217, 4.5191, 4.1141, 3.5115, 4.8828, 4.9955, 5.1075,\n",
      "         4.3944, 4.7808, 5.1985, 1.6094, 1.7918, 2.4849, 3.1781, 3.8286, 4.7185,\n",
      "         5.3107, 5.5491, 0.0000, 5.8777, 5.1417, 3.4095, 3.8330, 3.9512, 2.1203,\n",
      "         4.4864, 4.5512, 5.0830, 5.1108, 5.4170, 5.3246, 4.8714, 2.1972, 4.5609,\n",
      "         4.3086, 4.6821, 4.8866]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_money_turnover1_xs\n",
      "tensor([[2.1963, 1.9449, 1.9449, 4.6624, 5.5824, 4.6141, 5.3171, 2.3016, 1.3854,\n",
      "         4.3808, 1.7908, 1.7909, 1.7909, 1.0978, 3.3663, 5.7858, 4.6624, 4.6434,\n",
      "         4.1261, 4.1421, 1.3855, 2.0784, 5.3458, 5.7607, 4.7690, 1.9444, 4.6520,\n",
      "         1.7901, 5.4909, 6.0569, 1.6077, 1.7899, 6.0472, 5.3156, 5.1156, 5.2235,\n",
      "         1.0971, 5.5032, 4.6423, 3.3303, 3.8267, 1.0973, 4.6323, 3.2165, 5.1621,\n",
      "         1.6073, 5.3153, 1.3842, 1.3842, 1.7895, 1.0968, 4.6414, 0.0000, 1.0967,\n",
      "         1.7893, 4.7069, 5.3105, 4.6124, 5.4137, 4.6610, 5.9969, 4.7938, 5.3499,\n",
      "         1.7902, 3.2942, 4.9180, 1.7901, 0.6921, 0.6921, 2.3006, 2.7706, 0.0000,\n",
      "         4.8419, 1.6076, 1.0971, 1.3846, 5.9917, 5.9767, 5.1337, 4.5304, 4.5304,\n",
      "         5.6038, 6.0190, 4.6519, 1.6079, 1.9440, 3.5532, 1.9439, 4.8421, 4.5725,\n",
      "         4.6131, 2.3960, 0.6920, 4.5517, 4.5517, 1.3844, 1.0970, 1.0971, 1.3846,\n",
      "         1.0972, 0.6921, 0.0000, 3.0888, 5.4091, 4.2879, 1.7895, 1.0969, 1.3844,\n",
      "         4.7423, 1.6071, 3.9855, 2.6357, 2.6357, 3.2154, 4.6600, 5.5181, 3.8676,\n",
      "         1.3837, 3.3288, 1.6066]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0023]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id\n",
      "['9-633']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_id\n",
      "tensor([9.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds_in_bucket_xs\n",
      "tensor([[  5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,  60.,\n",
      "          65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115., 120.,\n",
      "         125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175., 180.,\n",
      "         185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235., 240.,\n",
      "         245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295., 300.,\n",
      "         305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355., 360.,\n",
      "         365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415., 420.,\n",
      "         425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475., 480.,\n",
      "         485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535., 540.,\n",
      "         545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595., 600.]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15084/2440942144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         )\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bsstonks\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "\n",
    "    \n",
    "dataloader_train = DataLoader(dataset, batch_size=1,\n",
    "                                shuffle=True, num_workers=0, pin_memory=False)#, collate_fn=optiver_custom_collate_func)\n",
    "# #             model.train()\n",
    "# i = 0\n",
    "# stockid = set()\n",
    "\n",
    "def feature_transform(feature_x, feature_name):\n",
    "        if feature_name in ['logrett_xs',\n",
    "                             'logret1_xs','logret2_xs','book_bid_spread_xs','book_ask_spread_xs']:\n",
    "            return feature_x * 10000\n",
    "        if feature_name in ['book_price_spread1_xs','book_price_spread2_xs']:\n",
    "            return feature_x * 1000\n",
    "        if feature_name in ['trade_ordercount_xs','trade_volume_xs','trade_money_turnover_xs','trade_money_turnover_per_order_xs',\n",
    "                             'book_total_volume_xs','book_volume_imbalance_xs','book_money_turnover1_xs']:\n",
    "            return torch.log(feature_x + 1)\n",
    "        return feature_x\n",
    "    \n",
    "for train_batch_idx, (Feature_X, feature_y) in enumerate(dataloader_train):\n",
    "    i += 1\n",
    "    for k,v in Feature_X.items():\n",
    "        print(k)\n",
    "        print(feature_transform(v,k))\n",
    "        input()\n",
    "    print(feature_y)\n",
    "    input()\n",
    "# batch = []\n",
    "# for idx in range(len(dataset)):\n",
    "#     batch.append(dataset[idx])\n",
    "#     if idx % 128 == 0:\n",
    "#         features_x = [x[0] for x in batch]\n",
    "#         features_y = [x[1] for x in batch]\n",
    "#         features_y = torch.tensor(features_y).reshape(-1,1)\n",
    "# #         print(features_y)\n",
    "# #         input()\n",
    "#         batch = []\n",
    "    \n",
    "#     y = feature_y.to(device) * output_scaling \n",
    "#     print(Feature_X['logret1_xs'].type())\n",
    "#     pred = model(Feature_X)\n",
    "#     print(pred.type())\n",
    "#     input()\n",
    "#     for stk in Feature_X['row_id']:\n",
    "        \n",
    "#         stockid.add(stk.split(\"-\")[0])\n",
    "# for i in range(len(dataset)-10):\n",
    "#     dataset[i]\n",
    "print(\"-->\", (time.time()-stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f03435-5cde-40bf-a86b-656ab4515ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce561c-5b64-44bf-882b-41f6250b1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated(device)/1024/1024/1024\n",
    "# model.to(\"cpu\")\n",
    "# torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966ee2c-8547-48be-a912-8d05bf48b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
