{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dade30-94ed-4d49-bb1e-553b91996bb0",
   "metadata": {},
   "source": [
    "## IMPUTE INSANITY!:\n",
    "### before we move onto neural networks we need to impute the NANs\n",
    "#### How do we even know we've correctly imputed?\n",
    "#### **Try out every impute methods and per feature set train the GBM and see which one got most importance**\n",
    "\n",
    "### TODO\n",
    "- #### [KNN , DeepLearner, other novel ways to impute](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779)\n",
    "  - KNN thoughts: we can perhaps use subset of features with no nans, but then the records will become similar, and decision trees already predict the same result for similar looking rows? then what's the point of imputing value same as similar looking rows?\n",
    "- ### DON't Impute rather provide the Flag wether the feature has value or not, kinda like mask; we did this in Optiver (not the transformer sequence mask , but we have mask about weather the second/grouped seconds is missing or not)\n",
    "  - #### [Results on passing information about missing values to neural networks](https://machinelearningmastery.com/binary-flags-for-missing-values-for-machine-learning/)\n",
    "- ### AMEND ABOVE: Impute as well as pass the missing Flag too, so neural network learns better\n",
    "- ### Categorical Imputation: train on data with missing categorical values as target variable! **We can even use TEST set to do this!!!! yay!**\n",
    "  - #### [Training to find missing categorical values](https://www.analyticsvidhya.com/blog/2021/04/how-to-handle-missing-values-of-categorical-variables/)\n",
    "\n",
    "### IMPORTANT FLOAT16 aggregations return NONE!!! mean, sum most of it doesn't work :-/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d809121-a984-441c-8885-a94938548420",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- ### MULTILEVEL IMPUTATION DEFAULT\n",
    "- ### LEVEL 1: out of all the variant+original; select the one with best amex scores DEFAULT_EMP1\n",
    "    - #### This is partial nans\n",
    "- ### Level 2: now that we have partial none df with best variants(including original with nans) ; TRAIN ML MODEL to have PREDICTED/BS variant\n",
    "    - #### In the order of lowest missing values to highest missing values\n",
    "    - #### we Target the feature with lowest amount on NAN as we have maximum training rows; then slowly cascade to more missing row features\n",
    "    - #### once we have computed PREDICTED/BS variants for all of the features with nans\n",
    "- ### Level 3: from DEFAULT_EMP1 vs PREDICTED variant select the one with maximum amex score (this is kinda like back to stage 1 but with improved train_df_wt)\n",
    "    - #### repetetively select and choose the best varint out of the two\n",
    "    - #### DEFAULT_EMP2 is generated!\n",
    "    - #### Now there is a scope of repeating Level 2 again with using base_df of EMP2 and then going to EMP3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799d3de7-7230-42ee-b699-26d02974f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHERE_THIS = \"local\" # local|kaggle\n",
    "\n",
    "BS_DATASET = \"amex-default-prediction-binarysentient\"\n",
    "if WHERE_THIS == \"kaggle\":\n",
    "    INPUT_PATH = \"/kaggle/input/amex-default-prediction/\"\n",
    "    OUTPUT_PATH = \"/kaggle/working/\"\n",
    "    TEMP_PATH = \"/kaggle/temp/\"\n",
    "elif WHERE_THIS == \"local\":\n",
    "    INPUT_PATH = \"input/amex-default-prediction/\"\n",
    "    OUTPUT_PATH = \"working/\"\n",
    "    TEMP_PATH = \"temp/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8e156e-282d-4a57-8738-46695bcc46cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/amex-default-prediction/sample_submission.csv\n",
      "input/amex-default-prediction/test_data.csv\n",
      "input/amex-default-prediction/train_data.csv\n",
      "input/amex-default-prediction/train_labels.csv\n",
      "input/amex-default-prediction/.ipynb_checkpoints\\sample_submission-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import display, HTML\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import plotly.express as pltex\n",
    "\n",
    "import impute_insanity\n",
    "from impute_insanity import load_prepare_amex_dataset\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(INPUT_PATH):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f240c1ff-1841-49f9-b7af-c868c9dd855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features = ['customer_ID']\n",
    "discard_features = ['D_66']\n",
    "datetime_features = ['S_2']\n",
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_68']\n",
    "target_features = ['target']\n",
    "numeric_features = ['R_2', 'S_25', 'D_118', 'B_5', 'D_60', 'B_21', 'D_115', 'S_15', 'D_84', 'D_122', 'B_9', 'B_33', 'D_53', 'R_24', 'D_94', 'D_56', 'D_139', 'R_28', 'B_3', 'S_20', 'B_31', 'D_133', 'B_2', 'S_12', 'D_71', 'D_96', 'S_7', 'D_72', 'B_36', 'B_41', 'S_5', 'D_41', 'R_22', 'R_8', 'D_140', 'D_47', 'D_89', 'P_2', 'R_19', 'D_59', 'B_23', 'S_3', 'D_145', 'D_103', 'B_19', 'R_20', 'D_73', 'D_136', 'D_141', 'D_142', 'B_22', 'D_46', 'B_29', 'B_25', 'D_128', 'B_18', 'D_86', 'D_109', 'B_8', 'B_17', 'R_17', 'B_12', 'D_54', 'D_74', 'S_16', 'B_6', 'D_49', 'D_80', 'S_8', 'B_7', 'D_144', 'B_27', 'B_26', 'R_25', 'R_23', 'D_82', 'D_111', 'B_10', 'D_113', 'R_4', 'D_48', 'R_26', 'S_23', 'B_11', 'D_104', 'D_134', 'D_79', 'P_3', 'D_132', 'D_137', 'D_135', 'B_28', 'D_88', 'S_13', 'D_51', 'D_61', 'D_75', 'D_69', 'R_16', 'S_6', 'S_17', 'D_93', 'B_20', 'D_112', 'D_123', 'D_130', 'B_1', 'D_78', 'D_92', 'S_27', 'D_44', 'B_16', 'R_5', 'D_43', 'S_18', 'B_15', 'D_39', 'D_50', 'D_55', 'S_9', 'D_105', 'D_70', 'R_18', 'D_125', 'D_58', 'S_24', 'D_110', 'D_42', 'R_6', 'D_81', 'R_7', 'D_138', 'D_52', 'R_27', 'D_124', 'D_45', 'D_91', 'D_108', 'S_22', 'B_14', 'D_83', 'R_13', 'D_87', 'S_19', 'D_131', 'R_21', 'B_40', 'R_3', 'D_65', 'B_13', 'D_129', 'D_119', 'B_32', 'R_9', 'B_24', 'D_127', 'D_106', 'D_102', 'R_1', 'R_14', 'B_37', 'D_107', 'R_15', 'R_12', 'P_4', 'R_10', 'customer_ID', 'D_121', 'R_11', 'S_11', 'D_76', 'D_143', 'B_39', 'B_42', 'D_62', 'B_4', 'S_26', 'D_77']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e62d91-78a3-44d5-a4dc-3697f03206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "## TODO: FAST AMEX implementation is not accurate; convert the dataframe accurate version to directly work with numpy arrays\n",
    "# @yunchonggan's fast metric implementation\n",
    "# From https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def fast_amex_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# Need Lightgbm supported eval metric\n",
    "#Custom eval function expects a callable with following signatures: func(y_true, y_pred), func(y_true, y_pred, weight) or func(y_true, y_pred, weight, group) and returns (eval_name, eval_result, is_higher_better) or list of (eval_name, eval_result, is_higher_better):\n",
    "def lgbm_eval_metric_amex(y_true, y_pred):\n",
    "    amex_metric = fast_amex_metric(y_true, y_pred)\n",
    "    return ('amex', amex_metric, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ccf182-f698-4fec-bd9b-d386027d57ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...     0.0\n",
       "1       00000fd6641609c6ece5454664794f0340ad84dddce9a2...     0.0\n",
       "2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...     0.0\n",
       "3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...     0.0\n",
       "4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...     0.0\n",
       "...                                                   ...     ...\n",
       "458908  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...     0.0\n",
       "458909  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...     0.0\n",
       "458910  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...     0.0\n",
       "458911  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...     1.0\n",
       "458912  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...     0.0\n",
       "\n",
       "[458913 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df = load_prepare_amex_dataset('train_labels')#, index_col='customer_ID')\n",
    "train_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09052bcc-5d49-4107-a017-2b27a1624677",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = train_label_df.copy()\n",
    "# prediction_labels['prediction'] = prediction_labels['target'] \n",
    "# prediction_labels['prediction'] = prediction_labels['target'] - 3\n",
    "prediction_labels['prediction'] = 1000\n",
    "del prediction_labels['target'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd1a55-95ff-4d87-9a34-c65d1dd30564",
   "metadata": {},
   "source": [
    "### Predictions impact on Evaluation Metric\n",
    "- #### all predictions 0 :   score 0.018829875288988086\n",
    "- #### all predictions 1 :   score 0.018829875288988086\n",
    "- #### all predictions 0.4 : score 0.018829875288988086\n",
    "- #### same as target      : score 1.0\n",
    "- #### target * 10         : score 1.0\n",
    "- #### target * 0.001      : score 1.0\n",
    "- #### target - 3          : score 1.0\n",
    "- #### target + 3          : score 1.0\n",
    "\n",
    "## The evaluation metrics is solid! amazing, need to understand more\n",
    "## TODO: FAST AMEX implementation is not accurate; convert the dataframe accurate version to directly work with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf09d96f-a3aa-4382-a65e-1a58c4588135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02260958442726859\n"
     ]
    }
   ],
   "source": [
    "## TODO: FAST AMEX implementation is not accurate; convert the dataframe accurate version to directly work with numpy arrays\n",
    "# print(amex_metric(train_labels, prediction_labels))\n",
    "print(fast_amex_metric(train_label_df['target'], prediction_labels['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33434f-4986-4a7b-8ac4-de48eb0052ed",
   "metadata": {},
   "source": [
    "## Precision impact on scores:\n",
    "\n",
    "### float32: 0.788541\n",
    "### float16: 0.788748, 0.788649, 0.788821\n",
    "### float64: 0.788276, 0.789053, 0.789025, 0.788543\n",
    "\n",
    "\n",
    "## Default\n",
    "\n",
    "## EMP1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959bc1be-77fe-42db-8dde-de902027aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_score_track = {}\n",
    "def track_score(key, score):\n",
    "    key = str(key)\n",
    "    if key not in fold_score_track:\n",
    "        fold_score_track[key] = []\n",
    "    fold_score_track[key].append(score)\n",
    "\n",
    "def show_score(key):\n",
    "    key = str(key)\n",
    "    display(HTML(f\"<h3>{key} OVERALL SCORE : {np.mean(fold_score_track[key]):0.6f}</h3>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da9083-1a02-4478-9a90-2c24146cc1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6368f18-9663-418e-84eb-413299e659fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lgbm_model_with_config(random_state=1, n_estimators=2400, importance_type=None, early_stopping_rounds=None):\n",
    "    \"\"\"\n",
    "    Creates model with our desired and some default hyper params\n",
    "    importance_type: split|gain\n",
    "    \"\"\"\n",
    "    if early_stopping_rounds is None:\n",
    "        early_stopping_rounds = n_estimators//10\n",
    "    return LGBMClassifier(n_estimators=n_estimators,\n",
    "                          learning_rate=0.03, reg_lambda=50,\n",
    "                          min_child_samples=2400,\n",
    "                          num_leaves=95, num_threads=12,\n",
    "                          colsample_bytree=0.19,early_stopping_rounds=early_stopping_rounds,\n",
    "                          max_bins=511, random_state=random_state, importance_type=importance_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381bb1be-dea6-48e3-adac-21b57db064fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test\n",
      "Computed avg test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:26: FutureWarning: Dropping invalid columns in DataFrameGroupBy.min is deprecated. In a future version, a TypeError will be raised. Before calling .min, select only columns which should be valid for the function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed min test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:33: FutureWarning: Dropping invalid columns in DataFrameGroupBy.max is deprecated. In a future version, a TypeError will be raised. Before calling .max, select only columns which should be valid for the function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed max test\n",
      "Computed last test\n",
      "test shape: (924621, 458)\n",
      "Read train\n",
      "Computed avg train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:26: FutureWarning: Dropping invalid columns in DataFrameGroupBy.min is deprecated. In a future version, a TypeError will be raised. Before calling .min, select only columns which should be valid for the function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed min train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:33: FutureWarning: Dropping invalid columns in DataFrameGroupBy.max is deprecated. In a future version, a TypeError will be raised. Before calling .max, select only columns which should be valid for the function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed max train\n",
      "Computed last train\n",
      "train shape: (458913, 458)\n",
      "target shape: (458913,)\n",
      "CPU times: total: 2min 53s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_avg = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_8', 'B_9', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_20', 'B_21', 'B_22', 'B_23', 'B_24', 'B_25', 'B_28', 'B_29', 'B_30', 'B_32', 'B_33', 'B_37', 'B_38', 'B_39', 'B_40', 'B_41', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_50', 'D_51', 'D_53', 'D_54', 'D_55', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_65', 'D_69', 'D_70', 'D_71', 'D_72', 'D_73', 'D_74', 'D_75', 'D_76', 'D_77', 'D_78', 'D_80', 'D_82', 'D_84', 'D_86', 'D_91', 'D_92', 'D_94', 'D_96', 'D_103', 'D_104', 'D_108', 'D_112', 'D_113', 'D_114', 'D_115', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_128', 'D_129', 'D_131', 'D_132', 'D_133', 'D_134', 'D_135', 'D_136', 'D_140', 'D_141', 'D_142', 'D_144', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_2', 'R_3', 'R_7', 'R_8', 'R_9', 'R_10', 'R_11', 'R_14', 'R_15', 'R_16', 'R_17', 'R_20', 'R_21', 'R_22', 'R_24', 'R_26', 'R_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_9', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_18', 'S_22', 'S_23', 'S_25', 'S_26']\n",
    "features_avg = list(set(features_avg).difference(set(cat_features)))\n",
    "features_min = ['B_2', 'B_4', 'B_5', 'B_9', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_19', 'B_20', 'B_28', 'B_29', 'B_33', 'B_36', 'B_42', 'D_39', 'D_41', 'D_42', 'D_45', 'D_46', 'D_48', 'D_50', 'D_51', 'D_53', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_62', 'D_70', 'D_71', 'D_74', 'D_75', 'D_78', 'D_83', 'D_102', 'D_112', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_122', 'D_128', 'D_132', 'D_140', 'D_141', 'D_144', 'D_145', 'P_2', 'P_3', 'R_1', 'R_27', 'S_3', 'S_5', 'S_7', 'S_9', 'S_11', 'S_12', 'S_23', 'S_25']\n",
    "features_min = list(set(features_min).difference(set(cat_features)))\n",
    "features_max = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9', 'B_10', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_21', 'B_23', 'B_24', 'B_25', 'B_29', 'B_30', 'B_33', 'B_37', 'B_38', 'B_39', 'B_40', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_52', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_63', 'D_64', 'D_65', 'D_70', 'D_71', 'D_72', 'D_73', 'D_74', 'D_76', 'D_77', 'D_78', 'D_80', 'D_82', 'D_84', 'D_91', 'D_102', 'D_105', 'D_107', 'D_110', 'D_111', 'D_112', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_128', 'D_131', 'D_132', 'D_133', 'D_134', 'D_135', 'D_136', 'D_138', 'D_140', 'D_141', 'D_142', 'D_144', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_3', 'R_5', 'R_6', 'R_7', 'R_8', 'R_10', 'R_11', 'R_14', 'R_17', 'R_20', 'R_26', 'R_27', 'S_3', 'S_5', 'S_7', 'S_8', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']\n",
    "features_max = list(set(features_max).difference(set(cat_features)))\n",
    "features_last = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_20', 'B_21', 'B_22', 'B_23', 'B_24', 'B_25', 'B_26', 'B_28', 'B_29', 'B_30', 'B_32', 'B_33', 'B_36', 'B_37', 'B_38', 'B_39', 'B_40', 'B_41', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_54', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_63', 'D_64', 'D_65', 'D_69', 'D_70', 'D_71', 'D_72', 'D_73', 'D_75', 'D_76', 'D_77', 'D_78', 'D_79', 'D_80', 'D_81', 'D_82', 'D_83', 'D_86', 'D_91', 'D_96', 'D_105', 'D_106', 'D_112', 'D_114', 'D_119', 'D_120', 'D_121', 'D_122', 'D_124', 'D_125', 'D_126', 'D_127', 'D_130', 'D_131', 'D_132', 'D_133', 'D_134', 'D_138', 'D_140', 'D_141', 'D_142', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_2', 'R_3', 'R_4', 'R_5', 'R_6', 'R_7', 'R_8', 'R_9', 'R_10', 'R_11', 'R_12', 'R_13', 'R_14', 'R_15', 'R_19', 'R_20', 'R_26', 'R_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9', 'S_11', 'S_12', 'S_13', 'S_16', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']\n",
    "features_last = list(set(features_last).union(set(cat_features)))\n",
    "for i in ['test', 'train']:\n",
    "    df = load_prepare_amex_dataset(f\"{i}_data_emp1\")\n",
    "    cid = pd.Categorical(df.pop('customer_ID'), ordered=True)\n",
    "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
    "    if 'target' in df.columns:\n",
    "        df.drop(columns=['target'], inplace=True)\n",
    "    gc.collect()\n",
    "    print('Read', i)\n",
    "    df_avg = (df\n",
    "              .groupby(cid)\n",
    "              .mean()[features_avg]\n",
    "              .rename(columns={f: f\"{f}_avg\" for f in features_avg})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed avg', i)\n",
    "    df_min = (df\n",
    "              .groupby(cid)\n",
    "              .min()[features_min]\n",
    "              .rename(columns={f: f\"{f}_min\" for f in features_min})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed min', i)\n",
    "    df_max = (df\n",
    "              .groupby(cid)\n",
    "              .max()[features_max]\n",
    "              .rename(columns={f: f\"{f}_max\" for f in features_max})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed max', i)\n",
    "    df = (df.loc[last, features_last]\n",
    "          .rename(columns={f: f\"{f}_last\" for f in features_last})\n",
    "          .set_index(np.asarray(cid[last]))\n",
    "         )\n",
    "    gc.collect()\n",
    "    print('Computed last', i)\n",
    "    df = pd.concat([df, df_min, df_max, df_avg], axis=1)\n",
    "    if i == 'train': df_train = df\n",
    "    else: df_test = df\n",
    "    print(f\"{i} shape: {df.shape}\")\n",
    "    del df, df_avg, df_min, df_max, cid, last\n",
    "\n",
    "target = load_prepare_amex_dataset('train_labels').target.values\n",
    "print(f\"target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d87c76-fb6f-48cf-82b5-f604a28692d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bs_features = load_prepare_amex_dataset(\"train_data_bs_features_extracted\")\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.rename(columns={'index':'customer_ID'})\n",
    "df_train = df_train.merge(df_train_bs_features, on=\"customer_ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00141891-c9ce-4cba-9afd-53314c7eb98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1ee1832-4c65-49ac-a7c8-8c4c8fe47971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c993ec9-6c06-4779-bd7b-58bb3519af66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>D_54_last</th>\n",
       "      <th>B_16_last</th>\n",
       "      <th>D_49_last</th>\n",
       "      <th>S_20_last</th>\n",
       "      <th>R_5_last</th>\n",
       "      <th>B_2_last</th>\n",
       "      <th>R_14_last</th>\n",
       "      <th>D_138_last</th>\n",
       "      <th>S_22_last</th>\n",
       "      <th>...</th>\n",
       "      <th>B_10_avg</th>\n",
       "      <th>B_1_avg</th>\n",
       "      <th>D_118_avg</th>\n",
       "      <th>D_121_avg</th>\n",
       "      <th>D_125_avg</th>\n",
       "      <th>D_94_avg</th>\n",
       "      <th>B_14_avg</th>\n",
       "      <th>D_122_avg</th>\n",
       "      <th>R_22_avg</th>\n",
       "      <th>B_17_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>1.008097</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.917811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270280</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.245514</td>\n",
       "      <td>0.711829</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.433732</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.932087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>1.002821</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.920889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298815</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.433039</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.290804</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.932087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>1.005992</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.302868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273711</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.354381</td>\n",
       "      <td>0.431903</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.147314</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.932087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>1.004073</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.931634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306553</td>\n",
       "      <td>0.059876</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.621386</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.324807</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.573924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.297843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100315</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.426588</td>\n",
       "      <td>0.550940</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.434149</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.932087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>1.009933</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>1.009866</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.948851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591469</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>0.160292</td>\n",
       "      <td>0.360471</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.108002</td>\n",
       "      <td>0.830225</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.932087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>1.008022</td>\n",
       "      <td>1.005743</td>\n",
       "      <td>0.021199</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.301055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042599</td>\n",
       "      <td>0.368335</td>\n",
       "      <td>0.563972</td>\n",
       "      <td>0.582941</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.086089</td>\n",
       "      <td>0.290629</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.883089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>1.002235</td>\n",
       "      <td>0.173585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>1.007023</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.986411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268444</td>\n",
       "      <td>0.043031</td>\n",
       "      <td>0.350878</td>\n",
       "      <td>0.406980</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>0.148788</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.422141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>1.003983</td>\n",
       "      <td>0.509407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.902168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039741</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>0.773797</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.008030</td>\n",
       "      <td>0.213409</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.375937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>1.003549</td>\n",
       "      <td>0.583801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.295251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256604</td>\n",
       "      <td>0.037961</td>\n",
       "      <td>0.023221</td>\n",
       "      <td>0.713941</td>\n",
       "      <td>0.465782</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.030458</td>\n",
       "      <td>0.367005</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.216813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  D_54_last  \\\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   1.008097   \n",
       "1       00000fd6641609c6ece5454664794f0340ad84dddce9a2...   1.002821   \n",
       "2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   1.005992   \n",
       "3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...   1.004073   \n",
       "4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...   1.007116   \n",
       "...                                                   ...        ...   \n",
       "458908  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...   1.009933   \n",
       "458909  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   1.008022   \n",
       "458910  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...   1.002235   \n",
       "458911  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...   1.003983   \n",
       "458912  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   1.003549   \n",
       "\n",
       "        B_16_last  D_49_last  S_20_last  R_5_last  B_2_last  R_14_last  \\\n",
       "0        0.006408        NaN   0.009411  0.009444  1.007647   0.002902   \n",
       "1        0.002940        NaN   0.009467  0.005880  1.004028   0.006271   \n",
       "2        0.007836        NaN   0.009926  0.003000  0.812649   0.002310   \n",
       "3        0.089177        NaN   0.007374  0.001347  1.006183   0.006133   \n",
       "4        0.005095        NaN   0.002803  0.008859  0.815746   0.006752   \n",
       "...           ...        ...        ...       ...       ...        ...   \n",
       "458908   0.000352        NaN   0.004142  0.001792  1.009866   0.003735   \n",
       "458909   1.005743   0.021199   0.007633  0.008006  0.055656   0.008819   \n",
       "458910   0.173585        NaN   0.007084  0.006079  1.007023   0.002009   \n",
       "458911   0.509407        NaN   0.004469  0.000409  0.714486   0.004916   \n",
       "458912   0.583801        NaN   0.009264  0.008112  0.992880   0.007238   \n",
       "\n",
       "        D_138_last  S_22_last  ...  B_10_avg   B_1_avg  D_118_avg  D_121_avg  \\\n",
       "0         0.164614   0.917811  ...  0.270280  0.012007   0.245514   0.711829   \n",
       "1         0.164614   0.920889  ...  0.298815  0.025654   0.433039   0.535892   \n",
       "2         0.164614   0.302868  ...  0.273711  0.004386   0.354381   0.431903   \n",
       "3         0.164614   0.931634  ...  0.306553  0.059876   0.048511   0.621386   \n",
       "4         0.164614   0.297843  ...  0.100315  0.005941   0.426588   0.550940   \n",
       "...            ...        ...  ...       ...       ...        ...        ...   \n",
       "458908    0.164614   0.948851  ...  0.591469  0.029180   0.160292   0.360471   \n",
       "458909    0.164614   0.301055  ...  0.042599  0.368335   0.563972   0.582941   \n",
       "458910    0.164614   0.986411  ...  0.268444  0.043031   0.350878   0.406980   \n",
       "458911    0.164614   0.902168  ...  0.039741  0.018161   0.038328   0.713475   \n",
       "458912    0.164614   0.295251  ...  0.256604  0.037961   0.023221   0.713941   \n",
       "\n",
       "        D_125_avg  D_94_avg  B_14_avg  D_122_avg  R_22_avg  B_17_avg  \n",
       "0        0.006253  0.005909  0.023142   0.433732  0.005002  0.932087  \n",
       "1        0.004236  0.005067  0.014848   0.290804  0.003541  0.932087  \n",
       "2        0.004741  0.004365  0.004729   0.147314  0.005015  0.932087  \n",
       "3        0.004309  0.004629  0.033350   0.324807  0.005413  0.573924  \n",
       "4        0.004640  0.005482  0.004924   0.434149  0.005027  0.932087  \n",
       "...           ...       ...       ...        ...       ...       ...  \n",
       "458908   0.005373  0.004145  0.108002   0.830225  0.004286  0.932087  \n",
       "458909   0.004042  0.005473  0.086089   0.290629  0.003844  0.883089  \n",
       "458910   0.005318  0.003546  0.033282   0.148788  0.004572  0.422141  \n",
       "458911   0.773797  0.004620  0.008030   0.213409  0.006008  0.375937  \n",
       "458912   0.465782  0.004476  0.030458   0.367005  0.005968  0.216813  \n",
       "\n",
       "[458913 rows x 459 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e248add2-6338-43c3-a364-f09d7612b5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3608451e-1569-4a8c-a4be-6be2ed1f6c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data nan 122\n",
      "train_data_emp1 nan 51\n",
      "test_data nan 121\n",
      "test_data_emp1 nan 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in ['train_data','train_data_emp1', 'test_data','test_data_emp1']:\n",
    "    df = load_prepare_amex_dataset(dataset)\n",
    "    nanmap = df.isna().sum().reset_index().rename({'index':'feature',0:'nan_count'}, axis=1).to_dict('records')\n",
    "    print(dataset, \"nan\", len([x for x in nanmap if x['nan_count']>0]))\n",
    "    del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a0622f8c-3f1e-45e7-af4f-d611bd8943b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data nan 122\n",
      "train_data_emp1 nan 35\n",
      "test_data nan 121\n",
      "test_data_emp1 nan 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in ['train_data','train_data_emp1', 'test_data','test_data_emp1']:\n",
    "    df = load_prepare_amex_dataset(dataset)\n",
    "    nanmap = df.isna().sum().reset_index().rename({'index':'feature',0:'nan_count'}, axis=1).to_dict('records')\n",
    "    print(dataset, \"nan\", len([x for x in nanmap if x['nan_count']>0]))\n",
    "    del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166adb4-de23-43f3-aa6f-b17ac7d71b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ FOLD: 1 of 5 -------\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] early_stopping_round is set=240, early_stopping_rounds=240 will be ignored. Current value: early_stopping_round=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.229371\tvalid_0's amex: 0.789217\n",
      "[200]\tvalid_0's binary_logloss: 0.217675\tvalid_0's amex: 0.79362\n",
      "[300]\tvalid_0's binary_logloss: 0.215718\tvalid_0's amex: 0.796506\n",
      "[400]\tvalid_0's binary_logloss: 0.214954\tvalid_0's amex: 0.798333\n",
      "[500]\tvalid_0's binary_logloss: 0.214507\tvalid_0's amex: 0.798791\n",
      "[600]\tvalid_0's binary_logloss: 0.214172\tvalid_0's amex: 0.79891\n",
      "[700]\tvalid_0's binary_logloss: 0.213963\tvalid_0's amex: 0.799214\n",
      "[800]\tvalid_0's binary_logloss: 0.213758\tvalid_0's amex: 0.798849\n",
      "[900]\tvalid_0's binary_logloss: 0.213657\tvalid_0's amex: 0.799415\n",
      "[1000]\tvalid_0's binary_logloss: 0.213672\tvalid_0's amex: 0.799898\n",
      "[1100]\tvalid_0's binary_logloss: 0.213637\tvalid_0's amex: 0.799686\n",
      "[1200]\tvalid_0's binary_logloss: 0.21361\tvalid_0's amex: 0.799702\n",
      "[1300]\tvalid_0's binary_logloss: 0.213616\tvalid_0's amex: 0.800107\n",
      "[1400]\tvalid_0's binary_logloss: 0.21364\tvalid_0's amex: 0.799435\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Fold 1 | 03:50 |  1221 trees |                Score = 0.79963 | Importance: Gain</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "------ FOLD: 2 of 5 -------\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] early_stopping_round is set=240, early_stopping_rounds=240 will be ignored. Current value: early_stopping_round=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.229027\tvalid_0's amex: 0.78596\n",
      "[200]\tvalid_0's binary_logloss: 0.216973\tvalid_0's amex: 0.791281\n",
      "[300]\tvalid_0's binary_logloss: 0.215037\tvalid_0's amex: 0.794386\n",
      "[400]\tvalid_0's binary_logloss: 0.214163\tvalid_0's amex: 0.795467\n",
      "[500]\tvalid_0's binary_logloss: 0.213653\tvalid_0's amex: 0.796625\n",
      "[600]\tvalid_0's binary_logloss: 0.213383\tvalid_0's amex: 0.796988\n",
      "[700]\tvalid_0's binary_logloss: 0.213184\tvalid_0's amex: 0.798296\n",
      "[800]\tvalid_0's binary_logloss: 0.212948\tvalid_0's amex: 0.797644\n",
      "[900]\tvalid_0's binary_logloss: 0.212885\tvalid_0's amex: 0.798003\n",
      "[1000]\tvalid_0's binary_logloss: 0.212812\tvalid_0's amex: 0.79814\n",
      "[1100]\tvalid_0's binary_logloss: 0.212814\tvalid_0's amex: 0.798291\n",
      "[1200]\tvalid_0's binary_logloss: 0.212825\tvalid_0's amex: 0.798442\n",
      "[1300]\tvalid_0's binary_logloss: 0.212899\tvalid_0's amex: 0.798592\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Fold 2 | 03:38 |  1070 trees |                Score = 0.79813 | Importance: Gain</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "------ FOLD: 3 of 5 -------\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] early_stopping_round is set=240, early_stopping_rounds=240 will be ignored. Current value: early_stopping_round=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.229086\tvalid_0's amex: 0.788911\n",
      "[200]\tvalid_0's binary_logloss: 0.217246\tvalid_0's amex: 0.793242\n",
      "[300]\tvalid_0's binary_logloss: 0.215267\tvalid_0's amex: 0.794015\n",
      "[400]\tvalid_0's binary_logloss: 0.214489\tvalid_0's amex: 0.795346\n",
      "[500]\tvalid_0's binary_logloss: 0.214052\tvalid_0's amex: 0.797026\n",
      "[600]\tvalid_0's binary_logloss: 0.213784\tvalid_0's amex: 0.797119\n",
      "[700]\tvalid_0's binary_logloss: 0.213638\tvalid_0's amex: 0.797273\n",
      "[800]\tvalid_0's binary_logloss: 0.213586\tvalid_0's amex: 0.797332\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Fold 3 | 02:27 |   642 trees |                Score = 0.79794 | Importance: Gain</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "------ FOLD: 4 of 5 -------\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] early_stopping_round is set=240, early_stopping_rounds=240 will be ignored. Current value: early_stopping_round=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.230773\tvalid_0's amex: 0.785932\n",
      "[200]\tvalid_0's binary_logloss: 0.219102\tvalid_0's amex: 0.791125\n",
      "[300]\tvalid_0's binary_logloss: 0.217228\tvalid_0's amex: 0.79339\n",
      "[400]\tvalid_0's binary_logloss: 0.216395\tvalid_0's amex: 0.793881\n",
      "[500]\tvalid_0's binary_logloss: 0.215961\tvalid_0's amex: 0.795143\n",
      "[600]\tvalid_0's binary_logloss: 0.215565\tvalid_0's amex: 0.795075\n",
      "[700]\tvalid_0's binary_logloss: 0.21541\tvalid_0's amex: 0.794899\n",
      "[800]\tvalid_0's binary_logloss: 0.215275\tvalid_0's amex: 0.795216\n",
      "[900]\tvalid_0's binary_logloss: 0.215199\tvalid_0's amex: 0.796085\n",
      "[1000]\tvalid_0's binary_logloss: 0.215195\tvalid_0's amex: 0.796199\n",
      "[1100]\tvalid_0's binary_logloss: 0.215155\tvalid_0's amex: 0.795775\n",
      "[1200]\tvalid_0's binary_logloss: 0.215161\tvalid_0's amex: 0.79582\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Fold 4 | 03:15 |  1002 trees |                Score = 0.79647 | Importance: Gain</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "------ FOLD: 5 of 5 -------\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] early_stopping_round is set=240, early_stopping_rounds=240 will be ignored. Current value: early_stopping_round=240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\nisha\\miniconda3\\envs\\kaggle\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.23205\tvalid_0's amex: 0.782182\n",
      "[200]\tvalid_0's binary_logloss: 0.221194\tvalid_0's amex: 0.785679\n",
      "[300]\tvalid_0's binary_logloss: 0.219522\tvalid_0's amex: 0.787362\n",
      "[400]\tvalid_0's binary_logloss: 0.218911\tvalid_0's amex: 0.78842\n",
      "[500]\tvalid_0's binary_logloss: 0.218456\tvalid_0's amex: 0.789408\n",
      "[600]\tvalid_0's binary_logloss: 0.218158\tvalid_0's amex: 0.789687\n",
      "[700]\tvalid_0's binary_logloss: 0.218025\tvalid_0's amex: 0.789803\n",
      "[800]\tvalid_0's binary_logloss: 0.217957\tvalid_0's amex: 0.789905\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Fold 5 | 02:09 |   581 trees |                Score = 0.79051 | Importance: Gain</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>['D_54_last', 'B_16_last', 'D_49_last', 'S_20_last', 'R_5_last', 'B_2_last', 'R_14_last', 'D_138_last', 'S_22_last', 'B_33_last', 'D_51_last', 'D_53_last', 'B_24_last', 'R_1_last', 'S_16_last', 'R_15_last', 'R_26_last', 'D_45_last', 'D_80_last', 'B_41_last', 'D_83_last', 'S_12_last', 'D_114_last', 'D_69_last', 'D_81_last', 'S_9_last', 'S_26_last', 'D_61_last', 'R_6_last', 'R_20_last', 'B_39_last', 'D_116_last', 'B_5_last', 'D_82_last', 'D_145_last', 'R_4_last', 'D_140_last', 'D_60_last', 'B_30_last', 'B_29_last', 'R_10_last', 'D_52_last', 'D_127_last', 'D_71_last', 'P_4_last', 'D_119_last', 'D_48_last', 'D_70_last', 'D_96_last', 'B_12_last', 'S_23_last', 'S_25_last', 'B_7_last', 'D_47_last', 'R_27_last', 'D_120_last', 'B_40_last', 'D_142_last', 'B_25_last', 'D_117_last', 'D_56_last', 'D_79_last', 'D_77_last', 'B_4_last', 'D_72_last', 'R_8_last', 'D_112_last', 'D_59_last', 'R_2_last', 'P_2_last', 'R_7_last', 'B_23_last', 'D_106_last', 'D_65_last', 'R_13_last', 'D_76_last', 'R_12_last', 'D_78_last', 'B_42_last', 'B_32_last', 'D_141_last', 'S_27_last', 'S_24_last', 'B_37_last', 'D_86_last', 'S_13_last', 'B_18_last', 'S_7_last', 'P_3_last', 'D_42_last', 'S_6_last', 'D_133_last', 'D_73_last', 'D_105_last', 'B_9_last', 'B_15_last', 'S_5_last', 'R_3_last', 'D_131_last', 'B_22_last', 'D_134_last', 'D_43_last', 'B_19_last', 'D_68_last', 'D_55_last', 'B_6_last', 'D_58_last', 'S_11_last', 'D_126_last', 'D_124_last', 'D_62_last', 'B_21_last', 'D_39_last', 'B_28_last', 'D_132_last', 'B_26_last', 'B_3_last', 'R_9_last', 'B_20_last', 'D_50_last', 'S_19_last', 'D_44_last', 'D_63_last', 'S_8_last', 'D_91_last', 'D_130_last', 'S_3_last', 'B_38_last', 'B_8_last', 'D_46_last', 'D_75_last', 'R_11_last', 'B_11_last', 'D_41_last', 'B_13_last', 'B_36_last', 'B_10_last', 'R_19_last', 'B_1_last', 'D_64_last', 'D_121_last', 'D_125_last', 'B_14_last', 'D_122_last', 'B_17_last', 'B_29_min', 'B_16_min', 'D_39_min', 'B_2_min', 'S_11_min', 'B_28_min', 'D_71_min', 'D_132_min', 'D_78_min', 'B_20_min', 'B_42_min', 'B_33_min', 'D_50_min', 'D_51_min', 'D_53_min', 'D_102_min', 'D_119_min', 'D_48_min', 'D_128_min', 'D_70_min', 'D_141_min', 'D_144_min', 'R_1_min', 'D_45_min', 'S_23_min', 'S_7_min', 'P_3_min', 'D_42_min', 'S_25_min', 'R_27_min', 'S_3_min', 'D_83_min', 'S_12_min', 'D_46_min', 'S_9_min', 'D_75_min', 'D_41_min', 'B_9_min', 'B_13_min', 'B_15_min', 'S_5_min', 'B_36_min', 'B_5_min', 'D_115_min', 'D_113_min', 'D_56_min', 'D_62_min', 'B_19_min', 'D_145_min', 'B_4_min', 'D_59_min', 'D_118_min', 'D_121_min', 'D_140_min', 'D_74_min', 'D_55_min', 'D_60_min', 'D_112_min', 'D_58_min', 'B_14_min', 'D_122_min', 'P_2_min', 'B_17_min', 'B_16_max', 'D_49_max', 'D_65_max', 'R_5_max', 'B_2_max', 'R_14_max', 'D_76_max', 'D_138_max', 'D_78_max', 'S_22_max', 'B_33_max', 'D_102_max', 'B_42_max', 'B_24_max', 'D_141_max', 'S_27_max', 'S_24_max', 'R_1_max', 'B_37_max', 'S_16_max', 'R_26_max', 'D_45_max', 'S_13_max', 'B_18_max', 'S_7_max', 'P_3_max', 'D_42_max', 'D_135_max', 'D_133_max', 'D_80_max', 'S_12_max', 'D_73_max', 'S_26_max', 'D_105_max', 'D_61_max', 'R_6_max', 'R_20_max', 'B_9_max', 'B_39_max', 'B_15_max', 'S_5_max', 'R_3_max', 'D_131_max', 'B_5_max', 'D_134_max', 'D_82_max', 'D_115_max', 'D_43_max', 'D_145_max', 'B_19_max', 'S_15_max', 'D_140_max', 'D_136_max', 'D_60_max', 'D_55_max', 'D_111_max', 'B_6_max', 'D_84_max', 'D_58_max', 'S_11_max', 'D_124_max', 'B_14_max', 'B_29_max', 'R_10_max', 'B_21_max', 'D_39_max', 'D_52_max', 'D_110_max', 'D_132_max', 'D_71_max', 'B_3_max', 'D_50_max', 'P_4_max', 'D_119_max', 'D_128_max', 'D_48_max', 'D_70_max', 'D_144_max', 'D_44_max', 'B_12_max', 'S_23_max', 'S_8_max', 'S_25_max', 'B_7_max', 'D_47_max', 'R_27_max', 'D_91_max', 'S_3_max', 'B_40_max', 'D_142_max', 'B_8_max', 'D_46_max', 'B_25_max', 'R_11_max', 'D_41_max', 'B_13_max', 'B_10_max', 'B_1_max', 'D_56_max', 'D_77_max', 'B_4_max', 'D_72_max', 'R_8_max', 'D_59_max', 'D_118_max', 'D_74_max', 'R_17_max', 'D_112_max', 'D_121_max', 'D_125_max', 'D_123_max', 'D_122_max', 'R_7_max', 'P_2_max', 'D_107_max', 'B_23_max', 'B_17_max', 'D_54_avg', 'B_16_avg', 'B_2_avg', 'R_14_avg', 'S_22_avg', 'B_33_avg', 'D_51_avg', 'D_53_avg', 'B_24_avg', 'R_1_avg', 'S_16_avg', 'R_15_avg', 'R_26_avg', 'D_45_avg', 'D_80_avg', 'B_41_avg', 'S_12_avg', 'D_69_avg', 'S_9_avg', 'S_26_avg', 'D_61_avg', 'R_20_avg', 'B_39_avg', 'B_5_avg', 'D_82_avg', 'D_145_avg', 'D_140_avg', 'D_60_avg', 'D_108_avg', 'B_29_avg', 'R_10_avg', 'R_24_avg', 'D_71_avg', 'P_4_avg', 'D_119_avg', 'D_128_avg', 'D_48_avg', 'D_70_avg', 'D_144_avg', 'D_96_avg', 'B_12_avg', 'S_23_avg', 'S_25_avg', 'D_47_avg', 'R_27_avg', 'B_40_avg', 'D_142_avg', 'B_25_avg', 'D_77_avg', 'B_4_avg', 'D_72_avg', 'R_8_avg', 'D_74_avg', 'R_17_avg', 'D_112_avg', 'D_59_avg', 'D_123_avg', 'R_2_avg', 'P_2_avg', 'R_7_avg', 'S_18_avg', 'B_23_avg', 'D_65_avg', 'D_76_avg', 'R_21_avg', 'D_78_avg', 'B_42_avg', 'B_32_avg', 'D_141_avg', 'B_37_avg', 'D_86_avg', 'S_13_avg', 'B_18_avg', 'S_7_avg', 'P_3_avg', 'D_42_avg', 'D_135_avg', 'S_6_avg', 'D_133_avg', 'D_73_avg', 'D_92_avg', 'B_9_avg', 'B_15_avg', 'R_16_avg', 'R_3_avg', 'D_131_avg', 'S_5_avg', 'B_22_avg', 'D_134_avg', 'D_115_avg', 'D_113_avg', 'D_43_avg', 'B_19_avg', 'S_15_avg', 'D_136_avg', 'D_55_avg', 'B_6_avg', 'D_84_avg', 'D_58_avg', 'S_11_avg', 'D_124_avg', 'D_62_avg', 'B_21_avg', 'D_39_avg', 'B_28_avg', 'D_132_avg', 'B_3_avg', 'R_9_avg', 'B_20_avg', 'D_50_avg', 'D_104_avg', 'D_103_avg', 'D_44_avg', 'D_129_avg', 'D_91_avg', 'S_3_avg', 'B_8_avg', 'D_46_avg', 'D_75_avg', 'R_11_avg', 'B_11_avg', 'D_41_avg', 'B_13_avg', 'B_10_avg', 'B_1_avg', 'D_118_avg', 'D_121_avg', 'D_125_avg', 'D_94_avg', 'B_14_avg', 'D_122_avg', 'R_22_avg', 'B_17_avg', 'bs_0', 'bs_1', 'bs_2', 'bs_3', 'bs_4', 'bs_5', 'bs_6', 'bs_7', 'bs_8', 'bs_9', 'bs_10', 'bs_11', 'bs_12', 'bs_13', 'bs_14', 'bs_15', 'bs_16', 'bs_17', 'bs_18', 'bs_19', 'bs_20', 'bs_21', 'bs_22', 'bs_23', 'bs_24', 'bs_25', 'bs_26', 'bs_27', 'bs_28', 'bs_29', 'bs_30', 'bs_31', 'bs_32', 'bs_33', 'bs_34', 'bs_35', 'bs_36', 'bs_37', 'bs_38', 'bs_39', 'bs_40', 'bs_41', 'bs_42', 'bs_43', 'bs_44', 'bs_45', 'bs_46', 'bs_47', 'bs_48', 'bs_49', 'bs_50', 'bs_51', 'bs_52', 'bs_53', 'bs_54', 'bs_55', 'bs_56', 'bs_57', 'bs_58', 'bs_59', 'bs_60', 'bs_61', 'bs_62', 'bs_63', 'bs_64', 'bs_65', 'bs_66', 'bs_67', 'bs_68', 'bs_69', 'bs_70', 'bs_71', 'bs_72', 'bs_73', 'bs_74', 'bs_75', 'bs_76', 'bs_77', 'bs_78', 'bs_79', 'bs_80', 'bs_81', 'bs_82', 'bs_83', 'bs_84', 'bs_85', 'bs_86', 'bs_87', 'bs_88', 'bs_89', 'bs_90', 'bs_91', 'bs_92', 'bs_93', 'bs_94', 'bs_95', 'bs_96', 'bs_97', 'bs_98', 'bs_99', 'bs_100', 'bs_101', 'bs_102', 'bs_103', 'bs_104', 'bs_105', 'bs_106', 'bs_107', 'bs_108', 'bs_109', 'bs_110', 'bs_111', 'bs_112', 'bs_113', 'bs_114', 'bs_115', 'bs_116', 'bs_117', 'bs_118', 'bs_119', 'bs_120', 'bs_121', 'bs_122', 'bs_123', 'bs_124', 'bs_125', 'bs_126', 'bs_127', 'bs_128', 'bs_129', 'bs_130', 'bs_131', 'bs_132', 'bs_133', 'bs_134', 'bs_135', 'bs_136', 'bs_137', 'bs_138', 'bs_139', 'bs_140', 'bs_141', 'bs_142', 'bs_143', 'bs_144', 'bs_145', 'bs_146', 'bs_147', 'bs_148', 'bs_149', 'bs_150', 'bs_151', 'bs_152', 'bs_153', 'bs_154', 'bs_155', 'bs_156', 'bs_157', 'bs_158', 'bs_159', 'bs_160', 'bs_161', 'bs_162', 'bs_163', 'bs_164', 'bs_165', 'bs_166', 'bs_167', 'bs_168', 'bs_169', 'bs_170', 'bs_171', 'bs_172', 'bs_173', 'bs_174', 'bs_175', 'bs_176', 'bs_177', 'bs_178', 'bs_179', 'bs_180', 'bs_181', 'bs_182', 'bs_183', 'bs_184', 'bs_185', 'bs_186', 'bs_187', 'bs_188', 'bs_189', 'bs_190', 'bs_191', 'bs_192', 'bs_193', 'bs_194', 'bs_195', 'bs_196', 'bs_197', 'bs_198', 'bs_199', 'bs_200', 'bs_201', 'bs_202', 'bs_203', 'bs_204', 'bs_205', 'bs_206', 'bs_207', 'bs_208', 'bs_209', 'bs_210', 'bs_211', 'bs_212', 'bs_213', 'bs_214', 'bs_215', 'bs_216', 'bs_217', 'bs_218', 'bs_219', 'bs_220', 'bs_221', 'bs_222', 'bs_223', 'bs_224', 'bs_225', 'bs_226', 'bs_227', 'bs_228', 'bs_229', 'bs_230', 'bs_231', 'bs_232', 'bs_233', 'bs_234', 'bs_235', 'bs_236', 'bs_237', 'bs_238', 'bs_239', 'bs_240', 'bs_241', 'bs_242', 'bs_243', 'bs_244', 'bs_245', 'bs_246', 'bs_247', 'bs_248', 'bs_249', 'bs_250', 'bs_251', 'bs_252', 'bs_253', 'bs_254', 'bs_255', 'bs_256', 'bs_257', 'bs_258', 'bs_259', 'bs_260', 'bs_261', 'bs_262', 'bs_263', 'bs_264', 'bs_265', 'bs_266', 'bs_267', 'bs_268', 'bs_269', 'bs_270', 'bs_271', 'bs_272', 'bs_273', 'bs_274', 'bs_275', 'bs_276', 'bs_277', 'bs_278', 'bs_279', 'bs_280', 'bs_281', 'bs_282', 'bs_283', 'bs_284', 'bs_285', 'bs_286', 'bs_287', 'bs_288', 'bs_289', 'bs_290', 'bs_291', 'bs_292', 'bs_293', 'bs_294', 'bs_295', 'bs_296', 'bs_297', 'bs_298', 'bs_299', 'bs_300', 'bs_301', 'bs_302', 'bs_303', 'bs_304', 'bs_305', 'bs_306', 'bs_307', 'bs_308', 'bs_309', 'bs_310', 'bs_311', 'bs_312', 'bs_313', 'bs_314', 'bs_315', 'bs_316', 'bs_317', 'bs_318', 'bs_319', 'bs_320', 'bs_321', 'bs_322', 'bs_323', 'bs_324', 'bs_325', 'bs_326', 'bs_327', 'bs_328', 'bs_329', 'bs_330', 'bs_331', 'bs_332', 'bs_333', 'bs_334', 'bs_335', 'bs_336', 'bs_337', 'bs_338', 'bs_339', 'bs_340', 'bs_341', 'bs_342', 'bs_343', 'bs_344', 'bs_345', 'bs_346', 'bs_347', 'bs_348', 'bs_349', 'bs_350', 'bs_351', 'bs_352', 'bs_353', 'bs_354', 'bs_355', 'bs_356', 'bs_357', 'bs_358', 'bs_359', 'bs_360', 'bs_361', 'bs_362', 'bs_363', 'bs_364', 'bs_365', 'bs_366', 'bs_367', 'bs_368', 'bs_369', 'bs_370', 'bs_371', 'bs_372', 'bs_373', 'bs_374', 'bs_375', 'bs_376', 'bs_377', 'bs_378', 'bs_379', 'bs_380', 'bs_381', 'bs_382', 'bs_383', 'bs_384', 'bs_385', 'bs_386', 'bs_387', 'bs_388', 'bs_389', 'bs_390', 'bs_391', 'bs_392', 'bs_393', 'bs_394', 'bs_395'] OVERALL SCORE : 0.796536</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 57min 21s\n",
      "Wall time: 15min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# variant_df = variant_df[reversed(list(variant_df.columns))]\n",
    "# we keep this copy so that original feature doens't stay on top!!!\n",
    "# it's some weird quirk i found\n",
    "# variant_df[missingvaluefeature+\"_COPY\"] = variant_df[missingvaluefeature]\n",
    "# del variant_df[missingvaluefeature]\n",
    "features_x = [f for f in df_train.columns if f != 'customer_ID' and f != 'target' and f!='S_2']\n",
    "feature_y = 'target'\n",
    "# df_x = df_train[features_x]\n",
    "# df_y = df_train_wt[feature_y]\n",
    "# target =\n",
    "\n",
    "total_splits = 5\n",
    "kf = StratifiedKFold(n_splits=total_splits, shuffle=True)\n",
    "fold_scores = []\n",
    "models = []\n",
    "# NOT TOO SURE about feature_importances when all features are variants!! it's non decisive\n",
    "for fold, (idx_train, idx_dev) in enumerate(kf.split(df_train, target)):\n",
    "    print(f\"------ FOLD: {fold+1} of {total_splits} -------\")\n",
    "    train_x, dev_x, train_y, dev_y, model = None, None, None, None, None\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    X_tr = df_train.iloc[idx_train][features_x]\n",
    "    X_va = df_train.iloc[idx_dev][features_x]\n",
    "    y_tr = target[idx_train]\n",
    "    y_va = target[idx_dev]\n",
    "   \n",
    "    model = create_lgbm_model_with_config(importance_type='gain')\n",
    "    model.fit(X_tr, y_tr,\n",
    "                  eval_set = [(X_va, y_va)], \n",
    "                  eval_metric=[lgbm_eval_metric_amex],\n",
    "                  callbacks=[log_evaluation(100)])\n",
    "\n",
    "    y_va_pred = model.predict_proba(X_va, raw_score=True)\n",
    "    score = fast_amex_metric(y_va, y_va_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: n_trees = model.n_estimators\n",
    "    print(\"-------------------------------------\")\n",
    "    display(HTML(f\"<h3>Fold {fold+1} | {str(datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f} | Importance: Gain</h3>\"))\n",
    "    print(\"-------------------------------------\")\n",
    "    # fold_scores.append(score)\n",
    "    track_score(features_x, score)\n",
    "    models.append(model)\n",
    "    # feature_importance_tuples = sorted(zip(X_tr.columns,model.feature_importances_), key=lambda x:x[1])\n",
    "    # # feature_importance_tuples = sorted(zip(X_tr.columns,model.feature_importance(importance_type='gain')), key=lambda x:x[1])\n",
    "    # feature_importance_map = {k:v for k,v in feature_importance_tuples}\n",
    "    # feature_imp = pd.DataFrame(feature_importance_tuples, columns=['feature','importance'])\n",
    "    # fig = pltex.bar(feature_imp, x='importance', y='feature', height=500)\n",
    "    # fig.show()\n",
    "\n",
    "\n",
    "    # track_score(features_x, score)\n",
    "            # feature_importance_tuples = sorted(zip(X_tr.columns,model.feature_importances_), key=lambda x:x[1])\n",
    "            # # feature_importance_tuples = sorted(zip(X_tr.columns,model.feature_importance(importance_type='gain')), key=lambda x:x[1])\n",
    "            # feature_importance_map = {k:v for k,v in feature_importance_tuples}\n",
    "            # feature_imp = pd.DataFrame(feature_importance_tuples, columns=['feature','importance'])\n",
    "            # fig = pltex.bar(feature_imp, x='importance', y='feature', height=500)\n",
    "            # fig.show()\n",
    "\n",
    "show_score(features_x)\n",
    "        \n",
    "    # input(\"-------- ENTER TO CONINUE -------\")\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "281316b0-0116-40df-9937-a2b206e65fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18763"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b363782e-2426-45b8-a0a0-a6d8c4bb0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 3s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_test = load_prepare_amex_dataset(\"test_data_emp1\")\n",
    "# df_test_last1 = df_test.groupby('customer_ID').last()\n",
    "# df_test_last1 = df_test_last1.reset_index()\n",
    "# df_test_wt = pd.merge(df_test_last1, train_label_df, how='inner', on = 'customer_ID')#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75b35c5e-84ed-47ad-8c79-5936437bc109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72d064-0a30-4ae9-9fe4-e5a8cc831be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_bs_features = load_prepare_amex_dataset(\"test_data_bs_features_extracted\")\n",
    "df_test = df_test.reset_index().rename(columns={'index':'customer_ID'})\n",
    "df_test = df_test.merge(df_test_bs_features, on=\"customer_ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e812ac2-e8ef-4e19-aa75-d9862f55c5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>D_54_last</th>\n",
       "      <th>B_16_last</th>\n",
       "      <th>D_49_last</th>\n",
       "      <th>S_20_last</th>\n",
       "      <th>R_5_last</th>\n",
       "      <th>B_2_last</th>\n",
       "      <th>R_14_last</th>\n",
       "      <th>D_138_last</th>\n",
       "      <th>...</th>\n",
       "      <th>bs_386</th>\n",
       "      <th>bs_387</th>\n",
       "      <th>bs_388</th>\n",
       "      <th>bs_389</th>\n",
       "      <th>bs_390</th>\n",
       "      <th>bs_391</th>\n",
       "      <th>bs_392</th>\n",
       "      <th>bs_393</th>\n",
       "      <th>bs_394</th>\n",
       "      <th>bs_395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>1.007686</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>1.009347</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335811</td>\n",
       "      <td>-0.263116</td>\n",
       "      <td>-0.358178</td>\n",
       "      <td>0.651611</td>\n",
       "      <td>-0.356908</td>\n",
       "      <td>-0.478558</td>\n",
       "      <td>-0.367319</td>\n",
       "      <td>0.651469</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>-0.642639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>1.003089</td>\n",
       "      <td>0.091107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>1.009245</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216133</td>\n",
       "      <td>-0.451675</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.589825</td>\n",
       "      <td>-1.719163</td>\n",
       "      <td>-0.615235</td>\n",
       "      <td>-0.863192</td>\n",
       "      <td>0.367502</td>\n",
       "      <td>0.924606</td>\n",
       "      <td>-0.155024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>1.003348</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.810072</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100861</td>\n",
       "      <td>-0.195216</td>\n",
       "      <td>-0.379617</td>\n",
       "      <td>0.511827</td>\n",
       "      <td>-0.867911</td>\n",
       "      <td>-0.046278</td>\n",
       "      <td>-0.733860</td>\n",
       "      <td>0.115301</td>\n",
       "      <td>0.734151</td>\n",
       "      <td>-0.118117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>1.005929</td>\n",
       "      <td>1.006609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>-0.076750</td>\n",
       "      <td>0.583770</td>\n",
       "      <td>0.474542</td>\n",
       "      <td>0.187113</td>\n",
       "      <td>0.799281</td>\n",
       "      <td>-0.935340</td>\n",
       "      <td>-0.552446</td>\n",
       "      <td>0.593164</td>\n",
       "      <td>0.096221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>1.004245</td>\n",
       "      <td>1.009822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.038021</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>0.434476</td>\n",
       "      <td>0.689682</td>\n",
       "      <td>0.153366</td>\n",
       "      <td>-0.259030</td>\n",
       "      <td>0.776191</td>\n",
       "      <td>-0.317919</td>\n",
       "      <td>-0.485008</td>\n",
       "      <td>0.351477</td>\n",
       "      <td>0.877450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>924616</td>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>1.002669</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.817037</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019105</td>\n",
       "      <td>-0.194065</td>\n",
       "      <td>-0.032324</td>\n",
       "      <td>0.184423</td>\n",
       "      <td>-0.669451</td>\n",
       "      <td>-0.316483</td>\n",
       "      <td>-0.806006</td>\n",
       "      <td>0.021660</td>\n",
       "      <td>1.058970</td>\n",
       "      <td>-0.052874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>924617</td>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>1.005131</td>\n",
       "      <td>0.750046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009761</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>0.082507</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.758463</td>\n",
       "      <td>-0.141299</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>0.542051</td>\n",
       "      <td>-0.877696</td>\n",
       "      <td>-0.496406</td>\n",
       "      <td>0.871348</td>\n",
       "      <td>0.833241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>924618</td>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>1.000603</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.134571</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>1.004201</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385386</td>\n",
       "      <td>-0.395347</td>\n",
       "      <td>0.154520</td>\n",
       "      <td>0.268312</td>\n",
       "      <td>0.320566</td>\n",
       "      <td>0.802908</td>\n",
       "      <td>-0.973622</td>\n",
       "      <td>-0.388167</td>\n",
       "      <td>0.424626</td>\n",
       "      <td>0.147250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>924619</td>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>1.001342</td>\n",
       "      <td>1.003929</td>\n",
       "      <td>0.145777</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351461</td>\n",
       "      <td>-0.602158</td>\n",
       "      <td>0.656530</td>\n",
       "      <td>0.326861</td>\n",
       "      <td>0.595702</td>\n",
       "      <td>0.146379</td>\n",
       "      <td>-0.909322</td>\n",
       "      <td>-0.067012</td>\n",
       "      <td>0.954207</td>\n",
       "      <td>-0.149358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>924620</td>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>1.006517</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.810128</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531713</td>\n",
       "      <td>-0.373528</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.580081</td>\n",
       "      <td>-0.260284</td>\n",
       "      <td>-0.442911</td>\n",
       "      <td>-0.170408</td>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.576980</td>\n",
       "      <td>-0.546239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_ID                                        customer_ID  \\\n",
       "0                0  00000469ba478561f23a92a868bd366de6f6527a684c9a...   \n",
       "1                1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...   \n",
       "2                2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...   \n",
       "3                3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...   \n",
       "4                4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...   \n",
       "...            ...                                                ...   \n",
       "924616      924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...   \n",
       "924617      924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...   \n",
       "924618      924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...   \n",
       "924619      924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...   \n",
       "924620      924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...   \n",
       "\n",
       "        D_54_last  B_16_last  D_49_last  S_20_last  R_5_last  B_2_last  \\\n",
       "0        1.007686   0.002311        NaN   0.005336  0.005444  1.009347   \n",
       "1        1.003089   0.091107        NaN   0.002152  0.004132  1.009245   \n",
       "2        1.003348   0.006028        NaN   0.004302  0.006620  0.810072   \n",
       "3        1.005929   1.006609        NaN   0.009516  0.002603  0.205678   \n",
       "4        1.004245   1.009822        NaN   0.007866  0.004384  0.038021   \n",
       "...           ...        ...        ...        ...       ...       ...   \n",
       "924616   1.002669   0.000557        NaN   0.004032  0.003819  0.817037   \n",
       "924617   1.005131   0.750046        NaN   1.009761  0.008875  0.082507   \n",
       "924618   1.000603   0.003766   0.134571   0.007734  0.001188  1.004201   \n",
       "924619   1.001342   1.003929   0.145777   0.006050  0.008189  0.192895   \n",
       "924620   1.006517   0.008362        NaN   0.002435  0.009943  0.810128   \n",
       "\n",
       "        R_14_last  D_138_last  ...    bs_386    bs_387    bs_388    bs_389  \\\n",
       "0        0.006869    0.156909  ... -0.335811 -0.263116 -0.358178  0.651611   \n",
       "1        0.005801    0.156909  ...  0.216133 -0.451675 -0.000535  0.589825   \n",
       "2        0.000496    0.156909  ... -0.100861 -0.195216 -0.379617  0.511827   \n",
       "3        0.002470    0.156909  ...  0.031008 -0.076750  0.583770  0.474542   \n",
       "4        0.007108    0.156909  ...  0.083369  0.434476  0.689682  0.153366   \n",
       "...           ...         ...  ...       ...       ...       ...       ...   \n",
       "924616   0.003745    0.156909  ... -0.019105 -0.194065 -0.032324  0.184423   \n",
       "924617   0.005900    0.156909  ...  0.285859  0.001305  0.758463 -0.141299   \n",
       "924618   0.005715    0.156909  ... -0.385386 -0.395347  0.154520  0.268312   \n",
       "924619   0.003014    0.156909  ...  0.351461 -0.602158  0.656530  0.326861   \n",
       "924620   0.006272    0.156909  ...  0.531713 -0.373528  0.106257  0.580081   \n",
       "\n",
       "          bs_390    bs_391    bs_392    bs_393    bs_394    bs_395  \n",
       "0      -0.356908 -0.478558 -0.367319  0.651469  0.656389 -0.642639  \n",
       "1      -1.719163 -0.615235 -0.863192  0.367502  0.924606 -0.155024  \n",
       "2      -0.867911 -0.046278 -0.733860  0.115301  0.734151 -0.118117  \n",
       "3       0.187113  0.799281 -0.935340 -0.552446  0.593164  0.096221  \n",
       "4      -0.259030  0.776191 -0.317919 -0.485008  0.351477  0.877450  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "924616 -0.669451 -0.316483 -0.806006  0.021660  1.058970 -0.052874  \n",
       "924617 -0.014544  0.542051 -0.877696 -0.496406  0.871348  0.833241  \n",
       "924618  0.320566  0.802908 -0.973622 -0.388167  0.424626  0.147250  \n",
       "924619  0.595702  0.146379 -0.909322 -0.067012  0.954207 -0.149358  \n",
       "924620 -0.260284 -0.442911 -0.170408  0.472028  0.576980 -0.546239  \n",
       "\n",
       "[924621 rows x 856 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06178114-6abe-4988-af33-356d5a59063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x = [f for f in df_test.columns if f not in ['customer_ID', 'target', 'prediction', 'S_2']]\n",
    "X_tr = df_test[features_x]\n",
    "\n",
    "predictions = []\n",
    "for model in models:\n",
    "    preds = model.predict_proba(X_tr)\n",
    "    predictions.append(preds[:,1])#/len(models)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85e5291-43e1-427e-ba8d-a3e45b6cd493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>D_105_last</th>\n",
       "      <th>B_41_last</th>\n",
       "      <th>B_6_last</th>\n",
       "      <th>D_47_last</th>\n",
       "      <th>S_11_last</th>\n",
       "      <th>S_19_last</th>\n",
       "      <th>B_17_last</th>\n",
       "      <th>D_71_last</th>\n",
       "      <th>D_62_last</th>\n",
       "      <th>...</th>\n",
       "      <th>D_43_avg</th>\n",
       "      <th>B_5_avg</th>\n",
       "      <th>B_28_avg</th>\n",
       "      <th>S_15_avg</th>\n",
       "      <th>B_32_avg</th>\n",
       "      <th>D_122_avg</th>\n",
       "      <th>D_91_avg</th>\n",
       "      <th>D_145_avg</th>\n",
       "      <th>B_3_avg</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.024945</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>1.767255</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.281546</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.047263</td>\n",
       "      <td>0.145220</td>\n",
       "      <td>0.459957</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.147003</td>\n",
       "      <td>2.340590</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.034984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>0.362383</td>\n",
       "      <td>0.128330</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>0.330806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161138</td>\n",
       "      <td>0.101462</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.106175</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.576952</td>\n",
       "      <td>0.235882</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.287646</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.058534</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>0.889807</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>0.520753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130507</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.147394</td>\n",
       "      <td>0.320956</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.290148</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.065729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.224398</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.171934</td>\n",
       "      <td>0.968042</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.668001</td>\n",
       "      <td>0.017329</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301156</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>0.312598</td>\n",
       "      <td>0.274504</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.147582</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.186693</td>\n",
       "      <td>0.666754</td>\n",
       "      <td>0.292063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.440953</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226945</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.089654</td>\n",
       "      <td>0.328378</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.147947</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.686751</td>\n",
       "      <td>0.325048</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.223897</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.105243</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.576284</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>0.038857</td>\n",
       "      <td>0.101321</td>\n",
       "      <td>0.281895</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>0.050171</td>\n",
       "      <td>0.025270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387672</td>\n",
       "      <td>0.024482</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>0.512608</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.290021</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.037561</td>\n",
       "      <td>0.842739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.334874</td>\n",
       "      <td>0.924145</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.024912</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170376</td>\n",
       "      <td>0.032785</td>\n",
       "      <td>0.160168</td>\n",
       "      <td>0.336011</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.576455</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.507823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>0.143969</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.554004</td>\n",
       "      <td>0.406022</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.492614</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.076901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204906</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.575861</td>\n",
       "      <td>0.474902</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.190556</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.119271</td>\n",
       "      <td>0.247863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>0.385235</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.401867</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.928880</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.075224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161138</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.503965</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>0.755314</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.044484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  D_105_last  \\\n",
       "0       00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.385235   \n",
       "1       00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.385235   \n",
       "2       0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.287646   \n",
       "3       00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.224398   \n",
       "4       00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.385235   \n",
       "...                                                   ...         ...   \n",
       "924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...    0.385235   \n",
       "924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...    0.227022   \n",
       "924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...    0.385235   \n",
       "924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...    0.143969   \n",
       "924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.385235   \n",
       "\n",
       "        B_41_last  B_6_last  D_47_last  S_11_last  S_19_last  B_17_last  \\\n",
       "0        0.006789  0.024945   0.489448   1.767255   0.003337   0.928880   \n",
       "1        0.007340  0.182720   0.362383   0.128330   0.008257   0.928880   \n",
       "2        0.007062  0.058534   0.204331   0.889807   0.005802   0.928880   \n",
       "3        0.002427  0.023546   0.171934   0.968042   0.008854   0.668001   \n",
       "4        0.004532  0.011244   0.039700   0.440953   0.001778   0.977441   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "924616   0.007432  0.027490   0.686751   0.325048   0.005104   0.928880   \n",
       "924617   0.005822  0.038857   0.101321   0.281895   0.015289   0.799603   \n",
       "924618   0.007736  0.022962   0.334874   0.924145   0.001483   0.928880   \n",
       "924619   0.007967  0.008749   0.554004   0.406022   0.007858   0.492614   \n",
       "924620   0.005383  0.040591   0.666607   0.401867   0.008297   0.928880   \n",
       "\n",
       "        D_71_last  D_62_last  ...  D_43_avg   B_5_avg  B_28_avg  S_15_avg  \\\n",
       "0        0.281546   0.049326  ...  0.006835  0.047263  0.145220  0.459957   \n",
       "1        0.010397   0.330806  ...  0.161138  0.101462  0.033780  0.106175   \n",
       "2        0.044768   0.520753  ...  0.130507  0.020789  0.147394  0.320956   \n",
       "3        0.017329   0.016577  ...  0.301156  0.031221  0.312598  0.274504   \n",
       "4        0.009581   0.008594  ...  0.226945  0.010636  0.089654  0.328378   \n",
       "...           ...        ...  ...       ...       ...       ...       ...   \n",
       "924616   0.223897   0.111100  ...  0.044796  0.006056  0.020825  0.105243   \n",
       "924617   0.050171   0.025270  ...  0.387672  0.024482  0.034786  0.512608   \n",
       "924618   0.024912   0.013268  ...  0.170376  0.032785  0.160168  0.336011   \n",
       "924619   0.013216   0.076901  ...  0.204906  0.012303  0.575861  0.474902   \n",
       "924620   0.010680   0.075224  ...  0.161138  0.003344  0.021894  0.503965   \n",
       "\n",
       "        B_32_avg  D_122_avg  D_91_avg  D_145_avg   B_3_avg  prediction  \n",
       "0       0.005471   0.147003  2.340590   0.005271  0.009732    0.034984  \n",
       "1       0.003917   0.576952  0.235882   0.005466  0.006160    0.001249  \n",
       "2       0.004749   0.290148  0.003051   0.096248  0.008552    0.065729  \n",
       "3       0.004543   0.147582  0.003694   0.186693  0.666754    0.292063  \n",
       "4       0.004853   0.147947  0.004779   0.005032  0.616494    0.899910  \n",
       "...          ...        ...       ...        ...       ...         ...  \n",
       "924616  0.003565   0.576284  0.004979   0.004533  0.024127    0.025200  \n",
       "924617  0.006330   0.290021  0.005509   0.005944  0.037561    0.842739  \n",
       "924618  0.004171   0.576455  0.004919   0.003697  0.028587    0.507823  \n",
       "924619  0.005058   0.190556  0.005707   0.004818  0.119271    0.247863  \n",
       "924620  0.005945   0.434101  0.755314   0.004048  0.005958    0.044484  \n",
       "\n",
       "[924621 rows x 460 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f8db4d8-d5e1-4657-b0ae-1f3fa56d1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for idx, x in enumerate(df_test.columns):\n",
    "    if idx == 0:\n",
    "        new_cols.append(\"asdf\")\n",
    "    else:\n",
    "        new_cols.append(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86a7187b-2cb7-4382-a2c7-ec3e76743e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45a79d61-62d9-4871-a52d-8cb49b4cdae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.012867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.038715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.268484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.822679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>0.022296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>0.827280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>0.475655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>0.299100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>0.047055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  prediction\n",
       "0       00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.012867\n",
       "1       00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000692\n",
       "2       0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.038715\n",
       "3       00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.268484\n",
       "4       00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.822679\n",
       "...                                                   ...         ...\n",
       "924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...    0.022296\n",
       "924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...    0.827280\n",
       "924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...    0.475655\n",
       "924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...    0.299100\n",
       "924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.047055\n",
       "\n",
       "[924621 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['customer_ID','prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d61c8aa9-6115-4ddd-aa0d-5d4f5a6a161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['prediction'] = np.mean(predictions, axis=0)\n",
    "df_test[['customer_ID','prediction']].to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "956fa8db-510c-4e22-a6c5-7f8ad8b005bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.009875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.032084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.237248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.804010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...</td>\n",
       "      <td>0.016307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...</td>\n",
       "      <td>0.781760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...</td>\n",
       "      <td>0.435008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>ffffddef1fc3643ea179c93245b68dca0f36941cd83977...</td>\n",
       "      <td>0.237427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...</td>\n",
       "      <td>0.041515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  prediction\n",
       "0       00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.009875\n",
       "1       00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000525\n",
       "2       0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.032084\n",
       "3       00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.237248\n",
       "4       00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.804010\n",
       "...                                                   ...         ...\n",
       "924616  ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...    0.016307\n",
       "924617  ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...    0.781760\n",
       "924618  ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...    0.435008\n",
       "924619  ffffddef1fc3643ea179c93245b68dca0f36941cd83977...    0.237427\n",
       "924620  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.041515\n",
       "\n",
       "[924621 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d876111-9020-48cd-8ff2-62e00c1ef8a0",
   "metadata": {},
   "source": [
    "```\n",
    "Data: EMP1, + NN Sequential NN\n",
    "Features: similar aggregation like https://www.kaggle.com/code/ambrosm/amex-lightgbm-quickstart, except Cat aggs\n",
    "FEATURES: BS MOde feature extractors\n",
    "Model: 5 fold, lgbm standard, based on Sequence Features extracted\n",
    "Ensemble: choose max prediction value;highest proba out of 5 models\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
