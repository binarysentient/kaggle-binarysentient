{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dade30-94ed-4d49-bb1e-553b91996bb0",
   "metadata": {},
   "source": [
    "## IMPUTE INSANITY!:\n",
    "### before we move onto neural networks we need to impute the NANs\n",
    "#### How do we even know we've correctly imputed?\n",
    "#### **Try out every impute methods and per feature set train the GBM and see which one got most importance**\n",
    "\n",
    "### TODO\n",
    "- #### [KNN , DeepLearner, other novel ways to impute](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779)\n",
    "  - KNN thoughts: we can perhaps use subset of features with no nans, but then the records will become similar, and decision trees already predict the same result for similar looking rows? then what's the point of imputing value same as similar looking rows?\n",
    "- ### DON't Impute rather provide the Flag wether the feature has value or not, kinda like mask; we did this in Optiver (not the transformer sequence mask , but we have mask about weather the second/grouped seconds is missing or not)\n",
    "  - #### [Results on passing information about missing values to neural networks](https://machinelearningmastery.com/binary-flags-for-missing-values-for-machine-learning/)\n",
    "- ### AMEND ABOVE: Impute as well as pass the missing Flag too, so neural network learns better\n",
    "- ### Categorical Imputation: train on data with missing categorical values as target variable! **We can even use TEST set to do this!!!! yay!**\n",
    "  - #### [Training to find missing categorical values](https://www.analyticsvidhya.com/blog/2021/04/how-to-handle-missing-values-of-categorical-variables/)\n",
    "\n",
    "### IMPORTANT FLOAT16 aggregations return NONE!!! mean, sum most of it doesn't work :-/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d809121-a984-441c-8885-a94938548420",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- ### MULTILEVEL IMPUTATION DEFAULT\n",
    "- ### LEVEL 1: out of all the variant+original; select the one with best amex scores DEFAULT_EMP1\n",
    "    - #### This is partial nans\n",
    "- ### Level 2: now that we have partial none df with best variants(including original with nans) ; TRAIN ML MODEL to have PREDICTED/BS variant\n",
    "    - #### In the order of lowest missing values to highest missing values\n",
    "    - #### we Target the feature with lowest amount on NAN as we have maximum training rows; then slowly cascade to more missing row features\n",
    "    - #### once we have computed PREDICTED/BS variants for all of the features with nans\n",
    "- ### Level 3: from DEFAULT_EMP1 vs PREDICTED variant select the one with maximum amex score (this is kinda like back to stage 1 but with improved train_df_wt)\n",
    "    - #### repetetively select and choose the best varint out of the two\n",
    "    - #### DEFAULT_EMP2 is generated!\n",
    "    - #### Now there is a scope of repeating Level 2 again with using base_df of EMP2 and then going to EMP3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799d3de7-7230-42ee-b699-26d02974f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHERE_THIS = \"local\" # local|kaggle\n",
    "\n",
    "BS_DATASET = \"amex-default-prediction-binarysentient\"\n",
    "if WHERE_THIS == \"kaggle\":\n",
    "    INPUT_PATH = \"/kaggle/input/amex-default-prediction/\"\n",
    "    OUTPUT_PATH = \"/kaggle/working/\"\n",
    "    TEMP_PATH = \"/kaggle/temp/\"\n",
    "elif WHERE_THIS == \"local\":\n",
    "    INPUT_PATH = \"input/amex-default-prediction/\"\n",
    "    OUTPUT_PATH = \"working/\"\n",
    "    TEMP_PATH = \"temp/\"\n",
    "import os\n",
    "BS_PATH = os.path.join(TEMP_PATH,BS_DATASET)\n",
    "MODEL_PATH = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8e156e-282d-4a57-8738-46695bcc46cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/amex-default-prediction/sample_submission.csv\n",
      "input/amex-default-prediction/test_data.csv\n",
      "input/amex-default-prediction/train_data.csv\n",
      "input/amex-default-prediction/train_labels.csv\n",
      "input/amex-default-prediction/.ipynb_checkpoints\\sample_submission-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import display, HTML\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import plotly.express as pltex\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import impute_insanity\n",
    "from impute_insanity import load_prepare_amex_dataset\n",
    "import amex_bs_torch\n",
    "from amex_bs_torch import AmexDefaultBSDataset\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(INPUT_PATH):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f240c1ff-1841-49f9-b7af-c868c9dd855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features = ['customer_ID']\n",
    "discard_features = ['D_66', 'D_87']\n",
    "datetime_features = ['S_2']\n",
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_68']\n",
    "target_features = ['target']\n",
    "numeric_features = ['D_87', 'R_2', 'S_25', 'D_118', 'B_5', 'D_60', 'B_21', 'D_115', 'S_15', 'D_84', 'D_122', 'B_9', 'B_33', 'D_53', 'R_24', 'D_94', 'D_56', 'D_139', 'R_28', 'B_3', 'S_20', 'B_31', 'D_133', 'B_2', 'S_12', 'D_71', 'D_96', 'S_7', 'D_72', 'B_36', 'B_41', 'S_5', 'D_41', 'R_22', 'R_8', 'D_140', 'D_47', 'D_89', 'P_2', 'R_19', 'D_59', 'B_23', 'S_3', 'D_145', 'D_103', 'B_19', 'R_20', 'D_73', 'D_136', 'D_141', 'D_142', 'B_22', 'D_46', 'B_29', 'B_25', 'D_128', 'B_18', 'D_86', 'D_109', 'B_8', 'B_17', 'R_17', 'B_12', 'D_54', 'D_74', 'S_16', 'B_6', 'D_49', 'D_80', 'S_8', 'B_7', 'D_144', 'B_27', 'B_26', 'R_25', 'R_23', 'D_82', 'D_111', 'B_10', 'D_113', 'R_4', 'D_48', 'R_26', 'S_23', 'B_11', 'D_104', 'D_134', 'D_79', 'P_3', 'D_132', 'D_137', 'D_135', 'B_28', 'D_88', 'S_13', 'D_51', 'D_61', 'D_75', 'D_69', 'R_16', 'S_6', 'S_17', 'D_93', 'B_20', 'D_112', 'D_123', 'D_130', 'B_1', 'D_78', 'D_92', 'S_27', 'D_44', 'B_16', 'R_5', 'D_43', 'S_18', 'B_15', 'D_39', 'D_50', 'D_55', 'S_9', 'D_105', 'D_70', 'R_18', 'D_125', 'D_58', 'S_24', 'D_110', 'D_42', 'R_6', 'D_81', 'R_7', 'D_138', 'D_52', 'R_27', 'D_124', 'D_45', 'D_91', 'D_108', 'S_22', 'B_14', 'D_83', 'R_13', 'S_19', 'D_131', 'R_21', 'B_40', 'R_3', 'D_65', 'B_13', 'D_129', 'D_119', 'B_32', 'R_9', 'B_24', 'D_127', 'D_106', 'D_102', 'R_1', 'R_14', 'B_37', 'D_107', 'R_15', 'R_12', 'P_4', 'R_10','D_121', 'R_11', 'S_11', 'D_76', 'D_143', 'B_39', 'B_42', 'D_62', 'B_4', 'S_26', 'D_77']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779b4d70-375c-45d5-9bf4-08f4d9f05673",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: FAST AMEX implementation is not accurate; convert the dataframe accurate version to directly work with numpy arrays\n",
    "# @yunchonggan's fast metric implementation\n",
    "# From https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def fast_amex_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae15077-5505-455c-8f47-764800e88079",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fe7704-32c9-4242-b775-214378b4adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec9b907-ce7a-44a9-9ff6-afdb438d01df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD EAZZZZZ\n",
      "NON LAZY LOAD\n",
      "['train_data_emp1_nn_chunk_121', 'train_data_emp1_nn_chunk_38', 'train_data_emp1_nn_chunk_3', 'train_data_emp1_nn_chunk_63', 'train_data_emp1_nn_chunk_85', 'train_data_emp1_nn_chunk_109', 'train_data_emp1_nn_chunk_5', 'train_data_emp1_nn_chunk_14', 'train_data_emp1_nn_chunk_46', 'train_data_emp1_nn_chunk_116', 'train_data_emp1_nn_chunk_125', 'train_data_emp1_nn_chunk_12', 'train_data_emp1_nn_chunk_127', 'train_data_emp1_nn_chunk_103', 'train_data_emp1_nn_chunk_114', 'train_data_emp1_nn_chunk_18', 'train_data_emp1_nn_chunk_115', 'train_data_emp1_nn_chunk_59', 'train_data_emp1_nn_chunk_19', 'train_data_emp1_nn_chunk_72', 'train_data_emp1_nn_chunk_8', 'train_data_emp1_nn_chunk_106', 'train_data_emp1_nn_chunk_1', 'train_data_emp1_nn_chunk_27', 'train_data_emp1_nn_chunk_20', 'train_data_emp1_nn_chunk_95', 'train_data_emp1_nn_chunk_30', 'train_data_emp1_nn_chunk_34', 'train_data_emp1_nn_chunk_98', 'train_data_emp1_nn_chunk_120', 'train_data_emp1_nn_chunk_32', 'train_data_emp1_nn_chunk_37', 'train_data_emp1_nn_chunk_93', 'train_data_emp1_nn_chunk_42', 'train_data_emp1_nn_chunk_17', 'train_data_emp1_nn_chunk_92', 'train_data_emp1_nn_chunk_24', 'train_data_emp1_nn_chunk_104', 'train_data_emp1_nn_chunk_71', 'train_data_emp1_nn_chunk_68', 'train_data_emp1_nn_chunk_99', 'train_data_emp1_nn_chunk_9', 'train_data_emp1_nn_chunk_119', 'train_data_emp1_nn_chunk_15', 'train_data_emp1_nn_chunk_57', 'train_data_emp1_nn_chunk_33', 'train_data_emp1_nn_chunk_66', 'train_data_emp1_nn_chunk_91', 'train_data_emp1_nn_chunk_112', 'train_data_emp1_nn_chunk_96', 'train_data_emp1_nn_chunk_45', 'train_data_emp1_nn_chunk_124', 'train_data_emp1_nn_chunk_126', 'train_data_emp1_nn_chunk_101', 'train_data_emp1_nn_chunk_75', 'train_data_emp1_nn_chunk_25', 'train_data_emp1_nn_chunk_0', 'train_data_emp1_nn_chunk_73', 'train_data_emp1_nn_chunk_29', 'train_data_emp1_nn_chunk_86', 'train_data_emp1_nn_chunk_80', 'train_data_emp1_nn_chunk_49', 'train_data_emp1_nn_chunk_90', 'train_data_emp1_nn_chunk_84', 'train_data_emp1_nn_chunk_55', 'train_data_emp1_nn_chunk_87', 'train_data_emp1_nn_chunk_22', 'train_data_emp1_nn_chunk_52', 'train_data_emp1_nn_chunk_23', 'train_data_emp1_nn_chunk_16', 'train_data_emp1_nn_chunk_35', 'train_data_emp1_nn_chunk_82', 'train_data_emp1_nn_chunk_62', 'train_data_emp1_nn_chunk_43', 'train_data_emp1_nn_chunk_64', 'train_data_emp1_nn_chunk_11', 'train_data_emp1_nn_chunk_61', 'train_data_emp1_nn_chunk_56', 'train_data_emp1_nn_chunk_79', 'train_data_emp1_nn_chunk_108', 'train_data_emp1_nn_chunk_7', 'train_data_emp1_nn_chunk_4', 'train_data_emp1_nn_chunk_97', 'train_data_emp1_nn_chunk_76', 'train_data_emp1_nn_chunk_51', 'train_data_emp1_nn_chunk_81', 'train_data_emp1_nn_chunk_44', 'train_data_emp1_nn_chunk_113', 'train_data_emp1_nn_chunk_74', 'train_data_emp1_nn_chunk_50', 'train_data_emp1_nn_chunk_65', 'train_data_emp1_nn_chunk_78', 'train_data_emp1_nn_chunk_107', 'train_data_emp1_nn_chunk_6', 'train_data_emp1_nn_chunk_10', 'train_data_emp1_nn_chunk_41', 'train_data_emp1_nn_chunk_39', 'train_data_emp1_nn_chunk_118', 'train_data_emp1_nn_chunk_77', 'train_data_emp1_nn_chunk_58', 'train_data_emp1_nn_chunk_2', 'train_data_emp1_nn_chunk_110', 'train_data_emp1_nn_chunk_70', 'train_data_emp1_nn_chunk_47', 'train_data_emp1_nn_chunk_94', 'train_data_emp1_nn_chunk_54', 'train_data_emp1_nn_chunk_83', 'train_data_emp1_nn_chunk_53', 'train_data_emp1_nn_chunk_26', 'train_data_emp1_nn_chunk_69', 'train_data_emp1_nn_chunk_60', 'train_data_emp1_nn_chunk_105', 'train_data_emp1_nn_chunk_48', 'train_data_emp1_nn_chunk_88', 'train_data_emp1_nn_chunk_28', 'train_data_emp1_nn_chunk_100', 'train_data_emp1_nn_chunk_117', 'train_data_emp1_nn_chunk_40', 'train_data_emp1_nn_chunk_123', 'train_data_emp1_nn_chunk_67', 'train_data_emp1_nn_chunk_31', 'train_data_emp1_nn_chunk_122', 'train_data_emp1_nn_chunk_89', 'train_data_emp1_nn_chunk_111', 'train_data_emp1_nn_chunk_102', 'train_data_emp1_nn_chunk_36', 'train_data_emp1_nn_chunk_13', 'train_data_emp1_nn_chunk_21']\n"
     ]
    }
   ],
   "source": [
    "amexbsdataset = AmexDefaultBSDataset(total_chunks=128, lazy_load=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8adef25c-5050-455f-8856-b40a573160a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0911797-08cf-4397-8d76-fb94cba29335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 13):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd84dca4-e12d-438f-b59f-960ccab97134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmexBSModel(\n",
       "  (cat_embedding_layer): ModuleList(\n",
       "    (0): Embedding(4, 3)\n",
       "    (1): Embedding(9, 3)\n",
       "    (2): Embedding(3, 3)\n",
       "    (3): Embedding(3, 3)\n",
       "    (4): Embedding(8, 3)\n",
       "    (5): Embedding(4, 3)\n",
       "    (6): Embedding(4, 3)\n",
       "    (7): Embedding(7, 3)\n",
       "    (8): Embedding(5, 3)\n",
       "    (9): Embedding(8, 3)\n",
       "  )\n",
       "  (encoder_stack): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=396, out_features=396, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=396, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.25, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=396, bias=True)\n",
       "        (norm1): LayerNorm((396,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((396,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.25, inplace=False)\n",
       "        (dropout2): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gru_stack): GRU(396, 396, batch_first=True)\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=5148, out_features=256, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): GELU(approximate=none)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=396, bias=True)\n",
       "  )\n",
       "  (post_transformer): Sequential(\n",
       "    (0): Linear(in_features=5148, out_features=396, bias=True)\n",
       "  )\n",
       "  (mega_fusion): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=1188, out_features=512, bias=True)\n",
       "    (2): GELU(approximate=none)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): GELU(approximate=none)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear_after_transformer): Sequential(\n",
       "    (0): Linear(in_features=396, out_features=512, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (4): GELU(approximate=none)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AmexBSModel(nn.Module):\n",
    "    def __init__(self, category_embedding_dimensions=3, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mode: train|feature_extractor\n",
    "        \"\"\"\n",
    "        super(AmexBSModel,self).__init__()\n",
    "        self.mode=mode\n",
    "        self.sequence_length = 13\n",
    "        # need categorical emeddings for each cat_features\n",
    "        # features + all the embeddings go into input of transformer\n",
    "        # transformer output goes to the linear layers\n",
    "        # output of linear layer should be binary classification/probability\n",
    "        # each embeddig has the number of classes it can have, then we add 1 as we'll have extra category for masked data\n",
    "        self.cat_embedding_dimensions = category_embedding_dimensions\n",
    "        self.cat_encoders = amex_bs_torch.get_generate_cat_encoders()\n",
    "        self.cat_embedding_layer = nn.ModuleList([nn.Embedding(len(self.cat_encoders[x].classes_)+1, self.cat_embedding_dimensions) for x  in cat_features])\n",
    "        \n",
    "        \n",
    "        self.transformer_input_dimension = len(self.cat_embedding_layer)*self.cat_embedding_dimensions + len(self.cat_embedding_layer) + len(numeric_features)*2 + 2 # we'll have custom feature for months in system as feature\n",
    "        # self.positional_ecoding = PositionalEncoding(self.transformer_input_dimension, max_len=self.sequence_length)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.transformer_input_dimension, batch_first=True, nhead=1, dim_feedforward=1024, dropout=0.25, activation='gelu')\n",
    "        self.encoder_stack = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        self.gru_hidden_size = self.transformer_input_dimension\n",
    "        self.gru_stack = nn.GRU(input_size=self.transformer_input_dimension, hidden_size=self.gru_hidden_size, num_layers=1, batch_first=True)\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(self.transformer_input_dimension*self.sequence_length, 256),\n",
    "            # nn.Linear(self.gru_hidden_size, 256),\n",
    "            # nn.Linear(self.transformer_input_dimension*3, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 64),\n",
    "             nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, self.gru_hidden_size)\n",
    "        )\n",
    "        self.post_transformer = nn.Sequential(\n",
    "            nn.Linear(self.transformer_input_dimension*self.sequence_length, self.gru_hidden_size)\n",
    "            # nn.Linear(self.gru_hidden_size, 256),\n",
    "            # nn.Linear(self.transformer_input_dimension*3, 256),\n",
    "        )\n",
    "        self.mega_fusion = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.gru_hidden_size*3, 512),\n",
    "            # nn.Linear(self.gru_hidden_size, 256),\n",
    "            # nn.Linear(self.transformer_input_dimension*3, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 64),\n",
    "             nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.linear_after_transformer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(self.transformer_input_dimension, 512),\n",
    "            # nn.Linear(self.gru_hidden_size, 256),\n",
    "            # nn.Linear(self.transformer_input_dimension*3, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 64),\n",
    "             nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        # we have 3*\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        sequence_features = x['sequence_features'].type(torch.float32).to(device)\n",
    "        # shape (batch_size, sequence_length(13))\n",
    "        datatheremask = (x['sequence_mask'].type(torch.FloatTensor).to(device)*-1)+1\n",
    "        sequence_mask = x['sequence_mask'].type(torch.bool).to(device)\n",
    "        \n",
    "        \n",
    "        cat_features_embedded = []\n",
    "        # cat_features_nan_mask = []\n",
    "        for idx, cat_feature in enumerate(cat_features):\n",
    "            # print(sequence_features[cat_feature].shape)\n",
    "            # shape (batch_size, seqlen(13), self.cat_embedding_dimension(2))\n",
    "            cat_feature_embedded_ = self.cat_embedding_layer[idx](sequence_features[:,:,idx*2].type(torch.int32)) #\n",
    "            cat_features_embedded.append(cat_feature_embedded_)\n",
    "            cat_features_embedded.append(sequence_features[:,:,(idx*2)+1].unsqueeze(2))\n",
    "        \n",
    "        transformer_input_features = torch.cat(cat_features_embedded+[sequence_features[:,:,len(cat_features)*2:]], dim=2)\n",
    "        # print(cat_features_embedded.shape, cat_features_embedded)\n",
    "        \n",
    "#         numeric_features_embedded = []\n",
    "#         for idx, numeric_feature in enumerate(numeric_features):\n",
    "#             numeric_features_embedded.append(sequence_features[numeric_feature].to(device)) #.type(torch.FloatTensor)\n",
    "        \n",
    "#         numeric_features_embedded = torch.stack(numeric_features_embedded, dim=2)\n",
    "        \n",
    "        # out custom reversed months in system encoding, last entry gets 1 value while first entry gets increasing value far from last value,\n",
    "        maxmonthinsystem, maxmonthindex = torch.max(datatheremask.cumsum(1), dim=1)\n",
    "        monthsinsystem_pos_encoding = (((maxmonthinsystem.unsqueeze(1) - datatheremask.cumsum(1))+1) / 1000.0) * datatheremask\n",
    "        transformer_input_features_wpos = torch.add(transformer_input_features, monthsinsystem_pos_encoding.unsqueeze(2))\n",
    "        \n",
    "        # transformer_input_features = self.positional_ecoding(transformer_input_features.view(self.sequence_length, -1, self.transformer_input_dimension)).view(-1, self.sequence_length, self.transformer_input_dimension)\n",
    "        \n",
    "        # linear_stack_output = self.linear_stack(transformer_input_features.reshape(-1, self.transformer_input_dimension*self.sequence_length))\n",
    "                                                \n",
    "        transformer_output = self.encoder_stack(transformer_input_features, src_key_padding_mask=sequence_mask)\n",
    "        # transformer_output = transformer_output.reshape(-1, self.transformer_input_dimension*self.sequence_length)\n",
    "        transformer_output = transformer_output.mean(dim=1)\n",
    "        # transformer_output = self.post_transformer(transformer_output)\n",
    "        # transformer_output = torch.cat([transformer_output[:,0,:], transformer_output[:,6,:], transformer_output[:,-1,:]], dim=1)\n",
    "        \n",
    "        _, gru_output = self.gru_stack(transformer_input_features, transformer_output.view(1,-1,self.gru_hidden_size))\n",
    "        gru_output = gru_output[-1,:,:].reshape(-1, self.gru_hidden_size)\n",
    "        \n",
    "        if self.mode == 'feature_extractor':\n",
    "            return gru_output\n",
    "        \n",
    "        # print(linear_stack_output.shape, transformer_output.shape, gru_output.shape)\n",
    "        # final_output = self.mega_fusion(torch.cat([linear_stack_output, transformer_output, gru_output], dim=1))\n",
    "        final_output = self.linear_after_transformer(gru_output)\n",
    "        \n",
    "        # print(x['sequence_mask'].shape)\n",
    "        return final_output\n",
    "AmexBSModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d11c88e-a3f4-4c8e-bf69-2806ad25af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_random_sampler(indices=None):\n",
    "    train_labels = load_prepare_amex_dataset(\"train_labels\")\n",
    "    \n",
    "    # we have class 0 and 1, 1 class is 25% ish, so to make them equal we turn 0,1 to 0,0.5 then 0.25,0.75 so that class 1 is 75% scale while class 0 is 25% scale\n",
    "\n",
    "    # we set replacement to False so that we can pass through every samples in one epoch; we also now have to reduce length by 4 otherwise when all 1s are used then only 0s will be left as target\n",
    "    thetarget = None\n",
    "    if indices is None:\n",
    "        thetarget = train_labels['target']\n",
    "    else:\n",
    "        thetarget = train_labels['target'].loc[indices]\n",
    "    sampler = WeightedRandomSampler(((thetarget*0.5)+0.25).values, len(thetarget)//4, replacement=False)\n",
    "    del train_labels\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b125be4-29c8-4693-a8be-aedfeed2a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(amexbsdataset)\n",
    "train_size = int(0.9 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(amexbsdataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6608468-df2a-47a5-8fe3-fbd79e641c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del amex_bs_model\n",
    "del loss_function\n",
    "del loss\n",
    "del y_true\n",
    "del y_pred\n",
    "del optimizer\n",
    "del train_dataloader\n",
    "del test_dataloader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c9879-5431-49f3-90a4-30deb5f6ad17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9530ef-44fe-429e-b190-daf9c68652ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "batch_size = 512\n",
    "accumulation_steps = 1\n",
    "amex_bs_model = AmexBSModel().to(device)\n",
    "optimizer = torch.optim.AdamW(amex_bs_model.parameters(), lr=0.00002)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(3.0)).to(device)\n",
    "\n",
    "# loss_function = torch.nn.BCELoss()\n",
    "\n",
    "# loss_function = torch.nn.CrossEntropyLoss(torch.tensor([1.0,4.0], dtype=torch.float32)).to(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4096, pin_memory=True)#, sampler=get_weighted_random_sampler(test_dataset.indices))\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"--- EPOCH :\", epoch+1)\n",
    "     #, sampler=get_weighted_random_sampler(train_dataset.indices))\n",
    "    \n",
    "    # if epoch==0:\n",
    "    #     batch_size=4096\n",
    "    #     accumulation_steps=4\n",
    "    # elif epoch==1:\n",
    "    #     batch_size=4096\n",
    "    #     accumulation_steps=1\n",
    "    # elif epoch>=2:\n",
    "    #     batch_size=1024\n",
    "    #     accumulation_steps=1\n",
    "    # elif epoch>=5:\n",
    "    #     batch_size=128\n",
    "    #     accumulation_steps=1\n",
    "    # elif epoch>=10:\n",
    "    #     batch_size=64\n",
    "    #     accumulation_steps=1\n",
    "    \n",
    "   \n",
    "    current_samples = 0\n",
    "    current_losses = []\n",
    "    \n",
    "    for train_batch_idx, (Feature_X, y_true) in enumerate(train_dataloader): \n",
    "        # print(train_batch_idx)\n",
    "        y_pred = amex_bs_model(Feature_X)\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device)\n",
    "        loss = loss_function(y_pred, y_true.reshape(-1,1))\n",
    "        loss.backward()  \n",
    "        if (train_batch_idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        current_samples += batch_size\n",
    "        current_losses.append(loss.item())\n",
    "        if current_samples < (len(train_dataset)/5) :\n",
    "            # we display 10% marks\n",
    "            continue\n",
    "        current_samples = 0\n",
    "  \n",
    "        print(f\"Loss:  {np.mean(current_losses):0.6f}\")\n",
    "        current_losses = []\n",
    "    \n",
    "    amex_bs_model.eval()\n",
    "    amex_scores = []\n",
    "    for train_batch_idx, (Feature_X, y_true) in enumerate(test_dataloader): \n",
    "\n",
    "        y_pred = amex_bs_model(Feature_X).reshape(-1).cpu().detach().numpy()\n",
    "        y_true = y_true.detach().numpy()\n",
    "\n",
    "        amex_scores.append(fast_amex_metric(y_true, y_pred))\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"AMEX SCORE: {np.mean(amex_scores):0.5f}\")\n",
    "    print(\"-------------------------\")\n",
    "    amex_bs_model.train()\n",
    "    \n",
    "    \n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "    torch.save(amex_bs_model.state_dict(), os.path.join(MODEL_PATH,f\"{np.mean(amex_scores):0.5f}_amex_default_bs_model_epoch_{epoch}.pt\"))\n",
    "    \n",
    "    # print(\"Batch, train_batch_idx\", train_batch_idx)\n",
    "    # print(feature_y.sum(), feature_y)\n",
    "    # input()\n",
    "    # if train_batch_idx>40:\n",
    "    #     break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cb8caab1-b435-491f-ac87-5cd5382cb5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9248886 ,  1.4796506 , -0.36563623, ..., -0.32325116,\n",
       "       -2.1727817 ,  1.8644756 ], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1042c17d-bc54-4da3-80fe-3e24ecd6c233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380ef949-fea4-419c-82cf-4530d7d8416d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5afd67-097d-4a34-a989-d0910fda0bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3432bc80-4afa-4885-b81e-5ac5046b8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD EAZZZZZ\n",
      "NON LAZY LOAD\n",
      "['test_data_emp1_nn_chunk_28', 'test_data_emp1_nn_chunk_41', 'test_data_emp1_nn_chunk_80', 'test_data_emp1_nn_chunk_123', 'test_data_emp1_nn_chunk_36', 'test_data_emp1_nn_chunk_16', 'test_data_emp1_nn_chunk_87', 'test_data_emp1_nn_chunk_13', 'test_data_emp1_nn_chunk_102', 'test_data_emp1_nn_chunk_2', 'test_data_emp1_nn_chunk_23', 'test_data_emp1_nn_chunk_53', 'test_data_emp1_nn_chunk_54', 'test_data_emp1_nn_chunk_108', 'test_data_emp1_nn_chunk_84', 'test_data_emp1_nn_chunk_97', 'test_data_emp1_nn_chunk_7', 'test_data_emp1_nn_chunk_104', 'test_data_emp1_nn_chunk_50', 'test_data_emp1_nn_chunk_66', 'test_data_emp1_nn_chunk_57', 'test_data_emp1_nn_chunk_105', 'test_data_emp1_nn_chunk_95', 'test_data_emp1_nn_chunk_12', 'test_data_emp1_nn_chunk_101', 'test_data_emp1_nn_chunk_120', 'test_data_emp1_nn_chunk_121', 'test_data_emp1_nn_chunk_59', 'test_data_emp1_nn_chunk_19', 'test_data_emp1_nn_chunk_64', 'test_data_emp1_nn_chunk_67', 'test_data_emp1_nn_chunk_94', 'test_data_emp1_nn_chunk_44', 'test_data_emp1_nn_chunk_39', 'test_data_emp1_nn_chunk_8', 'test_data_emp1_nn_chunk_55', 'test_data_emp1_nn_chunk_110', 'test_data_emp1_nn_chunk_124', 'test_data_emp1_nn_chunk_25', 'test_data_emp1_nn_chunk_31', 'test_data_emp1_nn_chunk_58', 'test_data_emp1_nn_chunk_125', 'test_data_emp1_nn_chunk_77', 'test_data_emp1_nn_chunk_82', 'test_data_emp1_nn_chunk_60', 'test_data_emp1_nn_chunk_122', 'test_data_emp1_nn_chunk_119', 'test_data_emp1_nn_chunk_10', 'test_data_emp1_nn_chunk_92', 'test_data_emp1_nn_chunk_51', 'test_data_emp1_nn_chunk_103', 'test_data_emp1_nn_chunk_107', 'test_data_emp1_nn_chunk_27', 'test_data_emp1_nn_chunk_20', 'test_data_emp1_nn_chunk_21', 'test_data_emp1_nn_chunk_42', 'test_data_emp1_nn_chunk_17', 'test_data_emp1_nn_chunk_72', 'test_data_emp1_nn_chunk_90', 'test_data_emp1_nn_chunk_71', 'test_data_emp1_nn_chunk_93', 'test_data_emp1_nn_chunk_76', 'test_data_emp1_nn_chunk_48', 'test_data_emp1_nn_chunk_34', 'test_data_emp1_nn_chunk_126', 'test_data_emp1_nn_chunk_18', 'test_data_emp1_nn_chunk_65', 'test_data_emp1_nn_chunk_56', 'test_data_emp1_nn_chunk_78', 'test_data_emp1_nn_chunk_117', 'test_data_emp1_nn_chunk_15', 'test_data_emp1_nn_chunk_106', 'test_data_emp1_nn_chunk_1', 'test_data_emp1_nn_chunk_70', 'test_data_emp1_nn_chunk_62', 'test_data_emp1_nn_chunk_43', 'test_data_emp1_nn_chunk_69', 'test_data_emp1_nn_chunk_32', 'test_data_emp1_nn_chunk_73', 'test_data_emp1_nn_chunk_114', 'test_data_emp1_nn_chunk_11', 'test_data_emp1_nn_chunk_3', 'test_data_emp1_nn_chunk_61', 'test_data_emp1_nn_chunk_40', 'test_data_emp1_nn_chunk_63', 'test_data_emp1_nn_chunk_98', 'test_data_emp1_nn_chunk_4', 'test_data_emp1_nn_chunk_52', 'test_data_emp1_nn_chunk_38', 'test_data_emp1_nn_chunk_68', 'test_data_emp1_nn_chunk_91', 'test_data_emp1_nn_chunk_30', 'test_data_emp1_nn_chunk_29', 'test_data_emp1_nn_chunk_22', 'test_data_emp1_nn_chunk_26', 'test_data_emp1_nn_chunk_112', 'test_data_emp1_nn_chunk_47', 'test_data_emp1_nn_chunk_75', 'test_data_emp1_nn_chunk_24', 'test_data_emp1_nn_chunk_115', 'test_data_emp1_nn_chunk_83', 'test_data_emp1_nn_chunk_100', 'test_data_emp1_nn_chunk_111', 'test_data_emp1_nn_chunk_37', 'test_data_emp1_nn_chunk_0', 'test_data_emp1_nn_chunk_113', 'test_data_emp1_nn_chunk_81', 'test_data_emp1_nn_chunk_45', 'test_data_emp1_nn_chunk_88', 'test_data_emp1_nn_chunk_116', 'test_data_emp1_nn_chunk_49', 'test_data_emp1_nn_chunk_9', 'test_data_emp1_nn_chunk_89', 'test_data_emp1_nn_chunk_118', 'test_data_emp1_nn_chunk_35', 'test_data_emp1_nn_chunk_85', 'test_data_emp1_nn_chunk_79', 'test_data_emp1_nn_chunk_46', 'test_data_emp1_nn_chunk_5', 'test_data_emp1_nn_chunk_86', 'test_data_emp1_nn_chunk_33', 'test_data_emp1_nn_chunk_74', 'test_data_emp1_nn_chunk_96', 'test_data_emp1_nn_chunk_6', 'test_data_emp1_nn_chunk_99', 'test_data_emp1_nn_chunk_109', 'test_data_emp1_nn_chunk_127', 'test_data_emp1_nn_chunk_14']\n"
     ]
    }
   ],
   "source": [
    "amexbsdataset_test = AmexDefaultBSDataset(mode=\"test\",total_chunks=128, lazy_load=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ae1a5c-7194-4b4e-991e-0a2bfe3d4fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmexBSModel(\n",
       "  (cat_embedding_layer): ModuleList(\n",
       "    (0): Embedding(4, 3)\n",
       "    (1): Embedding(9, 3)\n",
       "    (2): Embedding(3, 3)\n",
       "    (3): Embedding(3, 3)\n",
       "    (4): Embedding(8, 3)\n",
       "    (5): Embedding(4, 3)\n",
       "    (6): Embedding(4, 3)\n",
       "    (7): Embedding(7, 3)\n",
       "    (8): Embedding(5, 3)\n",
       "    (9): Embedding(8, 3)\n",
       "  )\n",
       "  (encoder_stack): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=396, out_features=396, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=396, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.25, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=396, bias=True)\n",
       "        (norm1): LayerNorm((396,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((396,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.25, inplace=False)\n",
       "        (dropout2): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gru_stack): GRU(396, 396, batch_first=True)\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=5148, out_features=256, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): GELU(approximate=none)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=396, bias=True)\n",
       "  )\n",
       "  (post_transformer): Sequential(\n",
       "    (0): Linear(in_features=5148, out_features=396, bias=True)\n",
       "  )\n",
       "  (mega_fusion): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=1188, out_features=512, bias=True)\n",
       "    (2): GELU(approximate=none)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): GELU(approximate=none)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear_after_transformer): Sequential(\n",
       "    (0): Linear(in_features=396, out_features=512, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (4): GELU(approximate=none)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_bs_model = AmexBSModel()\n",
    "amex_bs_model.load_state_dict(torch.load(os.path.join(MODEL_PATH,\"0.79105_amex_default_bs_model_epoch_9.pt\")))\n",
    "amex_bs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1476352-2d53-447c-869a-b0d5fa4e6edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>bs_0</th>\n",
       "      <th>bs_1</th>\n",
       "      <th>bs_2</th>\n",
       "      <th>bs_3</th>\n",
       "      <th>bs_4</th>\n",
       "      <th>bs_5</th>\n",
       "      <th>bs_6</th>\n",
       "      <th>bs_7</th>\n",
       "      <th>bs_8</th>\n",
       "      <th>...</th>\n",
       "      <th>bs_386</th>\n",
       "      <th>bs_387</th>\n",
       "      <th>bs_388</th>\n",
       "      <th>bs_389</th>\n",
       "      <th>bs_390</th>\n",
       "      <th>bs_391</th>\n",
       "      <th>bs_392</th>\n",
       "      <th>bs_393</th>\n",
       "      <th>bs_394</th>\n",
       "      <th>bs_395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [customer_ID, bs_0, bs_1, bs_2, bs_3, bs_4, bs_5, bs_6, bs_7, bs_8, bs_9, bs_10, bs_11, bs_12, bs_13, bs_14, bs_15, bs_16, bs_17, bs_18, bs_19, bs_20, bs_21, bs_22, bs_23, bs_24, bs_25, bs_26, bs_27, bs_28, bs_29, bs_30, bs_31, bs_32, bs_33, bs_34, bs_35, bs_36, bs_37, bs_38, bs_39, bs_40, bs_41, bs_42, bs_43, bs_44, bs_45, bs_46, bs_47, bs_48, bs_49, bs_50, bs_51, bs_52, bs_53, bs_54, bs_55, bs_56, bs_57, bs_58, bs_59, bs_60, bs_61, bs_62, bs_63, bs_64, bs_65, bs_66, bs_67, bs_68, bs_69, bs_70, bs_71, bs_72, bs_73, bs_74, bs_75, bs_76, bs_77, bs_78, bs_79, bs_80, bs_81, bs_82, bs_83, bs_84, bs_85, bs_86, bs_87, bs_88, bs_89, bs_90, bs_91, bs_92, bs_93, bs_94, bs_95, bs_96, bs_97, bs_98, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 397 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, dtype={f\"bs_{x}\":'float32' for x in range(amex_bs_model.gru_hidden_size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b21a2e-d3f2-40d4-9a2f-2ffc238b9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_bs_model.mode = \"feature_extractor\"\n",
    "amex_bs_model.to(device)\n",
    "amex_bs_model.eval()\n",
    "dataloader_test = DataLoader(amexbsdataset_test, shuffle=False, batch_size=4096, pin_memory=True)\n",
    "customer_ids = []\n",
    "ypreds = []\n",
    "features_df = pd.DataFrame(columns=['customer_ID']+[f\"bs_{x}\" for x in range(amex_bs_model.gru_hidden_size)])\n",
    "for train_batch_idx, (Feature_X, y_true) in enumerate(dataloader_test):\n",
    "    Feature_X['sequence_features'] = torch.nan_to_num(Feature_X['sequence_features'])\n",
    "    y_pred = amex_bs_model(Feature_X)\n",
    "    # print(y_pred)\n",
    "    feature_columns = {}\n",
    "    feature_columns['customer_ID'] = Feature_X['customer_ID']\n",
    "    for idx, feature in enumerate(y_pred.permute(1,0).unbind(dim=0)):\n",
    "        feature_columns[f\"bs_{idx}\"] = feature.cpu().detach().numpy()\n",
    "    \n",
    "    features_df = pd.concat([features_df, pd.DataFrame(feature_columns)], ignore_index=True)\n",
    "    # input(features_df)\n",
    "    if torch.isnan(y_pred).any():\n",
    "        print(\"______ NANANANANA ____________\")\n",
    "    y_pred = y_pred.reshape(-1).detach().tolist()\n",
    "    \n",
    "    ypreds += y_pred\n",
    "    # print(y_pred)\n",
    "    customer_id = Feature_X['customer_ID']\n",
    "    customer_ids += customer_id\n",
    "    # print(customer_ids)\n",
    "    # input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d345b324-97fa-4dc4-908c-da67a8baccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_parquet(os.path.join(BS_PATH,\"test_data_bs_features_extracted.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20766710-9e3b-448e-8532-27162e6543e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'customer_ID':customer_ids,'prediction':ypreds}).to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4aa87c5-05c7-4faa-ba89-03cc42217fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136_nan_mask</th>\n",
       "      <th>D_137_nan_mask</th>\n",
       "      <th>D_138_nan_mask</th>\n",
       "      <th>D_139_nan_mask</th>\n",
       "      <th>D_140_nan_mask</th>\n",
       "      <th>D_141_nan_mask</th>\n",
       "      <th>D_142_nan_mask</th>\n",
       "      <th>D_143_nan_mask</th>\n",
       "      <th>D_144_nan_mask</th>\n",
       "      <th>D_145_nan_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b...</td>\n",
       "      <td>2018-04-23</td>\n",
       "      <td>0.990080</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.036668</td>\n",
       "      <td>1.009193</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.109592</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b...</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>0.933168</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>1.007722</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.097053</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b...</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.934100</td>\n",
       "      <td>0.123914</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>1.001847</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b...</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>0.896938</td>\n",
       "      <td>0.152745</td>\n",
       "      <td>0.112452</td>\n",
       "      <td>1.009726</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.081935</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b...</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>0.990730</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>1.001405</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>0.086514</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88951</th>\n",
       "      <td>fdfb1a337f25534b21dfe27e582878243d7ef5db838019...</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>0.148674</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88952</th>\n",
       "      <td>fdfb1a337f25534b21dfe27e582878243d7ef5db838019...</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>0.517142</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.084325</td>\n",
       "      <td>0.085383</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.274656</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.105405</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88953</th>\n",
       "      <td>fdfb1a337f25534b21dfe27e582878243d7ef5db838019...</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.086585</td>\n",
       "      <td>0.091485</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88954</th>\n",
       "      <td>fdfb1a337f25534b21dfe27e582878243d7ef5db838019...</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>0.531693</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.078207</td>\n",
       "      <td>0.092427</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.467106</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.153611</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88955</th>\n",
       "      <td>fdfb1a337f25534b21dfe27e582878243d7ef5db838019...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.434714</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.180432</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88956 rows Ã— 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             customer_ID        S_2       P_2  \\\n",
       "0      fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b... 2018-04-23  0.990080   \n",
       "1      fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b... 2018-05-16  0.933168   \n",
       "2      fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b... 2018-06-01  0.934100   \n",
       "3      fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b... 2018-07-02  0.896938   \n",
       "4      fbfa8ef66af90ba332c1c024fea9e2ad89a34d3692a07b... 2018-08-20  0.990730   \n",
       "...                                                  ...        ...       ...   \n",
       "88951  fdfb1a337f25534b21dfe27e582878243d7ef5db838019... 2019-06-19  0.530724   \n",
       "88952  fdfb1a337f25534b21dfe27e582878243d7ef5db838019... 2019-07-15  0.517142   \n",
       "88953  fdfb1a337f25534b21dfe27e582878243d7ef5db838019... 2019-08-18  0.532790   \n",
       "88954  fdfb1a337f25534b21dfe27e582878243d7ef5db838019... 2019-09-14  0.531693   \n",
       "88955  fdfb1a337f25534b21dfe27e582878243d7ef5db838019... 2019-10-17  0.522118   \n",
       "\n",
       "           D_39       B_1       B_2       R_1       S_3      D_41       B_3  \\\n",
       "0      0.002432  0.036668  1.009193  0.004333  0.109592  0.009624  0.008216   \n",
       "1      0.000008  0.036715  1.007722  0.007168  0.097053  0.001303  0.006442   \n",
       "2      0.123914  0.033306  1.001847  0.007540  0.098578  0.006818  0.008657   \n",
       "3      0.152745  0.112452  1.009726  0.006455  0.081935  0.005706  0.006653   \n",
       "4      0.000764  0.012469  1.001405  0.003212  0.086514  0.007664  0.002409   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "88951  0.148674  0.092000  0.087423  0.007374  0.303600  0.009540  0.110265   \n",
       "88952  0.009457  0.084325  0.085383  0.001179  0.274656  0.002791  0.105405   \n",
       "88953  0.066512  0.086585  0.091485  0.007870  0.451863  0.000864  0.160311   \n",
       "88954  0.008981  0.078207  0.092427  0.005957  0.467106  0.006395  0.153611   \n",
       "88955  0.036789  0.088421  0.089100  0.001886  0.434714  0.004184  0.180432   \n",
       "\n",
       "       ...  D_136_nan_mask  D_137_nan_mask  D_138_nan_mask  D_139_nan_mask  \\\n",
       "0      ...            True            True            True           False   \n",
       "1      ...            True            True            True           False   \n",
       "2      ...            True            True            True           False   \n",
       "3      ...            True            True            True           False   \n",
       "4      ...            True            True            True           False   \n",
       "...    ...             ...             ...             ...             ...   \n",
       "88951  ...           False           False           False           False   \n",
       "88952  ...           False           False           False           False   \n",
       "88953  ...           False           False           False           False   \n",
       "88954  ...           False           False           False           False   \n",
       "88955  ...           False           False           False           False   \n",
       "\n",
       "       D_140_nan_mask  D_141_nan_mask  D_142_nan_mask  D_143_nan_mask  \\\n",
       "0               False           False           False           False   \n",
       "1               False           False           False           False   \n",
       "2               False           False           False           False   \n",
       "3               False           False           False           False   \n",
       "4               False           False           False           False   \n",
       "...               ...             ...             ...             ...   \n",
       "88951           False           False           False           False   \n",
       "88952           False           False           False           False   \n",
       "88953           False           False           False           False   \n",
       "88954           False           False           False           False   \n",
       "88955           False           False           False           False   \n",
       "\n",
       "       D_144_nan_mask  D_145_nan_mask  \n",
       "0               False           False  \n",
       "1               False           False  \n",
       "2               False           False  \n",
       "3               False           False  \n",
       "4               False           False  \n",
       "...               ...             ...  \n",
       "88951           False           False  \n",
       "88952           False           False  \n",
       "88953           False           False  \n",
       "88954           False           False  \n",
       "88955           False           False  \n",
       "\n",
       "[88956 rows x 377 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_prepare_amex_dataset(\"test_data_emp1_nn_chunk_126\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61bdb6db-95c3-41de-a635-122f59bdc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanmask = load_prepare_amex_dataset(\"train_data_nan_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b32be3e9-f503-4f76-930d-f53e3c830266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2_nan</th>\n",
       "      <th>P_2_nan</th>\n",
       "      <th>D_39_nan</th>\n",
       "      <th>B_1_nan</th>\n",
       "      <th>B_2_nan</th>\n",
       "      <th>R_1_nan</th>\n",
       "      <th>S_3_nan</th>\n",
       "      <th>D_41_nan</th>\n",
       "      <th>B_3_nan</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136_nan</th>\n",
       "      <th>D_137_nan</th>\n",
       "      <th>D_138_nan</th>\n",
       "      <th>D_139_nan</th>\n",
       "      <th>D_140_nan</th>\n",
       "      <th>D_141_nan</th>\n",
       "      <th>D_142_nan</th>\n",
       "      <th>D_143_nan</th>\n",
       "      <th>D_144_nan</th>\n",
       "      <th>D_145_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531446</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531447</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531448</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531449</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531450</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5531451 rows Ã— 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_ID  S_2_nan  P_2_nan  D_39_nan  B_1_nan  B_2_nan  R_1_nan  \\\n",
       "0              False    False    False     False    False    False    False   \n",
       "1              False    False    False     False    False    False    False   \n",
       "2              False    False    False     False    False    False    False   \n",
       "3              False    False    False     False    False    False    False   \n",
       "4              False    False    False     False    False    False    False   \n",
       "...              ...      ...      ...       ...      ...      ...      ...   \n",
       "5531446        False    False    False     False    False    False    False   \n",
       "5531447        False    False    False     False    False    False    False   \n",
       "5531448        False    False    False     False    False    False    False   \n",
       "5531449        False    False    False     False    False    False    False   \n",
       "5531450        False    False    False     False    False    False    False   \n",
       "\n",
       "         S_3_nan  D_41_nan  B_3_nan  ...  D_136_nan  D_137_nan  D_138_nan  \\\n",
       "0          False     False    False  ...       True       True       True   \n",
       "1          False     False    False  ...       True       True       True   \n",
       "2          False     False    False  ...       True       True       True   \n",
       "3          False     False    False  ...       True       True       True   \n",
       "4          False     False    False  ...       True       True       True   \n",
       "...          ...       ...      ...  ...        ...        ...        ...   \n",
       "5531446    False     False    False  ...       True       True       True   \n",
       "5531447    False     False    False  ...       True       True       True   \n",
       "5531448    False     False    False  ...       True       True       True   \n",
       "5531449    False     False    False  ...       True       True       True   \n",
       "5531450    False     False    False  ...       True       True       True   \n",
       "\n",
       "         D_139_nan  D_140_nan  D_141_nan  D_142_nan  D_143_nan  D_144_nan  \\\n",
       "0            False      False      False       True      False      False   \n",
       "1            False      False      False       True      False      False   \n",
       "2            False      False      False       True      False      False   \n",
       "3            False      False      False       True      False      False   \n",
       "4            False      False      False       True      False      False   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "5531446      False      False      False       True      False      False   \n",
       "5531447      False      False      False       True      False      False   \n",
       "5531448      False      False      False       True      False      False   \n",
       "5531449      False      False      False       True      False      False   \n",
       "5531450      False      False      False       True      False      False   \n",
       "\n",
       "         D_145_nan  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "...            ...  \n",
       "5531446      False  \n",
       "5531447      False  \n",
       "5531448      False  \n",
       "5531449      False  \n",
       "5531450      False  \n",
       "\n",
       "[5531451 rows x 189 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanmask.rename(lambda x: x+\"_nan\" if x!=\"customer_ID\" else x, axis=1)\n",
    "nanmask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d876111-9020-48cd-8ff2-62e00c1ef8a0",
   "metadata": {},
   "source": [
    "```\n",
    "Data: EMP1_nn\n",
    "Features: Sequence_BSemp1, SequenceNANMASKS\n",
    "Model: BS Transformer -> TOUT As HiddenInitialState -> GRU, Linear , 256batch size\n",
    "Model: 0.79105_amex_default_bs_model_epoch_9\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
